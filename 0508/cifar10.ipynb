{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1E40beIIUadZ3Ju7lZQ4CaAwXlti1fido",
      "authorship_tag": "ABX9TyMphgfdjAtX8CDo73ACOTQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeitaTakami/WeeklyReport/blob/master/0508/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpaTHUeORZSJ",
        "colab_type": "code",
        "outputId": "5d5dcca7-bab8-4fc7-c911-b74cc307005b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        }
      },
      "source": [
        "!pip install dlt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dlt\n",
            "  Downloading https://files.pythonhosted.org/packages/34/3b/313449ab71dc7fecca4b3cd645bea0dcec9cf36bd772f93075bc185952c2/dlt-0.2.3-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from dlt) (3.2.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from dlt) (2.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from dlt) (0.22.2.post1)\n",
            "Requirement already satisfied: Numpy in /usr/local/lib/python3.6/dist-packages (from dlt) (1.18.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from dlt) (2.2.0rc4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dlt) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dlt) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dlt) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dlt) (2.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (3.13)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dlt) (0.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (1.28.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (2.2.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (2.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (3.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (46.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.2.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.6.0.post3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (0.4.8)\n",
            "Installing collected packages: dlt\n",
            "Successfully installed dlt-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlbFDrrH2QcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_AB=0\n",
        "learningrate=0.0001\n",
        "batch_s=32\n",
        "change_num=1\n",
        "epoch=50\n",
        "repetition=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYNOQGcSS7pl",
        "colab_type": "code",
        "outputId": "a69f2bf7-6c31-4da0-aeb1-30aeefbfe1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#dlt=Deep Learning Tools\n",
        "\n",
        "# parameter\n",
        "random_AB=0\n",
        "learningrate=0.0001\n",
        "batch_s=32\n",
        "change_num=1\n",
        "epoch=50\n",
        "repetition=10\n",
        "\n",
        "\n",
        "import dlt\n",
        "data=dlt.cifar.load_cifar10()\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation,Conv2D,MaxPooling2D,Flatten\n",
        "from keras.optimizers import Adam\n",
        "#データの取得,確認\n",
        "x=data.train_images[:10000]\n",
        "x=x.astype('float32')/255.0\n",
        "print(x.shape)\n",
        "y=data.train_labels[:10000]\n",
        "y=to_categorical(y,10)\n",
        "print(y.shape)\n",
        "#print(x[0])\n",
        "#print(y[0])\n",
        "#AとBに二分割\n",
        "x_a,x_b=train_test_split(x,test_size=0.5,random_state=random_AB)\n",
        "print(x_a.shape)\n",
        "print(x_b.shape)\n",
        "y_a,y_b=train_test_split(y,test_size=0.5,random_state=random_AB)\n",
        "print(y_a.shape)\n",
        "print(y_b.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading CIFAR-10 dataset\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 10)\n",
            "(5000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(5000, 10)\n",
            "(5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4uvY3dGYFhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#モデルの構築\n",
        "\n",
        "model_AtoB=Sequential()\n",
        "\n",
        "# 1層目\n",
        "model_AtoB.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(32,32,3)))\n",
        "model_AtoB.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model_AtoB.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_AtoB.add(Dropout(0.25))\n",
        "\n",
        "# 2層目\n",
        "model_AtoB.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model_AtoB.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model_AtoB.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_AtoB.add(Dropout(0.25))\n",
        "\n",
        "# 出力層\n",
        "model_AtoB.add(Flatten())\n",
        "model_AtoB.add(Dense(512))\n",
        "model_AtoB.add(Activation('relu'))\n",
        "model_AtoB.add(Dropout(0.5))\n",
        "model_AtoB.add(Dense(10))\n",
        "model_AtoB.add(Activation('softmax'))\n",
        "\n",
        "#モデルの構築\n",
        "model_BtoA=Sequential()\n",
        "\n",
        "# 1層目\n",
        "model_BtoA.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(32,32,3)))\n",
        "model_BtoA.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model_BtoA.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_BtoA.add(Dropout(0.25))\n",
        "\n",
        "# 2層目\n",
        "model_BtoA.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model_BtoA.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "model_BtoA.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_BtoA.add(Dropout(0.25))\n",
        "\n",
        "# 出力層\n",
        "model_BtoA.add(Flatten())\n",
        "model_BtoA.add(Dense(512))\n",
        "model_BtoA.add(Activation('relu'))\n",
        "model_BtoA.add(Dropout(0.5))\n",
        "model_BtoA.add(Dense(10))\n",
        "model_BtoA.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#モデルの構築\n",
        "def model():\n",
        "  model=Sequential()\n",
        "\n",
        "  # 1層目\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(32,32,3)))\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # 2層目\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # 出力層\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yxgerEhZogC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#A->train,B->test\n",
        "model_AtoB=model()\n",
        "model_BtoA=model()\n",
        "model_AtoB.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(lr=learningrate),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "#B->train,A->test\n",
        "model_BtoA.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(lr=learningrate),\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmFgoH93Zswz",
        "colab_type": "code",
        "outputId": "2bfab6c7-58be-46e3-b980-2ca68dbcab93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "AtoB_train_loss=[]\n",
        "AtoB_train_acc=[]\n",
        "AtoB_test_loss=[]\n",
        "AtoB_test_acc=[]\n",
        "BtoA_train_loss=[]\n",
        "BtoA_train_acc=[]\n",
        "BtoA_test_loss=[]\n",
        "BtoA_test_acc=[]\n",
        "for i in range(repetition):\n",
        "  print('%d回目' % i)\n",
        "  #A->train,B->test\n",
        "  model_AtoB.fit(x_a,y_a,\n",
        "    batch_size=batch_s,\n",
        "    epochs=epoch,\n",
        "    verbose=1,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "  AtoB_train_loss.append(model_AtoB.evaluate(x_a,y_a)[0])\n",
        "  AtoB_train_acc.append(model_AtoB.evaluate(x_a,y_a)[1])\n",
        "  AtoB_test_loss.append(model_AtoB.evaluate(x_b,y_b)[0])\n",
        "  AtoB_test_acc.append(model_AtoB.evaluate(x_b,y_b)[1])\n",
        "  y_b_pred=model_AtoB.predict_classes(x_b)\n",
        "  y_b_true=np.argmax(y_b,axis=1)\n",
        "  # Bの正解\n",
        "  B_correct=[]\n",
        "  for j in range(5000):\n",
        "    if y_b_pred[j] == y_b_true[j]:\n",
        "      B_correct.append(j)\n",
        "  \n",
        "\n",
        "  #B->train,A->test\n",
        "  model_BtoA.fit(x_b,y_b,\n",
        "    batch_size=batch_s,\n",
        "    epochs=epoch,\n",
        "    verbose=1,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "  BtoA_train_loss.append(model_BtoA.evaluate(x_b,y_b)[0])\n",
        "  BtoA_train_acc.append(model_BtoA.evaluate(x_b,y_b)[1])\n",
        "  BtoA_test_loss.append(model_BtoA.evaluate(x_a,y_a)[0])\n",
        "  BtoA_test_acc.append(model_BtoA.evaluate(x_a,y_a)[1])\n",
        "  y_a_pred=model_BtoA.predict_classes(x_a)\n",
        "  y_a_true=np.argmax(y_a,axis=1)\n",
        "  # Aの間違い\n",
        "  A_miss=[]\n",
        "  x_a_miss=[]\n",
        "  y_a_miss=[]\n",
        "  for j in range(5000):\n",
        "    if y_a_pred[j] != y_a_true[j]:\n",
        "      A_miss.append(j)\n",
        "  \n",
        "  random.shuffle(A_miss)\n",
        "  random.shuffle(B_correct)\n",
        "  \n",
        "  if change_num > 0:\n",
        "    if len(A_miss) <= len(B_correct):\n",
        "      change_max=len(A_miss)\n",
        "    else:\n",
        "      change_max=len(B_correct)\n",
        "    \n",
        "    if change_max > change_num:\n",
        "      change_max = change_num\n",
        "\n",
        "    for j in range(change_max):\n",
        "      x_a[A_miss[j]],x_b[B_correct[j]]=x_b[B_correct[j]],x_a[A_miss[j]]\n",
        "      y_a[A_miss[j]],y_b[B_correct[j]]=y_b[B_correct[j]],y_a[A_miss[j]]\n",
        "    \n",
        "    model_AtoB=model()\n",
        "    model_BtoA=model()\n",
        "    model_AtoB.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(lr=learningrate),\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    model_BtoA.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(lr=learningrate),\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/ABtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_test_acc))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/ABtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_train_acc))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/BAtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_test_acc))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/BAtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_train_acc))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/ABtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_test_loss))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/ABtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_train_loss))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/BAtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_test_loss))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/BAtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_train_loss))\n",
        "\n",
        "\n",
        "#モデルの保存\n",
        "import numpy as np\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import RMSprop\n",
        "import os\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/model/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_\"\n",
        "# モデル構造の保存\n",
        "open(SAVE_DATA_DIR_PATH  + \"model_AtoB.json\",\"w\").write(model_AtoB.to_json())\n",
        "\n",
        "# 学習済みの重みを保存\n",
        "model_AtoB.save_weights(SAVE_DATA_DIR_PATH + \"AtoB_weight.hdf5\")\n",
        "\n",
        "# モデル構造の保存\n",
        "open(SAVE_DATA_DIR_PATH  + \"model_BtoA.json\",\"w\").write(model_BtoA.to_json())\n",
        "\n",
        "# 学習済みの重みを保存\n",
        "model_BtoA.save_weights(SAVE_DATA_DIR_PATH + \"BtoA_weight.hdf5\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2830 - accuracy: 0.1320 - val_loss: 2.1971 - val_accuracy: 0.2280\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1008 - accuracy: 0.2209 - val_loss: 2.0181 - val_accuracy: 0.2660\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0006 - accuracy: 0.2624 - val_loss: 1.9399 - val_accuracy: 0.2880\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9021 - accuracy: 0.3107 - val_loss: 1.8689 - val_accuracy: 0.3260\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8163 - accuracy: 0.3340 - val_loss: 1.7995 - val_accuracy: 0.3580\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7504 - accuracy: 0.3642 - val_loss: 1.7665 - val_accuracy: 0.3540\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7006 - accuracy: 0.3758 - val_loss: 1.7236 - val_accuracy: 0.3640\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6585 - accuracy: 0.3898 - val_loss: 1.7168 - val_accuracy: 0.3920\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6271 - accuracy: 0.4002 - val_loss: 1.6788 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5881 - accuracy: 0.4222 - val_loss: 1.6384 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5602 - accuracy: 0.4289 - val_loss: 1.6289 - val_accuracy: 0.4060\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5197 - accuracy: 0.4440 - val_loss: 1.6127 - val_accuracy: 0.4300\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5067 - accuracy: 0.4458 - val_loss: 1.5740 - val_accuracy: 0.4220\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4787 - accuracy: 0.4644 - val_loss: 1.6205 - val_accuracy: 0.4260\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4652 - accuracy: 0.4662 - val_loss: 1.5632 - val_accuracy: 0.4260\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4443 - accuracy: 0.4660 - val_loss: 1.5706 - val_accuracy: 0.4260\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4264 - accuracy: 0.4833 - val_loss: 1.5699 - val_accuracy: 0.4580\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4075 - accuracy: 0.4927 - val_loss: 1.5227 - val_accuracy: 0.4640\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3911 - accuracy: 0.4902 - val_loss: 1.5358 - val_accuracy: 0.4600\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3709 - accuracy: 0.5084 - val_loss: 1.5641 - val_accuracy: 0.4520\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3689 - accuracy: 0.4980 - val_loss: 1.5565 - val_accuracy: 0.4480\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3527 - accuracy: 0.5116 - val_loss: 1.4963 - val_accuracy: 0.4520\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3354 - accuracy: 0.5158 - val_loss: 1.4852 - val_accuracy: 0.4560\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3152 - accuracy: 0.5309 - val_loss: 1.4879 - val_accuracy: 0.4620\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3042 - accuracy: 0.5327 - val_loss: 1.4766 - val_accuracy: 0.4700\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3008 - accuracy: 0.5340 - val_loss: 1.4644 - val_accuracy: 0.4540\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2756 - accuracy: 0.5378 - val_loss: 1.4932 - val_accuracy: 0.4460\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2696 - accuracy: 0.5411 - val_loss: 1.4702 - val_accuracy: 0.4640\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2374 - accuracy: 0.5571 - val_loss: 1.4949 - val_accuracy: 0.4540\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2344 - accuracy: 0.5542 - val_loss: 1.4898 - val_accuracy: 0.4280\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2310 - accuracy: 0.5613 - val_loss: 1.4733 - val_accuracy: 0.4640\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1959 - accuracy: 0.5747 - val_loss: 1.4545 - val_accuracy: 0.4780\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1856 - accuracy: 0.5693 - val_loss: 1.4375 - val_accuracy: 0.4600\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1721 - accuracy: 0.5842 - val_loss: 1.4536 - val_accuracy: 0.4740\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1468 - accuracy: 0.5898 - val_loss: 1.4333 - val_accuracy: 0.4880\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1595 - accuracy: 0.5796 - val_loss: 1.4245 - val_accuracy: 0.4860\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1353 - accuracy: 0.5871 - val_loss: 1.3898 - val_accuracy: 0.4880\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1315 - accuracy: 0.5909 - val_loss: 1.3900 - val_accuracy: 0.4940\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0995 - accuracy: 0.6100 - val_loss: 1.3971 - val_accuracy: 0.4700\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0878 - accuracy: 0.6256 - val_loss: 1.4041 - val_accuracy: 0.4900\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0958 - accuracy: 0.6093 - val_loss: 1.3824 - val_accuracy: 0.4960\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0778 - accuracy: 0.6109 - val_loss: 1.3962 - val_accuracy: 0.4780\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0710 - accuracy: 0.6222 - val_loss: 1.3832 - val_accuracy: 0.4840\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0535 - accuracy: 0.6244 - val_loss: 1.3916 - val_accuracy: 0.5020\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0076 - accuracy: 0.6444 - val_loss: 1.4422 - val_accuracy: 0.4960\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0107 - accuracy: 0.6484 - val_loss: 1.3498 - val_accuracy: 0.5080\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9921 - accuracy: 0.6529 - val_loss: 1.3754 - val_accuracy: 0.4940\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9846 - accuracy: 0.6524 - val_loss: 1.4194 - val_accuracy: 0.5160\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9839 - accuracy: 0.6478 - val_loss: 1.3495 - val_accuracy: 0.4860\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9582 - accuracy: 0.6560 - val_loss: 1.3798 - val_accuracy: 0.5000\n",
            "5000/5000 [==============================] - 4s 840us/step\n",
            "5000/5000 [==============================] - 4s 841us/step\n",
            "5000/5000 [==============================] - 4s 840us/step\n",
            "5000/5000 [==============================] - 4s 837us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2683 - accuracy: 0.1396 - val_loss: 2.1210 - val_accuracy: 0.2360\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0817 - accuracy: 0.2213 - val_loss: 2.0081 - val_accuracy: 0.2700\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9978 - accuracy: 0.2507 - val_loss: 1.9291 - val_accuracy: 0.3240\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8872 - accuracy: 0.3033 - val_loss: 1.7759 - val_accuracy: 0.3440\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7818 - accuracy: 0.3478 - val_loss: 1.7163 - val_accuracy: 0.3780\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7317 - accuracy: 0.3664 - val_loss: 1.6511 - val_accuracy: 0.4220\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6906 - accuracy: 0.3869 - val_loss: 1.6242 - val_accuracy: 0.4120\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6562 - accuracy: 0.3967 - val_loss: 1.5897 - val_accuracy: 0.4320\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6359 - accuracy: 0.4078 - val_loss: 1.5521 - val_accuracy: 0.4420\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5873 - accuracy: 0.4236 - val_loss: 1.5394 - val_accuracy: 0.4600\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5630 - accuracy: 0.4367 - val_loss: 1.5067 - val_accuracy: 0.4840\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5337 - accuracy: 0.4371 - val_loss: 1.4794 - val_accuracy: 0.4820\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5029 - accuracy: 0.4442 - val_loss: 1.4585 - val_accuracy: 0.4600\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4792 - accuracy: 0.4624 - val_loss: 1.4396 - val_accuracy: 0.4880\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4484 - accuracy: 0.4733 - val_loss: 1.4074 - val_accuracy: 0.4820\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4372 - accuracy: 0.4773 - val_loss: 1.4134 - val_accuracy: 0.4920\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4097 - accuracy: 0.4847 - val_loss: 1.3914 - val_accuracy: 0.5040\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3842 - accuracy: 0.4938 - val_loss: 1.3894 - val_accuracy: 0.4980\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3816 - accuracy: 0.4958 - val_loss: 1.3706 - val_accuracy: 0.5120\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3513 - accuracy: 0.5160 - val_loss: 1.3463 - val_accuracy: 0.5220\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3453 - accuracy: 0.5118 - val_loss: 1.3578 - val_accuracy: 0.5020\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3274 - accuracy: 0.5184 - val_loss: 1.3445 - val_accuracy: 0.5060\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3139 - accuracy: 0.5327 - val_loss: 1.3288 - val_accuracy: 0.5260\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2865 - accuracy: 0.5358 - val_loss: 1.3024 - val_accuracy: 0.5360\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2794 - accuracy: 0.5311 - val_loss: 1.3117 - val_accuracy: 0.5240\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2537 - accuracy: 0.5504 - val_loss: 1.3195 - val_accuracy: 0.5340\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2360 - accuracy: 0.5576 - val_loss: 1.2863 - val_accuracy: 0.5380\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2372 - accuracy: 0.5649 - val_loss: 1.2808 - val_accuracy: 0.5500\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2133 - accuracy: 0.5667 - val_loss: 1.2806 - val_accuracy: 0.5400\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2101 - accuracy: 0.5667 - val_loss: 1.2687 - val_accuracy: 0.5460\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1719 - accuracy: 0.5807 - val_loss: 1.2647 - val_accuracy: 0.5500\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1695 - accuracy: 0.5747 - val_loss: 1.2404 - val_accuracy: 0.5680\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1664 - accuracy: 0.5840 - val_loss: 1.2806 - val_accuracy: 0.5560\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1466 - accuracy: 0.5849 - val_loss: 1.2496 - val_accuracy: 0.5580\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1394 - accuracy: 0.5911 - val_loss: 1.2295 - val_accuracy: 0.5840\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1401 - accuracy: 0.5909 - val_loss: 1.2304 - val_accuracy: 0.5620\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1132 - accuracy: 0.6011 - val_loss: 1.2314 - val_accuracy: 0.5660\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1005 - accuracy: 0.6020 - val_loss: 1.2464 - val_accuracy: 0.5520\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0961 - accuracy: 0.6038 - val_loss: 1.2018 - val_accuracy: 0.5920\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0616 - accuracy: 0.6202 - val_loss: 1.2028 - val_accuracy: 0.5780\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0629 - accuracy: 0.6076 - val_loss: 1.2317 - val_accuracy: 0.5720\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0551 - accuracy: 0.6220 - val_loss: 1.1948 - val_accuracy: 0.5700\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0431 - accuracy: 0.6258 - val_loss: 1.2038 - val_accuracy: 0.5760\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0098 - accuracy: 0.6304 - val_loss: 1.1939 - val_accuracy: 0.5820\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0083 - accuracy: 0.6469 - val_loss: 1.2172 - val_accuracy: 0.5700\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9904 - accuracy: 0.6444 - val_loss: 1.1524 - val_accuracy: 0.5920\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9761 - accuracy: 0.6551 - val_loss: 1.1448 - val_accuracy: 0.5960\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9648 - accuracy: 0.6469 - val_loss: 1.1501 - val_accuracy: 0.5920\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9638 - accuracy: 0.6553 - val_loss: 1.1582 - val_accuracy: 0.6040\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9458 - accuracy: 0.6593 - val_loss: 1.1902 - val_accuracy: 0.5760\n",
            "5000/5000 [==============================] - 4s 845us/step\n",
            "5000/5000 [==============================] - 4s 850us/step\n",
            "5000/5000 [==============================] - 4s 870us/step\n",
            "5000/5000 [==============================] - 4s 849us/step\n",
            "1回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2871 - accuracy: 0.1351 - val_loss: 2.2223 - val_accuracy: 0.2040\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0892 - accuracy: 0.2162 - val_loss: 1.9999 - val_accuracy: 0.2440\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9031 - accuracy: 0.3013 - val_loss: 1.8919 - val_accuracy: 0.3140\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7979 - accuracy: 0.3327 - val_loss: 1.7803 - val_accuracy: 0.3480\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7354 - accuracy: 0.3569 - val_loss: 1.7390 - val_accuracy: 0.3720\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6868 - accuracy: 0.3784 - val_loss: 1.7082 - val_accuracy: 0.3900\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6601 - accuracy: 0.3871 - val_loss: 1.7212 - val_accuracy: 0.3920\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6174 - accuracy: 0.4036 - val_loss: 1.6865 - val_accuracy: 0.3860\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6094 - accuracy: 0.3991 - val_loss: 1.6441 - val_accuracy: 0.3920\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5731 - accuracy: 0.4156 - val_loss: 1.6278 - val_accuracy: 0.4200\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5651 - accuracy: 0.4271 - val_loss: 1.6163 - val_accuracy: 0.4320\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5332 - accuracy: 0.4380 - val_loss: 1.5795 - val_accuracy: 0.4140\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5153 - accuracy: 0.4396 - val_loss: 1.5760 - val_accuracy: 0.4180\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4938 - accuracy: 0.4467 - val_loss: 1.5577 - val_accuracy: 0.4520\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4670 - accuracy: 0.4573 - val_loss: 1.5270 - val_accuracy: 0.4560\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4567 - accuracy: 0.4618 - val_loss: 1.5180 - val_accuracy: 0.4600\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4254 - accuracy: 0.4789 - val_loss: 1.5312 - val_accuracy: 0.4560\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4209 - accuracy: 0.4769 - val_loss: 1.4925 - val_accuracy: 0.4860\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3885 - accuracy: 0.4929 - val_loss: 1.4815 - val_accuracy: 0.4780\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3869 - accuracy: 0.4933 - val_loss: 1.4956 - val_accuracy: 0.4700\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3739 - accuracy: 0.4956 - val_loss: 1.4741 - val_accuracy: 0.4840\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3487 - accuracy: 0.5040 - val_loss: 1.4711 - val_accuracy: 0.4840\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3315 - accuracy: 0.5156 - val_loss: 1.4906 - val_accuracy: 0.4620\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3397 - accuracy: 0.5120 - val_loss: 1.4875 - val_accuracy: 0.4780\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3167 - accuracy: 0.5224 - val_loss: 1.4398 - val_accuracy: 0.4700\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2954 - accuracy: 0.5284 - val_loss: 1.4751 - val_accuracy: 0.4860\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2785 - accuracy: 0.5380 - val_loss: 1.4413 - val_accuracy: 0.4920\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2687 - accuracy: 0.5351 - val_loss: 1.4639 - val_accuracy: 0.4880\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2594 - accuracy: 0.5424 - val_loss: 1.4518 - val_accuracy: 0.4960\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2391 - accuracy: 0.5491 - val_loss: 1.4167 - val_accuracy: 0.5060\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2326 - accuracy: 0.5567 - val_loss: 1.4487 - val_accuracy: 0.5020\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2411 - accuracy: 0.5473 - val_loss: 1.4063 - val_accuracy: 0.5080\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2132 - accuracy: 0.5578 - val_loss: 1.4365 - val_accuracy: 0.4920\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1927 - accuracy: 0.5693 - val_loss: 1.4000 - val_accuracy: 0.5060\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1808 - accuracy: 0.5782 - val_loss: 1.4054 - val_accuracy: 0.5040\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1714 - accuracy: 0.5733 - val_loss: 1.3824 - val_accuracy: 0.5080\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1505 - accuracy: 0.5842 - val_loss: 1.4098 - val_accuracy: 0.5020\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1435 - accuracy: 0.5824 - val_loss: 1.3807 - val_accuracy: 0.5160\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1191 - accuracy: 0.5976 - val_loss: 1.3967 - val_accuracy: 0.5040\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1209 - accuracy: 0.5978 - val_loss: 1.3921 - val_accuracy: 0.5140\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1195 - accuracy: 0.5944 - val_loss: 1.3808 - val_accuracy: 0.5240\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1020 - accuracy: 0.5996 - val_loss: 1.4044 - val_accuracy: 0.5060\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0907 - accuracy: 0.6100 - val_loss: 1.3631 - val_accuracy: 0.5300\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0830 - accuracy: 0.6169 - val_loss: 1.3685 - val_accuracy: 0.5140\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0621 - accuracy: 0.6240 - val_loss: 1.4011 - val_accuracy: 0.5220\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0466 - accuracy: 0.6251 - val_loss: 1.3425 - val_accuracy: 0.5240\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0380 - accuracy: 0.6358 - val_loss: 1.3926 - val_accuracy: 0.5220\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0300 - accuracy: 0.6322 - val_loss: 1.3514 - val_accuracy: 0.5460\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0121 - accuracy: 0.6316 - val_loss: 1.3801 - val_accuracy: 0.5260\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0017 - accuracy: 0.6438 - val_loss: 1.3476 - val_accuracy: 0.5280\n",
            "5000/5000 [==============================] - 4s 847us/step\n",
            "5000/5000 [==============================] - 4s 855us/step\n",
            "5000/5000 [==============================] - 4s 848us/step\n",
            "5000/5000 [==============================] - 4s 842us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2838 - accuracy: 0.1236 - val_loss: 2.2406 - val_accuracy: 0.2440\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1174 - accuracy: 0.2162 - val_loss: 2.0567 - val_accuracy: 0.2700\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0090 - accuracy: 0.2424 - val_loss: 1.9488 - val_accuracy: 0.2940\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9557 - accuracy: 0.2738 - val_loss: 1.8820 - val_accuracy: 0.3140\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8504 - accuracy: 0.3267 - val_loss: 1.7670 - val_accuracy: 0.3500\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7932 - accuracy: 0.3413 - val_loss: 1.7212 - val_accuracy: 0.3620\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7401 - accuracy: 0.3607 - val_loss: 1.6828 - val_accuracy: 0.4080\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7009 - accuracy: 0.3856 - val_loss: 1.6340 - val_accuracy: 0.4240\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6552 - accuracy: 0.3918 - val_loss: 1.6027 - val_accuracy: 0.4160\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6327 - accuracy: 0.4029 - val_loss: 1.5733 - val_accuracy: 0.4340\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5866 - accuracy: 0.4264 - val_loss: 1.5578 - val_accuracy: 0.4340\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5715 - accuracy: 0.4182 - val_loss: 1.5182 - val_accuracy: 0.4580\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5398 - accuracy: 0.4458 - val_loss: 1.4949 - val_accuracy: 0.4660\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5153 - accuracy: 0.4542 - val_loss: 1.4891 - val_accuracy: 0.4440\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4933 - accuracy: 0.4553 - val_loss: 1.4577 - val_accuracy: 0.4680\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4805 - accuracy: 0.4620 - val_loss: 1.4513 - val_accuracy: 0.4760\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4673 - accuracy: 0.4651 - val_loss: 1.4183 - val_accuracy: 0.4860\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4571 - accuracy: 0.4753 - val_loss: 1.4200 - val_accuracy: 0.5020\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4178 - accuracy: 0.4849 - val_loss: 1.3894 - val_accuracy: 0.4920\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3967 - accuracy: 0.4942 - val_loss: 1.3830 - val_accuracy: 0.4940\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3853 - accuracy: 0.5002 - val_loss: 1.4217 - val_accuracy: 0.4980\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3684 - accuracy: 0.5044 - val_loss: 1.3440 - val_accuracy: 0.5140\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3575 - accuracy: 0.5120 - val_loss: 1.3388 - val_accuracy: 0.5200\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3400 - accuracy: 0.5171 - val_loss: 1.3344 - val_accuracy: 0.5160\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3111 - accuracy: 0.5271 - val_loss: 1.3269 - val_accuracy: 0.5020\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2866 - accuracy: 0.5413 - val_loss: 1.3011 - val_accuracy: 0.5280\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2974 - accuracy: 0.5358 - val_loss: 1.2981 - val_accuracy: 0.5240\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2765 - accuracy: 0.5538 - val_loss: 1.2827 - val_accuracy: 0.5220\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2678 - accuracy: 0.5429 - val_loss: 1.2728 - val_accuracy: 0.5280\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2416 - accuracy: 0.5580 - val_loss: 1.2635 - val_accuracy: 0.5340\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2227 - accuracy: 0.5607 - val_loss: 1.2528 - val_accuracy: 0.5440\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2106 - accuracy: 0.5658 - val_loss: 1.2409 - val_accuracy: 0.5400\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2034 - accuracy: 0.5762 - val_loss: 1.2571 - val_accuracy: 0.5320\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1832 - accuracy: 0.5864 - val_loss: 1.2237 - val_accuracy: 0.5540\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1749 - accuracy: 0.5813 - val_loss: 1.2311 - val_accuracy: 0.5520\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1573 - accuracy: 0.5936 - val_loss: 1.1976 - val_accuracy: 0.5700\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1317 - accuracy: 0.6002 - val_loss: 1.1995 - val_accuracy: 0.5740\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1204 - accuracy: 0.5989 - val_loss: 1.1792 - val_accuracy: 0.5760\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1068 - accuracy: 0.6144 - val_loss: 1.1813 - val_accuracy: 0.5880\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0989 - accuracy: 0.6142 - val_loss: 1.2120 - val_accuracy: 0.5680\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0982 - accuracy: 0.6093 - val_loss: 1.1571 - val_accuracy: 0.5800\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0796 - accuracy: 0.6187 - val_loss: 1.1701 - val_accuracy: 0.5700\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0493 - accuracy: 0.6302 - val_loss: 1.1669 - val_accuracy: 0.5740\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0399 - accuracy: 0.6309 - val_loss: 1.1559 - val_accuracy: 0.5800\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0369 - accuracy: 0.6384 - val_loss: 1.1649 - val_accuracy: 0.5780\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0208 - accuracy: 0.6389 - val_loss: 1.1329 - val_accuracy: 0.5940\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0197 - accuracy: 0.6371 - val_loss: 1.1411 - val_accuracy: 0.5940\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9941 - accuracy: 0.6469 - val_loss: 1.1323 - val_accuracy: 0.6040\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 20s 5ms/step - loss: 0.9718 - accuracy: 0.6578 - val_loss: 1.1398 - val_accuracy: 0.5920\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9666 - accuracy: 0.6547 - val_loss: 1.1583 - val_accuracy: 0.5920\n",
            "5000/5000 [==============================] - 4s 850us/step\n",
            "5000/5000 [==============================] - 4s 844us/step\n",
            "5000/5000 [==============================] - 4s 858us/step\n",
            "5000/5000 [==============================] - 4s 850us/step\n",
            "2回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2860 - accuracy: 0.1278 - val_loss: 2.2326 - val_accuracy: 0.2260\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0922 - accuracy: 0.2216 - val_loss: 1.9511 - val_accuracy: 0.2480\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8841 - accuracy: 0.3064 - val_loss: 1.8372 - val_accuracy: 0.3300\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8087 - accuracy: 0.3298 - val_loss: 1.8058 - val_accuracy: 0.3660\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7492 - accuracy: 0.3604 - val_loss: 1.7717 - val_accuracy: 0.3520\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6924 - accuracy: 0.3744 - val_loss: 1.7077 - val_accuracy: 0.3760\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6404 - accuracy: 0.3896 - val_loss: 1.6585 - val_accuracy: 0.4080\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6155 - accuracy: 0.4036 - val_loss: 1.6656 - val_accuracy: 0.3940\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5928 - accuracy: 0.4211 - val_loss: 1.6628 - val_accuracy: 0.4060\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5432 - accuracy: 0.4338 - val_loss: 1.5821 - val_accuracy: 0.4400\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5206 - accuracy: 0.4338 - val_loss: 1.6632 - val_accuracy: 0.4120\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4949 - accuracy: 0.4451 - val_loss: 1.5628 - val_accuracy: 0.4420\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4741 - accuracy: 0.4682 - val_loss: 1.5505 - val_accuracy: 0.4400\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4602 - accuracy: 0.4667 - val_loss: 1.5520 - val_accuracy: 0.4440\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4259 - accuracy: 0.4769 - val_loss: 1.5319 - val_accuracy: 0.4420\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4116 - accuracy: 0.4876 - val_loss: 1.5374 - val_accuracy: 0.4520\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4093 - accuracy: 0.4858 - val_loss: 1.5333 - val_accuracy: 0.4580\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3904 - accuracy: 0.4904 - val_loss: 1.5047 - val_accuracy: 0.4560\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3758 - accuracy: 0.4993 - val_loss: 1.4969 - val_accuracy: 0.4740\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3502 - accuracy: 0.5120 - val_loss: 1.4953 - val_accuracy: 0.4720\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3448 - accuracy: 0.5104 - val_loss: 1.5088 - val_accuracy: 0.4580\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3269 - accuracy: 0.5127 - val_loss: 1.4882 - val_accuracy: 0.4560\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3120 - accuracy: 0.5211 - val_loss: 1.5165 - val_accuracy: 0.4540\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3096 - accuracy: 0.5287 - val_loss: 1.4886 - val_accuracy: 0.4820\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2883 - accuracy: 0.5336 - val_loss: 1.4599 - val_accuracy: 0.4800\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2695 - accuracy: 0.5440 - val_loss: 1.4619 - val_accuracy: 0.4860\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2575 - accuracy: 0.5476 - val_loss: 1.4578 - val_accuracy: 0.4900\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2559 - accuracy: 0.5484 - val_loss: 1.4550 - val_accuracy: 0.4840\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2304 - accuracy: 0.5567 - val_loss: 1.4198 - val_accuracy: 0.5040\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2105 - accuracy: 0.5687 - val_loss: 1.4441 - val_accuracy: 0.4960\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2113 - accuracy: 0.5633 - val_loss: 1.4332 - val_accuracy: 0.4780\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1942 - accuracy: 0.5700 - val_loss: 1.4410 - val_accuracy: 0.5040\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1903 - accuracy: 0.5702 - val_loss: 1.4377 - val_accuracy: 0.5060\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1663 - accuracy: 0.5871 - val_loss: 1.3777 - val_accuracy: 0.5160\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1462 - accuracy: 0.5909 - val_loss: 1.4579 - val_accuracy: 0.4840\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1435 - accuracy: 0.5880 - val_loss: 1.3851 - val_accuracy: 0.5140\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1189 - accuracy: 0.5938 - val_loss: 1.3747 - val_accuracy: 0.5200\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1100 - accuracy: 0.6038 - val_loss: 1.4074 - val_accuracy: 0.5060\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1040 - accuracy: 0.6009 - val_loss: 1.3932 - val_accuracy: 0.5240\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0985 - accuracy: 0.6078 - val_loss: 1.3427 - val_accuracy: 0.5260\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0727 - accuracy: 0.6116 - val_loss: 1.4037 - val_accuracy: 0.5080\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0483 - accuracy: 0.6202 - val_loss: 1.3998 - val_accuracy: 0.5180\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0508 - accuracy: 0.6213 - val_loss: 1.3637 - val_accuracy: 0.5240\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0367 - accuracy: 0.6329 - val_loss: 1.3443 - val_accuracy: 0.5180\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0216 - accuracy: 0.6387 - val_loss: 1.3446 - val_accuracy: 0.5200\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0022 - accuracy: 0.6398 - val_loss: 1.3467 - val_accuracy: 0.5300\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9933 - accuracy: 0.6427 - val_loss: 1.4087 - val_accuracy: 0.5240\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9861 - accuracy: 0.6467 - val_loss: 1.3333 - val_accuracy: 0.5300\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9788 - accuracy: 0.6471 - val_loss: 1.3283 - val_accuracy: 0.5320\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9612 - accuracy: 0.6529 - val_loss: 1.3377 - val_accuracy: 0.5220\n",
            "5000/5000 [==============================] - 4s 843us/step\n",
            "5000/5000 [==============================] - 4s 849us/step\n",
            "5000/5000 [==============================] - 4s 838us/step\n",
            "5000/5000 [==============================] - 4s 841us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2395 - accuracy: 0.1547 - val_loss: 2.0757 - val_accuracy: 0.2220\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0573 - accuracy: 0.2318 - val_loss: 1.9761 - val_accuracy: 0.2920\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9752 - accuracy: 0.2658 - val_loss: 1.9056 - val_accuracy: 0.3500\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8604 - accuracy: 0.3158 - val_loss: 1.7968 - val_accuracy: 0.3620\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7725 - accuracy: 0.3431 - val_loss: 1.7180 - val_accuracy: 0.3700\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7185 - accuracy: 0.3722 - val_loss: 1.6702 - val_accuracy: 0.4120\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6894 - accuracy: 0.3784 - val_loss: 1.6262 - val_accuracy: 0.4040\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6456 - accuracy: 0.3936 - val_loss: 1.6067 - val_accuracy: 0.4300\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6284 - accuracy: 0.4004 - val_loss: 1.5720 - val_accuracy: 0.4420\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 20s 4ms/step - loss: 1.6015 - accuracy: 0.4064 - val_loss: 1.5557 - val_accuracy: 0.4460\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5724 - accuracy: 0.4156 - val_loss: 1.5330 - val_accuracy: 0.4300\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5530 - accuracy: 0.4256 - val_loss: 1.5121 - val_accuracy: 0.4420\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5198 - accuracy: 0.4469 - val_loss: 1.4849 - val_accuracy: 0.4640\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4818 - accuracy: 0.4598 - val_loss: 1.4623 - val_accuracy: 0.4640\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4810 - accuracy: 0.4644 - val_loss: 1.4441 - val_accuracy: 0.4740\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4419 - accuracy: 0.4731 - val_loss: 1.4390 - val_accuracy: 0.4780\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4179 - accuracy: 0.4811 - val_loss: 1.4183 - val_accuracy: 0.4920\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4061 - accuracy: 0.4936 - val_loss: 1.3838 - val_accuracy: 0.4980\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3889 - accuracy: 0.4918 - val_loss: 1.3759 - val_accuracy: 0.4980\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3618 - accuracy: 0.5031 - val_loss: 1.3913 - val_accuracy: 0.4760\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3594 - accuracy: 0.5124 - val_loss: 1.3816 - val_accuracy: 0.4900\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3337 - accuracy: 0.5160 - val_loss: 1.3626 - val_accuracy: 0.5020\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3209 - accuracy: 0.5293 - val_loss: 1.3371 - val_accuracy: 0.4920\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3039 - accuracy: 0.5211 - val_loss: 1.3167 - val_accuracy: 0.5160\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2813 - accuracy: 0.5364 - val_loss: 1.3150 - val_accuracy: 0.5180\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2756 - accuracy: 0.5407 - val_loss: 1.3122 - val_accuracy: 0.5200\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2615 - accuracy: 0.5400 - val_loss: 1.3012 - val_accuracy: 0.5220\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2467 - accuracy: 0.5513 - val_loss: 1.2858 - val_accuracy: 0.5340\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2295 - accuracy: 0.5584 - val_loss: 1.2796 - val_accuracy: 0.5300\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2307 - accuracy: 0.5560 - val_loss: 1.3011 - val_accuracy: 0.5320\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2055 - accuracy: 0.5713 - val_loss: 1.2698 - val_accuracy: 0.5540\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2067 - accuracy: 0.5644 - val_loss: 1.2761 - val_accuracy: 0.5300\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1879 - accuracy: 0.5662 - val_loss: 1.2704 - val_accuracy: 0.5360\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1675 - accuracy: 0.5827 - val_loss: 1.2665 - val_accuracy: 0.5400\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1620 - accuracy: 0.5811 - val_loss: 1.2401 - val_accuracy: 0.5600\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1478 - accuracy: 0.5807 - val_loss: 1.2455 - val_accuracy: 0.5500\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1323 - accuracy: 0.5918 - val_loss: 1.2377 - val_accuracy: 0.5560\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1148 - accuracy: 0.5949 - val_loss: 1.2405 - val_accuracy: 0.5620\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1134 - accuracy: 0.6004 - val_loss: 1.2230 - val_accuracy: 0.5700\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0999 - accuracy: 0.6160 - val_loss: 1.2284 - val_accuracy: 0.5660\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0970 - accuracy: 0.5987 - val_loss: 1.2131 - val_accuracy: 0.5860\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0735 - accuracy: 0.6087 - val_loss: 1.2255 - val_accuracy: 0.5580\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0710 - accuracy: 0.6207 - val_loss: 1.2293 - val_accuracy: 0.5540\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0643 - accuracy: 0.6222 - val_loss: 1.2108 - val_accuracy: 0.5720\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0368 - accuracy: 0.6322 - val_loss: 1.1890 - val_accuracy: 0.5860\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0294 - accuracy: 0.6207 - val_loss: 1.2208 - val_accuracy: 0.5700\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 21s 5ms/step - loss: 1.0252 - accuracy: 0.6376 - val_loss: 1.1960 - val_accuracy: 0.5760\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0043 - accuracy: 0.6353 - val_loss: 1.2048 - val_accuracy: 0.5680\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9846 - accuracy: 0.6464 - val_loss: 1.1930 - val_accuracy: 0.5760\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9903 - accuracy: 0.6558 - val_loss: 1.2072 - val_accuracy: 0.6020\n",
            "5000/5000 [==============================] - 4s 859us/step\n",
            "5000/5000 [==============================] - 4s 858us/step\n",
            "5000/5000 [==============================] - 4s 859us/step\n",
            "5000/5000 [==============================] - 4s 859us/step\n",
            "3回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2944 - accuracy: 0.1133 - val_loss: 2.2356 - val_accuracy: 0.1660\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1223 - accuracy: 0.2067 - val_loss: 2.0377 - val_accuracy: 0.2460\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9994 - accuracy: 0.2578 - val_loss: 1.9527 - val_accuracy: 0.2900\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8823 - accuracy: 0.3111 - val_loss: 1.8357 - val_accuracy: 0.3500\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7880 - accuracy: 0.3373 - val_loss: 1.7814 - val_accuracy: 0.3480\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7427 - accuracy: 0.3613 - val_loss: 1.7417 - val_accuracy: 0.3640\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6828 - accuracy: 0.3736 - val_loss: 1.6987 - val_accuracy: 0.3780\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6546 - accuracy: 0.3856 - val_loss: 1.6857 - val_accuracy: 0.3820\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6270 - accuracy: 0.3951 - val_loss: 1.6553 - val_accuracy: 0.3860\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6012 - accuracy: 0.4122 - val_loss: 1.6214 - val_accuracy: 0.4000\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5846 - accuracy: 0.4138 - val_loss: 1.6070 - val_accuracy: 0.4200\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5676 - accuracy: 0.4220 - val_loss: 1.6012 - val_accuracy: 0.4220\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5538 - accuracy: 0.4307 - val_loss: 1.5766 - val_accuracy: 0.4120\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5307 - accuracy: 0.4380 - val_loss: 1.5882 - val_accuracy: 0.4400\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5072 - accuracy: 0.4496 - val_loss: 1.5822 - val_accuracy: 0.4180\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4823 - accuracy: 0.4536 - val_loss: 1.5618 - val_accuracy: 0.4320\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4634 - accuracy: 0.4702 - val_loss: 1.5369 - val_accuracy: 0.4260\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4377 - accuracy: 0.4827 - val_loss: 1.5174 - val_accuracy: 0.4540\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4262 - accuracy: 0.4820 - val_loss: 1.5306 - val_accuracy: 0.4500\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3981 - accuracy: 0.4929 - val_loss: 1.4872 - val_accuracy: 0.4660\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3955 - accuracy: 0.4971 - val_loss: 1.4803 - val_accuracy: 0.4600\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3815 - accuracy: 0.4931 - val_loss: 1.5154 - val_accuracy: 0.4520\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3517 - accuracy: 0.5127 - val_loss: 1.4834 - val_accuracy: 0.4520\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3480 - accuracy: 0.5084 - val_loss: 1.4234 - val_accuracy: 0.4840\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3306 - accuracy: 0.5120 - val_loss: 1.4273 - val_accuracy: 0.4880\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2983 - accuracy: 0.5344 - val_loss: 1.4363 - val_accuracy: 0.4800\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2969 - accuracy: 0.5371 - val_loss: 1.4055 - val_accuracy: 0.4900\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2769 - accuracy: 0.5331 - val_loss: 1.4048 - val_accuracy: 0.4680\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2741 - accuracy: 0.5462 - val_loss: 1.3770 - val_accuracy: 0.4820\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2433 - accuracy: 0.5509 - val_loss: 1.3792 - val_accuracy: 0.5020\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2344 - accuracy: 0.5511 - val_loss: 1.3845 - val_accuracy: 0.4800\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2317 - accuracy: 0.5549 - val_loss: 1.3582 - val_accuracy: 0.5080\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 20s 4ms/step - loss: 1.2087 - accuracy: 0.5738 - val_loss: 1.3575 - val_accuracy: 0.5020\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1861 - accuracy: 0.5729 - val_loss: 1.3632 - val_accuracy: 0.5140\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1766 - accuracy: 0.5773 - val_loss: 1.3420 - val_accuracy: 0.5060\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1594 - accuracy: 0.5811 - val_loss: 1.3750 - val_accuracy: 0.4980\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1464 - accuracy: 0.5856 - val_loss: 1.3421 - val_accuracy: 0.5160\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1365 - accuracy: 0.5864 - val_loss: 1.3291 - val_accuracy: 0.4940\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1455 - accuracy: 0.5929 - val_loss: 1.3449 - val_accuracy: 0.4980\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1082 - accuracy: 0.6000 - val_loss: 1.3258 - val_accuracy: 0.5120\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1047 - accuracy: 0.6011 - val_loss: 1.3937 - val_accuracy: 0.5040\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0902 - accuracy: 0.6151 - val_loss: 1.3731 - val_accuracy: 0.5120\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0703 - accuracy: 0.6202 - val_loss: 1.3685 - val_accuracy: 0.5180\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0712 - accuracy: 0.6187 - val_loss: 1.3187 - val_accuracy: 0.5240\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0481 - accuracy: 0.6251 - val_loss: 1.3565 - val_accuracy: 0.4920\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0482 - accuracy: 0.6304 - val_loss: 1.3193 - val_accuracy: 0.5240\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0338 - accuracy: 0.6216 - val_loss: 1.3122 - val_accuracy: 0.5220\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0039 - accuracy: 0.6411 - val_loss: 1.3150 - val_accuracy: 0.5200\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9911 - accuracy: 0.6529 - val_loss: 1.3442 - val_accuracy: 0.5120\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9834 - accuracy: 0.6493 - val_loss: 1.3333 - val_accuracy: 0.5240\n",
            "5000/5000 [==============================] - 4s 857us/step\n",
            "5000/5000 [==============================] - 4s 851us/step\n",
            "5000/5000 [==============================] - 4s 861us/step\n",
            "5000/5000 [==============================] - 4s 853us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2904 - accuracy: 0.1253 - val_loss: 2.2523 - val_accuracy: 0.2120\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0739 - accuracy: 0.2382 - val_loss: 1.8903 - val_accuracy: 0.3420\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8910 - accuracy: 0.3071 - val_loss: 1.7751 - val_accuracy: 0.3480\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7897 - accuracy: 0.3484 - val_loss: 1.7239 - val_accuracy: 0.3880\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7487 - accuracy: 0.3631 - val_loss: 1.6794 - val_accuracy: 0.3860\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6864 - accuracy: 0.3813 - val_loss: 1.6319 - val_accuracy: 0.4100\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6612 - accuracy: 0.3871 - val_loss: 1.6359 - val_accuracy: 0.3920\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6305 - accuracy: 0.3964 - val_loss: 1.5848 - val_accuracy: 0.4400\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6016 - accuracy: 0.4120 - val_loss: 1.5323 - val_accuracy: 0.4560\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5704 - accuracy: 0.4262 - val_loss: 1.5208 - val_accuracy: 0.4460\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5353 - accuracy: 0.4487 - val_loss: 1.4986 - val_accuracy: 0.4520\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5266 - accuracy: 0.4469 - val_loss: 1.4812 - val_accuracy: 0.4660\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4982 - accuracy: 0.4582 - val_loss: 1.4898 - val_accuracy: 0.4720\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4868 - accuracy: 0.4662 - val_loss: 1.4445 - val_accuracy: 0.4740\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4599 - accuracy: 0.4693 - val_loss: 1.4383 - val_accuracy: 0.4720\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4315 - accuracy: 0.4820 - val_loss: 1.4797 - val_accuracy: 0.4780\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4278 - accuracy: 0.4931 - val_loss: 1.4224 - val_accuracy: 0.4900\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4030 - accuracy: 0.4882 - val_loss: 1.3984 - val_accuracy: 0.5080\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 20s 4ms/step - loss: 1.3864 - accuracy: 0.5044 - val_loss: 1.3791 - val_accuracy: 0.4900\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3783 - accuracy: 0.5022 - val_loss: 1.3884 - val_accuracy: 0.4940\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3649 - accuracy: 0.5064 - val_loss: 1.4026 - val_accuracy: 0.4940\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3491 - accuracy: 0.5153 - val_loss: 1.3430 - val_accuracy: 0.5140\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3064 - accuracy: 0.5313 - val_loss: 1.3270 - val_accuracy: 0.5120\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3011 - accuracy: 0.5304 - val_loss: 1.3276 - val_accuracy: 0.5280\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2960 - accuracy: 0.5349 - val_loss: 1.3283 - val_accuracy: 0.4980\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2801 - accuracy: 0.5422 - val_loss: 1.3235 - val_accuracy: 0.5160\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2548 - accuracy: 0.5498 - val_loss: 1.3064 - val_accuracy: 0.5240\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2526 - accuracy: 0.5576 - val_loss: 1.2912 - val_accuracy: 0.5300\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2363 - accuracy: 0.5556 - val_loss: 1.3021 - val_accuracy: 0.5260\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2253 - accuracy: 0.5587 - val_loss: 1.3040 - val_accuracy: 0.5220\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2069 - accuracy: 0.5713 - val_loss: 1.3173 - val_accuracy: 0.5280\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1978 - accuracy: 0.5767 - val_loss: 1.2709 - val_accuracy: 0.5480\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1819 - accuracy: 0.5740 - val_loss: 1.2625 - val_accuracy: 0.5500\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1651 - accuracy: 0.5856 - val_loss: 1.2418 - val_accuracy: 0.5480\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1540 - accuracy: 0.5880 - val_loss: 1.2272 - val_accuracy: 0.5580\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1368 - accuracy: 0.5922 - val_loss: 1.2227 - val_accuracy: 0.5620\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1313 - accuracy: 0.5958 - val_loss: 1.2412 - val_accuracy: 0.5420\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1067 - accuracy: 0.6004 - val_loss: 1.2742 - val_accuracy: 0.5380\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1048 - accuracy: 0.6067 - val_loss: 1.2413 - val_accuracy: 0.5600\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0823 - accuracy: 0.6111 - val_loss: 1.2450 - val_accuracy: 0.5660\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0810 - accuracy: 0.6142 - val_loss: 1.2146 - val_accuracy: 0.5580\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0575 - accuracy: 0.6298 - val_loss: 1.2212 - val_accuracy: 0.5580\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0477 - accuracy: 0.6280 - val_loss: 1.2314 - val_accuracy: 0.5520\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0353 - accuracy: 0.6331 - val_loss: 1.1899 - val_accuracy: 0.5700\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0158 - accuracy: 0.6418 - val_loss: 1.1855 - val_accuracy: 0.5700\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0050 - accuracy: 0.6384 - val_loss: 1.1819 - val_accuracy: 0.5640\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0035 - accuracy: 0.6460 - val_loss: 1.2139 - val_accuracy: 0.5820\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9906 - accuracy: 0.6482 - val_loss: 1.1846 - val_accuracy: 0.5780\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9769 - accuracy: 0.6513 - val_loss: 1.2035 - val_accuracy: 0.5820\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9611 - accuracy: 0.6536 - val_loss: 1.1725 - val_accuracy: 0.5780\n",
            "5000/5000 [==============================] - 4s 849us/step\n",
            "5000/5000 [==============================] - 4s 843us/step\n",
            "5000/5000 [==============================] - 4s 861us/step\n",
            "5000/5000 [==============================] - 4s 850us/step\n",
            "4回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.2929 - accuracy: 0.1180 - val_loss: 2.2536 - val_accuracy: 0.1840\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1459 - accuracy: 0.2209 - val_loss: 2.0140 - val_accuracy: 0.2740\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0071 - accuracy: 0.2662 - val_loss: 1.9578 - val_accuracy: 0.2760\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9123 - accuracy: 0.3047 - val_loss: 1.8722 - val_accuracy: 0.3380\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.8153 - accuracy: 0.3447 - val_loss: 1.7914 - val_accuracy: 0.3640\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.7646 - accuracy: 0.3507 - val_loss: 1.7615 - val_accuracy: 0.3760\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7000 - accuracy: 0.3824 - val_loss: 1.7216 - val_accuracy: 0.3800\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6697 - accuracy: 0.3927 - val_loss: 1.6943 - val_accuracy: 0.3920\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6367 - accuracy: 0.4084 - val_loss: 1.6795 - val_accuracy: 0.3980\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5893 - accuracy: 0.4211 - val_loss: 1.6201 - val_accuracy: 0.4260\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5536 - accuracy: 0.4302 - val_loss: 1.5910 - val_accuracy: 0.4420\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5187 - accuracy: 0.4436 - val_loss: 1.5898 - val_accuracy: 0.4260\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5020 - accuracy: 0.4518 - val_loss: 1.5710 - val_accuracy: 0.4160\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4707 - accuracy: 0.4520 - val_loss: 1.5676 - val_accuracy: 0.4380\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4534 - accuracy: 0.4671 - val_loss: 1.5232 - val_accuracy: 0.4580\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4459 - accuracy: 0.4793 - val_loss: 1.5162 - val_accuracy: 0.4600\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4093 - accuracy: 0.4893 - val_loss: 1.5139 - val_accuracy: 0.4720\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3957 - accuracy: 0.4880 - val_loss: 1.4851 - val_accuracy: 0.4760\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3781 - accuracy: 0.5016 - val_loss: 1.5048 - val_accuracy: 0.4380\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3551 - accuracy: 0.5033 - val_loss: 1.4927 - val_accuracy: 0.4620\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3467 - accuracy: 0.5127 - val_loss: 1.4472 - val_accuracy: 0.4780\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3305 - accuracy: 0.5240 - val_loss: 1.4650 - val_accuracy: 0.4900\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3241 - accuracy: 0.5218 - val_loss: 1.4439 - val_accuracy: 0.4860\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3015 - accuracy: 0.5198 - val_loss: 1.4213 - val_accuracy: 0.4800\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2845 - accuracy: 0.5349 - val_loss: 1.4819 - val_accuracy: 0.4340\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2772 - accuracy: 0.5464 - val_loss: 1.4599 - val_accuracy: 0.4700\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2727 - accuracy: 0.5458 - val_loss: 1.4792 - val_accuracy: 0.4680\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2457 - accuracy: 0.5520 - val_loss: 1.4478 - val_accuracy: 0.4840\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2300 - accuracy: 0.5540 - val_loss: 1.4847 - val_accuracy: 0.4580\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2235 - accuracy: 0.5616 - val_loss: 1.3938 - val_accuracy: 0.4820\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2212 - accuracy: 0.5569 - val_loss: 1.4184 - val_accuracy: 0.4860\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2058 - accuracy: 0.5676 - val_loss: 1.4004 - val_accuracy: 0.5020\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1845 - accuracy: 0.5656 - val_loss: 1.4719 - val_accuracy: 0.4820\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1766 - accuracy: 0.5767 - val_loss: 1.4569 - val_accuracy: 0.4780\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1696 - accuracy: 0.5802 - val_loss: 1.3709 - val_accuracy: 0.4920\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1513 - accuracy: 0.5871 - val_loss: 1.3977 - val_accuracy: 0.4980\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1428 - accuracy: 0.5924 - val_loss: 1.3871 - val_accuracy: 0.4900\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1344 - accuracy: 0.5902 - val_loss: 1.3848 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1196 - accuracy: 0.6011 - val_loss: 1.3666 - val_accuracy: 0.4960\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1192 - accuracy: 0.6022 - val_loss: 1.3935 - val_accuracy: 0.4860\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1013 - accuracy: 0.6078 - val_loss: 1.3586 - val_accuracy: 0.5060\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0804 - accuracy: 0.6196 - val_loss: 1.3676 - val_accuracy: 0.5120\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 20s 4ms/step - loss: 1.0687 - accuracy: 0.6147 - val_loss: 1.3845 - val_accuracy: 0.5060\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0584 - accuracy: 0.6280 - val_loss: 1.3766 - val_accuracy: 0.5120\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0541 - accuracy: 0.6244 - val_loss: 1.3407 - val_accuracy: 0.5140\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0437 - accuracy: 0.6327 - val_loss: 1.3754 - val_accuracy: 0.5200\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0216 - accuracy: 0.6342 - val_loss: 1.4132 - val_accuracy: 0.5020\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0212 - accuracy: 0.6387 - val_loss: 1.3651 - val_accuracy: 0.5380\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0051 - accuracy: 0.6378 - val_loss: 1.3662 - val_accuracy: 0.5200\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9892 - accuracy: 0.6464 - val_loss: 1.3305 - val_accuracy: 0.5260\n",
            "5000/5000 [==============================] - 4s 854us/step\n",
            "5000/5000 [==============================] - 4s 853us/step\n",
            "5000/5000 [==============================] - 4s 850us/step\n",
            "5000/5000 [==============================] - 4s 857us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2877 - accuracy: 0.1227 - val_loss: 2.2539 - val_accuracy: 0.1980\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1109 - accuracy: 0.2236 - val_loss: 1.9687 - val_accuracy: 0.2740\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9048 - accuracy: 0.2956 - val_loss: 1.8088 - val_accuracy: 0.3660\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8121 - accuracy: 0.3284 - val_loss: 1.7130 - val_accuracy: 0.4040\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7394 - accuracy: 0.3536 - val_loss: 1.6856 - val_accuracy: 0.3960\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6953 - accuracy: 0.3731 - val_loss: 1.6143 - val_accuracy: 0.4380\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6553 - accuracy: 0.4013 - val_loss: 1.5896 - val_accuracy: 0.4300\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6214 - accuracy: 0.4031 - val_loss: 1.5662 - val_accuracy: 0.4560\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5946 - accuracy: 0.4044 - val_loss: 1.5285 - val_accuracy: 0.4700\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5559 - accuracy: 0.4207 - val_loss: 1.5156 - val_accuracy: 0.4600\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5288 - accuracy: 0.4324 - val_loss: 1.4891 - val_accuracy: 0.4640\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4843 - accuracy: 0.4464 - val_loss: 1.4683 - val_accuracy: 0.4840\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4663 - accuracy: 0.4662 - val_loss: 1.4915 - val_accuracy: 0.4840\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4477 - accuracy: 0.4678 - val_loss: 1.4084 - val_accuracy: 0.4900\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4323 - accuracy: 0.4762 - val_loss: 1.4054 - val_accuracy: 0.5140\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4157 - accuracy: 0.4851 - val_loss: 1.3992 - val_accuracy: 0.4980\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3990 - accuracy: 0.4880 - val_loss: 1.3839 - val_accuracy: 0.5180\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3842 - accuracy: 0.4862 - val_loss: 1.3832 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3590 - accuracy: 0.5049 - val_loss: 1.3660 - val_accuracy: 0.5020\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3354 - accuracy: 0.5078 - val_loss: 1.3340 - val_accuracy: 0.5180\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3355 - accuracy: 0.5156 - val_loss: 1.3908 - val_accuracy: 0.5120\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3319 - accuracy: 0.5196 - val_loss: 1.3274 - val_accuracy: 0.5140\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2927 - accuracy: 0.5291 - val_loss: 1.3418 - val_accuracy: 0.5060\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2955 - accuracy: 0.5362 - val_loss: 1.3095 - val_accuracy: 0.5300\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2673 - accuracy: 0.5384 - val_loss: 1.3231 - val_accuracy: 0.5380\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2535 - accuracy: 0.5478 - val_loss: 1.3265 - val_accuracy: 0.5180\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2353 - accuracy: 0.5553 - val_loss: 1.2995 - val_accuracy: 0.5120\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2359 - accuracy: 0.5647 - val_loss: 1.2943 - val_accuracy: 0.5300\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 21s 5ms/step - loss: 1.2226 - accuracy: 0.5698 - val_loss: 1.2766 - val_accuracy: 0.5480\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2046 - accuracy: 0.5718 - val_loss: 1.2851 - val_accuracy: 0.5400\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1788 - accuracy: 0.5767 - val_loss: 1.3230 - val_accuracy: 0.5380\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1745 - accuracy: 0.5756 - val_loss: 1.2625 - val_accuracy: 0.5600\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1757 - accuracy: 0.5804 - val_loss: 1.2420 - val_accuracy: 0.5520\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1451 - accuracy: 0.5893 - val_loss: 1.2552 - val_accuracy: 0.5520\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1173 - accuracy: 0.6071 - val_loss: 1.2603 - val_accuracy: 0.5680\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1273 - accuracy: 0.5936 - val_loss: 1.2194 - val_accuracy: 0.5680\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1176 - accuracy: 0.5984 - val_loss: 1.2258 - val_accuracy: 0.5640\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1000 - accuracy: 0.6078 - val_loss: 1.2408 - val_accuracy: 0.5440\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0936 - accuracy: 0.6122 - val_loss: 1.2075 - val_accuracy: 0.5640\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0755 - accuracy: 0.6136 - val_loss: 1.2121 - val_accuracy: 0.5720\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0574 - accuracy: 0.6211 - val_loss: 1.2196 - val_accuracy: 0.5580\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0434 - accuracy: 0.6222 - val_loss: 1.1934 - val_accuracy: 0.5640\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0266 - accuracy: 0.6324 - val_loss: 1.2003 - val_accuracy: 0.5560\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0092 - accuracy: 0.6444 - val_loss: 1.2323 - val_accuracy: 0.5580\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0104 - accuracy: 0.6373 - val_loss: 1.1885 - val_accuracy: 0.5760\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0016 - accuracy: 0.6396 - val_loss: 1.2239 - val_accuracy: 0.5800\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9882 - accuracy: 0.6433 - val_loss: 1.1965 - val_accuracy: 0.5600\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9722 - accuracy: 0.6520 - val_loss: 1.1887 - val_accuracy: 0.5740\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9708 - accuracy: 0.6527 - val_loss: 1.1675 - val_accuracy: 0.5840\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9368 - accuracy: 0.6711 - val_loss: 1.1947 - val_accuracy: 0.5840\n",
            "5000/5000 [==============================] - 4s 866us/step\n",
            "5000/5000 [==============================] - 4s 865us/step\n",
            "5000/5000 [==============================] - 4s 866us/step\n",
            "5000/5000 [==============================] - 4s 861us/step\n",
            "5回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.2799 - accuracy: 0.1376 - val_loss: 2.2099 - val_accuracy: 0.2040\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0699 - accuracy: 0.2360 - val_loss: 2.0077 - val_accuracy: 0.2680\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9221 - accuracy: 0.2904 - val_loss: 1.9112 - val_accuracy: 0.3100\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8495 - accuracy: 0.3116 - val_loss: 1.8291 - val_accuracy: 0.3520\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7874 - accuracy: 0.3458 - val_loss: 1.8244 - val_accuracy: 0.3580\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7334 - accuracy: 0.3689 - val_loss: 1.8029 - val_accuracy: 0.3560\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7026 - accuracy: 0.3780 - val_loss: 1.7589 - val_accuracy: 0.3680\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6698 - accuracy: 0.3882 - val_loss: 1.6901 - val_accuracy: 0.4180\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6367 - accuracy: 0.3982 - val_loss: 1.6662 - val_accuracy: 0.4020\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6205 - accuracy: 0.4056 - val_loss: 1.6431 - val_accuracy: 0.4200\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5760 - accuracy: 0.4184 - val_loss: 1.6336 - val_accuracy: 0.4300\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5459 - accuracy: 0.4304 - val_loss: 1.6546 - val_accuracy: 0.4240\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5246 - accuracy: 0.4382 - val_loss: 1.5894 - val_accuracy: 0.4380\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5121 - accuracy: 0.4447 - val_loss: 1.5728 - val_accuracy: 0.4220\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 20s 5ms/step - loss: 1.4884 - accuracy: 0.4649 - val_loss: 1.5721 - val_accuracy: 0.4500\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4500 - accuracy: 0.4804 - val_loss: 1.5358 - val_accuracy: 0.4600\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4389 - accuracy: 0.4800 - val_loss: 1.5269 - val_accuracy: 0.4640\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4121 - accuracy: 0.4909 - val_loss: 1.5603 - val_accuracy: 0.4380\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4020 - accuracy: 0.4878 - val_loss: 1.5016 - val_accuracy: 0.4780\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3793 - accuracy: 0.4973 - val_loss: 1.4977 - val_accuracy: 0.4900\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3605 - accuracy: 0.5071 - val_loss: 1.4886 - val_accuracy: 0.4720\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3380 - accuracy: 0.5120 - val_loss: 1.5465 - val_accuracy: 0.4600\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3296 - accuracy: 0.5178 - val_loss: 1.4926 - val_accuracy: 0.4880\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3224 - accuracy: 0.5291 - val_loss: 1.4719 - val_accuracy: 0.4820\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3005 - accuracy: 0.5311 - val_loss: 1.4848 - val_accuracy: 0.4700\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2788 - accuracy: 0.5336 - val_loss: 1.4645 - val_accuracy: 0.4780\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2683 - accuracy: 0.5402 - val_loss: 1.4453 - val_accuracy: 0.4740\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2514 - accuracy: 0.5473 - val_loss: 1.4386 - val_accuracy: 0.4860\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2503 - accuracy: 0.5489 - val_loss: 1.4504 - val_accuracy: 0.4860\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2213 - accuracy: 0.5671 - val_loss: 1.4662 - val_accuracy: 0.4900\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2117 - accuracy: 0.5724 - val_loss: 1.4337 - val_accuracy: 0.4960\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1946 - accuracy: 0.5716 - val_loss: 1.4285 - val_accuracy: 0.4860\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1886 - accuracy: 0.5749 - val_loss: 1.3834 - val_accuracy: 0.5020\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1756 - accuracy: 0.5771 - val_loss: 1.3832 - val_accuracy: 0.5040\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1602 - accuracy: 0.5838 - val_loss: 1.4154 - val_accuracy: 0.5100\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1428 - accuracy: 0.5871 - val_loss: 1.3833 - val_accuracy: 0.5060\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1101 - accuracy: 0.6058 - val_loss: 1.4080 - val_accuracy: 0.5060\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1143 - accuracy: 0.6038 - val_loss: 1.3875 - val_accuracy: 0.5200\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1074 - accuracy: 0.6029 - val_loss: 1.3915 - val_accuracy: 0.5100\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0851 - accuracy: 0.6140 - val_loss: 1.4290 - val_accuracy: 0.5100\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0757 - accuracy: 0.6211 - val_loss: 1.3886 - val_accuracy: 0.5240\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0625 - accuracy: 0.6231 - val_loss: 1.3804 - val_accuracy: 0.5320\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0547 - accuracy: 0.6293 - val_loss: 1.3512 - val_accuracy: 0.5320\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0377 - accuracy: 0.6351 - val_loss: 1.3790 - val_accuracy: 0.5240\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0252 - accuracy: 0.6318 - val_loss: 1.3804 - val_accuracy: 0.5220\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0146 - accuracy: 0.6380 - val_loss: 1.3496 - val_accuracy: 0.5180\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9936 - accuracy: 0.6418 - val_loss: 1.3556 - val_accuracy: 0.5380\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0138 - accuracy: 0.6402 - val_loss: 1.3528 - val_accuracy: 0.5420\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9812 - accuracy: 0.6449 - val_loss: 1.3321 - val_accuracy: 0.5240\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9580 - accuracy: 0.6604 - val_loss: 1.3871 - val_accuracy: 0.5280\n",
            "5000/5000 [==============================] - 4s 856us/step\n",
            "5000/5000 [==============================] - 4s 844us/step\n",
            "5000/5000 [==============================] - 4s 856us/step\n",
            "5000/5000 [==============================] - 4s 852us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 20s 5ms/step - loss: 2.2845 - accuracy: 0.1204 - val_loss: 2.2367 - val_accuracy: 0.2200\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.1147 - accuracy: 0.2140 - val_loss: 1.9833 - val_accuracy: 0.3000\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9496 - accuracy: 0.2840 - val_loss: 1.8342 - val_accuracy: 0.3460\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8212 - accuracy: 0.3296 - val_loss: 1.7246 - val_accuracy: 0.4040\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7370 - accuracy: 0.3611 - val_loss: 1.6627 - val_accuracy: 0.4260\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6908 - accuracy: 0.3711 - val_loss: 1.6412 - val_accuracy: 0.4300\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6558 - accuracy: 0.3922 - val_loss: 1.6312 - val_accuracy: 0.4560\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6299 - accuracy: 0.3938 - val_loss: 1.5687 - val_accuracy: 0.4420\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5997 - accuracy: 0.4122 - val_loss: 1.5748 - val_accuracy: 0.4640\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5632 - accuracy: 0.4280 - val_loss: 1.5044 - val_accuracy: 0.4520\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5433 - accuracy: 0.4347 - val_loss: 1.5017 - val_accuracy: 0.4820\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5114 - accuracy: 0.4504 - val_loss: 1.5213 - val_accuracy: 0.4420\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5006 - accuracy: 0.4502 - val_loss: 1.5225 - val_accuracy: 0.4300\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4860 - accuracy: 0.4611 - val_loss: 1.4912 - val_accuracy: 0.4820\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4598 - accuracy: 0.4622 - val_loss: 1.4153 - val_accuracy: 0.5060\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4437 - accuracy: 0.4740 - val_loss: 1.4446 - val_accuracy: 0.4880\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4357 - accuracy: 0.4720 - val_loss: 1.3892 - val_accuracy: 0.5040\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3962 - accuracy: 0.4849 - val_loss: 1.3902 - val_accuracy: 0.5080\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3699 - accuracy: 0.4980 - val_loss: 1.3984 - val_accuracy: 0.5140\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3672 - accuracy: 0.5009 - val_loss: 1.3581 - val_accuracy: 0.5160\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3667 - accuracy: 0.5016 - val_loss: 1.3616 - val_accuracy: 0.5180\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3329 - accuracy: 0.5180 - val_loss: 1.3462 - val_accuracy: 0.5180\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3267 - accuracy: 0.5253 - val_loss: 1.3804 - val_accuracy: 0.5020\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3077 - accuracy: 0.5238 - val_loss: 1.3191 - val_accuracy: 0.5240\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2856 - accuracy: 0.5407 - val_loss: 1.3032 - val_accuracy: 0.5380\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2788 - accuracy: 0.5433 - val_loss: 1.3137 - val_accuracy: 0.5380\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2687 - accuracy: 0.5324 - val_loss: 1.2931 - val_accuracy: 0.5380\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2413 - accuracy: 0.5589 - val_loss: 1.2795 - val_accuracy: 0.5560\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2495 - accuracy: 0.5491 - val_loss: 1.3000 - val_accuracy: 0.5400\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2342 - accuracy: 0.5556 - val_loss: 1.2804 - val_accuracy: 0.5480\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2217 - accuracy: 0.5631 - val_loss: 1.2840 - val_accuracy: 0.5460\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1973 - accuracy: 0.5747 - val_loss: 1.2723 - val_accuracy: 0.5520\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1902 - accuracy: 0.5811 - val_loss: 1.2761 - val_accuracy: 0.5360\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1836 - accuracy: 0.5738 - val_loss: 1.2401 - val_accuracy: 0.5620\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1459 - accuracy: 0.5913 - val_loss: 1.2342 - val_accuracy: 0.5680\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1434 - accuracy: 0.5798 - val_loss: 1.2494 - val_accuracy: 0.5580\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1388 - accuracy: 0.5869 - val_loss: 1.2442 - val_accuracy: 0.5660\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 19s 4ms/step - loss: 1.1267 - accuracy: 0.5913 - val_loss: 1.2401 - val_accuracy: 0.5620\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.1186 - accuracy: 0.5947 - val_loss: 1.2556 - val_accuracy: 0.5720\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1064 - accuracy: 0.6004 - val_loss: 1.2195 - val_accuracy: 0.5780\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0807 - accuracy: 0.6093 - val_loss: 1.2061 - val_accuracy: 0.5720\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0660 - accuracy: 0.6216 - val_loss: 1.2269 - val_accuracy: 0.5740\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0587 - accuracy: 0.6202 - val_loss: 1.2359 - val_accuracy: 0.5580\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0484 - accuracy: 0.6258 - val_loss: 1.2049 - val_accuracy: 0.5940\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0488 - accuracy: 0.6242 - val_loss: 1.2046 - val_accuracy: 0.5960\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0210 - accuracy: 0.6391 - val_loss: 1.1941 - val_accuracy: 0.5700\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0020 - accuracy: 0.6476 - val_loss: 1.1899 - val_accuracy: 0.5900\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9879 - accuracy: 0.6482 - val_loss: 1.1960 - val_accuracy: 0.5940\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9878 - accuracy: 0.6500 - val_loss: 1.1947 - val_accuracy: 0.5860\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9932 - accuracy: 0.6404 - val_loss: 1.1902 - val_accuracy: 0.6000\n",
            "5000/5000 [==============================] - 4s 866us/step\n",
            "5000/5000 [==============================] - 4s 863us/step\n",
            "5000/5000 [==============================] - 4s 875us/step\n",
            "5000/5000 [==============================] - 4s 866us/step\n",
            "6回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.2931 - accuracy: 0.1267 - val_loss: 2.2452 - val_accuracy: 0.2580\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1204 - accuracy: 0.2156 - val_loss: 2.0215 - val_accuracy: 0.2500\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0038 - accuracy: 0.2671 - val_loss: 1.9708 - val_accuracy: 0.2440\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9354 - accuracy: 0.2940 - val_loss: 1.9231 - val_accuracy: 0.2880\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8384 - accuracy: 0.3149 - val_loss: 1.8311 - val_accuracy: 0.3320\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7799 - accuracy: 0.3504 - val_loss: 1.7601 - val_accuracy: 0.3360\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7263 - accuracy: 0.3636 - val_loss: 1.7183 - val_accuracy: 0.3880\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6820 - accuracy: 0.3836 - val_loss: 1.6837 - val_accuracy: 0.3820\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6421 - accuracy: 0.3969 - val_loss: 1.6482 - val_accuracy: 0.3960\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6067 - accuracy: 0.4209 - val_loss: 1.6287 - val_accuracy: 0.4160\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5834 - accuracy: 0.4169 - val_loss: 1.6227 - val_accuracy: 0.4180\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5611 - accuracy: 0.4278 - val_loss: 1.5943 - val_accuracy: 0.4360\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5178 - accuracy: 0.4518 - val_loss: 1.6053 - val_accuracy: 0.4240\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4997 - accuracy: 0.4556 - val_loss: 1.5562 - val_accuracy: 0.4220\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4715 - accuracy: 0.4624 - val_loss: 1.5642 - val_accuracy: 0.4260\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4512 - accuracy: 0.4667 - val_loss: 1.5365 - val_accuracy: 0.4400\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4309 - accuracy: 0.4720 - val_loss: 1.5435 - val_accuracy: 0.4440\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4081 - accuracy: 0.4878 - val_loss: 1.5041 - val_accuracy: 0.4560\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3826 - accuracy: 0.5009 - val_loss: 1.5054 - val_accuracy: 0.4640\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3673 - accuracy: 0.5102 - val_loss: 1.5061 - val_accuracy: 0.4720\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3340 - accuracy: 0.5202 - val_loss: 1.5189 - val_accuracy: 0.4580\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3377 - accuracy: 0.5104 - val_loss: 1.5015 - val_accuracy: 0.4620\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3183 - accuracy: 0.5276 - val_loss: 1.4827 - val_accuracy: 0.4740\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 20s 4ms/step - loss: 1.2998 - accuracy: 0.5338 - val_loss: 1.4676 - val_accuracy: 0.4780\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2795 - accuracy: 0.5391 - val_loss: 1.4682 - val_accuracy: 0.4660\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2682 - accuracy: 0.5404 - val_loss: 1.4783 - val_accuracy: 0.4660\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2504 - accuracy: 0.5562 - val_loss: 1.4590 - val_accuracy: 0.4900\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2421 - accuracy: 0.5556 - val_loss: 1.4517 - val_accuracy: 0.4920\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2204 - accuracy: 0.5609 - val_loss: 1.4731 - val_accuracy: 0.4820\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2101 - accuracy: 0.5598 - val_loss: 1.4187 - val_accuracy: 0.5080\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1926 - accuracy: 0.5782 - val_loss: 1.4407 - val_accuracy: 0.4880\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1787 - accuracy: 0.5769 - val_loss: 1.4393 - val_accuracy: 0.4800\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1727 - accuracy: 0.5809 - val_loss: 1.4265 - val_accuracy: 0.5020\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1601 - accuracy: 0.5811 - val_loss: 1.4467 - val_accuracy: 0.4920\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1331 - accuracy: 0.5940 - val_loss: 1.4236 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1149 - accuracy: 0.6009 - val_loss: 1.4489 - val_accuracy: 0.4820\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1195 - accuracy: 0.6013 - val_loss: 1.3969 - val_accuracy: 0.5320\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1087 - accuracy: 0.5971 - val_loss: 1.4044 - val_accuracy: 0.5160\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0880 - accuracy: 0.6124 - val_loss: 1.4095 - val_accuracy: 0.5180\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0705 - accuracy: 0.6229 - val_loss: 1.3891 - val_accuracy: 0.5360\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0481 - accuracy: 0.6284 - val_loss: 1.3745 - val_accuracy: 0.5340\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0482 - accuracy: 0.6213 - val_loss: 1.3837 - val_accuracy: 0.5260\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0228 - accuracy: 0.6440 - val_loss: 1.3754 - val_accuracy: 0.5260\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9969 - accuracy: 0.6444 - val_loss: 1.3429 - val_accuracy: 0.5480\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9874 - accuracy: 0.6547 - val_loss: 1.4271 - val_accuracy: 0.5320\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0059 - accuracy: 0.6451 - val_loss: 1.3938 - val_accuracy: 0.5180\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9683 - accuracy: 0.6458 - val_loss: 1.3344 - val_accuracy: 0.5320\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9631 - accuracy: 0.6600 - val_loss: 1.3638 - val_accuracy: 0.5360\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9375 - accuracy: 0.6667 - val_loss: 1.3529 - val_accuracy: 0.5420\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9277 - accuracy: 0.6718 - val_loss: 1.3347 - val_accuracy: 0.5580\n",
            "5000/5000 [==============================] - 4s 872us/step\n",
            "5000/5000 [==============================] - 4s 869us/step\n",
            "5000/5000 [==============================] - 4s 864us/step\n",
            "5000/5000 [==============================] - 4s 874us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.3000 - accuracy: 0.1138 - val_loss: 2.2882 - val_accuracy: 0.1060\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1903 - accuracy: 0.1878 - val_loss: 2.0445 - val_accuracy: 0.2820\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0165 - accuracy: 0.2496 - val_loss: 1.9255 - val_accuracy: 0.3020\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8933 - accuracy: 0.3016 - val_loss: 1.7751 - val_accuracy: 0.3580\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7716 - accuracy: 0.3456 - val_loss: 1.6548 - val_accuracy: 0.4440\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7012 - accuracy: 0.3693 - val_loss: 1.6463 - val_accuracy: 0.4380\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6435 - accuracy: 0.3931 - val_loss: 1.5790 - val_accuracy: 0.4220\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6186 - accuracy: 0.4029 - val_loss: 1.6367 - val_accuracy: 0.4480\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5956 - accuracy: 0.4222 - val_loss: 1.5508 - val_accuracy: 0.4640\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 20s 5ms/step - loss: 1.5659 - accuracy: 0.4282 - val_loss: 1.5138 - val_accuracy: 0.4560\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5402 - accuracy: 0.4333 - val_loss: 1.4747 - val_accuracy: 0.4760\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5200 - accuracy: 0.4398 - val_loss: 1.4495 - val_accuracy: 0.4820\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4830 - accuracy: 0.4596 - val_loss: 1.5097 - val_accuracy: 0.4680\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4596 - accuracy: 0.4729 - val_loss: 1.4242 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4465 - accuracy: 0.4693 - val_loss: 1.4220 - val_accuracy: 0.5060\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4179 - accuracy: 0.4793 - val_loss: 1.4452 - val_accuracy: 0.4880\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3913 - accuracy: 0.4931 - val_loss: 1.3845 - val_accuracy: 0.5140\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3836 - accuracy: 0.5027 - val_loss: 1.3570 - val_accuracy: 0.5280\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3672 - accuracy: 0.5044 - val_loss: 1.3686 - val_accuracy: 0.5240\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3448 - accuracy: 0.5193 - val_loss: 1.3781 - val_accuracy: 0.4940\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3259 - accuracy: 0.5251 - val_loss: 1.3893 - val_accuracy: 0.5220\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3053 - accuracy: 0.5256 - val_loss: 1.3601 - val_accuracy: 0.5400\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3055 - accuracy: 0.5220 - val_loss: 1.3254 - val_accuracy: 0.5420\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2873 - accuracy: 0.5362 - val_loss: 1.3026 - val_accuracy: 0.5420\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2744 - accuracy: 0.5489 - val_loss: 1.3578 - val_accuracy: 0.5140\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2523 - accuracy: 0.5491 - val_loss: 1.3428 - val_accuracy: 0.5240\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2328 - accuracy: 0.5598 - val_loss: 1.2703 - val_accuracy: 0.5520\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2122 - accuracy: 0.5678 - val_loss: 1.3116 - val_accuracy: 0.5460\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2020 - accuracy: 0.5676 - val_loss: 1.2707 - val_accuracy: 0.5620\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1945 - accuracy: 0.5656 - val_loss: 1.2834 - val_accuracy: 0.5420\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1697 - accuracy: 0.5869 - val_loss: 1.2880 - val_accuracy: 0.5620\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1603 - accuracy: 0.5800 - val_loss: 1.2800 - val_accuracy: 0.5420\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1624 - accuracy: 0.5842 - val_loss: 1.2580 - val_accuracy: 0.5840\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1412 - accuracy: 0.5922 - val_loss: 1.2541 - val_accuracy: 0.5860\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1167 - accuracy: 0.6049 - val_loss: 1.2460 - val_accuracy: 0.5660\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0960 - accuracy: 0.6153 - val_loss: 1.2670 - val_accuracy: 0.5540\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0916 - accuracy: 0.6120 - val_loss: 1.2319 - val_accuracy: 0.5640\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0900 - accuracy: 0.6242 - val_loss: 1.2591 - val_accuracy: 0.5600\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0652 - accuracy: 0.6249 - val_loss: 1.2308 - val_accuracy: 0.5780\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0523 - accuracy: 0.6258 - val_loss: 1.2167 - val_accuracy: 0.5820\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0504 - accuracy: 0.6284 - val_loss: 1.2873 - val_accuracy: 0.5600\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0188 - accuracy: 0.6353 - val_loss: 1.2316 - val_accuracy: 0.5880\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0070 - accuracy: 0.6449 - val_loss: 1.2303 - val_accuracy: 0.6000\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9946 - accuracy: 0.6442 - val_loss: 1.2081 - val_accuracy: 0.5820\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9743 - accuracy: 0.6491 - val_loss: 1.2009 - val_accuracy: 0.5960\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9640 - accuracy: 0.6589 - val_loss: 1.1907 - val_accuracy: 0.5960\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 21s 5ms/step - loss: 0.9626 - accuracy: 0.6542 - val_loss: 1.2139 - val_accuracy: 0.5880\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9399 - accuracy: 0.6627 - val_loss: 1.2017 - val_accuracy: 0.6080\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9305 - accuracy: 0.6676 - val_loss: 1.2035 - val_accuracy: 0.5940\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9069 - accuracy: 0.6867 - val_loss: 1.1976 - val_accuracy: 0.5940\n",
            "5000/5000 [==============================] - 4s 856us/step\n",
            "5000/5000 [==============================] - 4s 857us/step\n",
            "5000/5000 [==============================] - 4s 859us/step\n",
            "5000/5000 [==============================] - 4s 860us/step\n",
            "7回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.2883 - accuracy: 0.1240 - val_loss: 2.2375 - val_accuracy: 0.1740\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1036 - accuracy: 0.2258 - val_loss: 1.9927 - val_accuracy: 0.2640\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.9416 - accuracy: 0.2922 - val_loss: 1.8776 - val_accuracy: 0.2920\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.8104 - accuracy: 0.3451 - val_loss: 1.8043 - val_accuracy: 0.3580\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7357 - accuracy: 0.3636 - val_loss: 1.7080 - val_accuracy: 0.3780\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6598 - accuracy: 0.3898 - val_loss: 1.6964 - val_accuracy: 0.3940\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6160 - accuracy: 0.4038 - val_loss: 1.6509 - val_accuracy: 0.4060\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5625 - accuracy: 0.4244 - val_loss: 1.6266 - val_accuracy: 0.4100\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5500 - accuracy: 0.4347 - val_loss: 1.5962 - val_accuracy: 0.4160\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5170 - accuracy: 0.4444 - val_loss: 1.6012 - val_accuracy: 0.4180\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4932 - accuracy: 0.4596 - val_loss: 1.5606 - val_accuracy: 0.4340\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4770 - accuracy: 0.4593 - val_loss: 1.5385 - val_accuracy: 0.4380\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4528 - accuracy: 0.4620 - val_loss: 1.5441 - val_accuracy: 0.4200\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4268 - accuracy: 0.4716 - val_loss: 1.5090 - val_accuracy: 0.4520\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4073 - accuracy: 0.4807 - val_loss: 1.5080 - val_accuracy: 0.4520\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3863 - accuracy: 0.5000 - val_loss: 1.5004 - val_accuracy: 0.4720\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3844 - accuracy: 0.4916 - val_loss: 1.4866 - val_accuracy: 0.4560\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3498 - accuracy: 0.5080 - val_loss: 1.4995 - val_accuracy: 0.4760\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3350 - accuracy: 0.5151 - val_loss: 1.4850 - val_accuracy: 0.4600\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3444 - accuracy: 0.5049 - val_loss: 1.4525 - val_accuracy: 0.4880\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3029 - accuracy: 0.5276 - val_loss: 1.4793 - val_accuracy: 0.4760\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2892 - accuracy: 0.5351 - val_loss: 1.4652 - val_accuracy: 0.4740\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2857 - accuracy: 0.5400 - val_loss: 1.4506 - val_accuracy: 0.4740\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2751 - accuracy: 0.5302 - val_loss: 1.4660 - val_accuracy: 0.4860\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2501 - accuracy: 0.5531 - val_loss: 1.4489 - val_accuracy: 0.4840\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2509 - accuracy: 0.5511 - val_loss: 1.4048 - val_accuracy: 0.4840\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2273 - accuracy: 0.5527 - val_loss: 1.4268 - val_accuracy: 0.4920\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2208 - accuracy: 0.5613 - val_loss: 1.3999 - val_accuracy: 0.4760\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2045 - accuracy: 0.5611 - val_loss: 1.3976 - val_accuracy: 0.4780\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2001 - accuracy: 0.5711 - val_loss: 1.4831 - val_accuracy: 0.4720\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1826 - accuracy: 0.5731 - val_loss: 1.4301 - val_accuracy: 0.5080\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 19s 4ms/step - loss: 1.1640 - accuracy: 0.5829 - val_loss: 1.3848 - val_accuracy: 0.5100\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.1557 - accuracy: 0.5838 - val_loss: 1.4006 - val_accuracy: 0.4940\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1499 - accuracy: 0.5769 - val_loss: 1.3999 - val_accuracy: 0.5080\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1336 - accuracy: 0.5884 - val_loss: 1.3533 - val_accuracy: 0.4960\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1072 - accuracy: 0.6007 - val_loss: 1.3929 - val_accuracy: 0.4880\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1012 - accuracy: 0.5991 - val_loss: 1.3714 - val_accuracy: 0.5080\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0988 - accuracy: 0.6113 - val_loss: 1.4595 - val_accuracy: 0.4980\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0731 - accuracy: 0.6151 - val_loss: 1.3742 - val_accuracy: 0.5180\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0627 - accuracy: 0.6100 - val_loss: 1.3514 - val_accuracy: 0.5140\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0504 - accuracy: 0.6211 - val_loss: 1.3682 - val_accuracy: 0.4880\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0156 - accuracy: 0.6362 - val_loss: 1.3376 - val_accuracy: 0.5260\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0158 - accuracy: 0.6313 - val_loss: 1.4569 - val_accuracy: 0.5280\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0157 - accuracy: 0.6404 - val_loss: 1.3735 - val_accuracy: 0.5160\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9985 - accuracy: 0.6369 - val_loss: 1.3523 - val_accuracy: 0.5080\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9937 - accuracy: 0.6433 - val_loss: 1.3405 - val_accuracy: 0.5080\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9648 - accuracy: 0.6549 - val_loss: 1.3339 - val_accuracy: 0.5040\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9563 - accuracy: 0.6556 - val_loss: 1.3714 - val_accuracy: 0.5180\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9486 - accuracy: 0.6562 - val_loss: 1.3526 - val_accuracy: 0.5320\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9243 - accuracy: 0.6747 - val_loss: 1.3705 - val_accuracy: 0.5040\n",
            "5000/5000 [==============================] - 4s 874us/step\n",
            "5000/5000 [==============================] - 4s 879us/step\n",
            "5000/5000 [==============================] - 4s 872us/step\n",
            "5000/5000 [==============================] - 4s 879us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.2934 - accuracy: 0.1169 - val_loss: 2.2769 - val_accuracy: 0.1840\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.1886 - accuracy: 0.1793 - val_loss: 2.0185 - val_accuracy: 0.3140\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.9914 - accuracy: 0.2658 - val_loss: 1.8864 - val_accuracy: 0.3360\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.8996 - accuracy: 0.3058 - val_loss: 1.7905 - val_accuracy: 0.3860\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.8265 - accuracy: 0.3331 - val_loss: 1.7528 - val_accuracy: 0.3900\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7561 - accuracy: 0.3633 - val_loss: 1.6940 - val_accuracy: 0.4040\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7008 - accuracy: 0.3793 - val_loss: 1.6303 - val_accuracy: 0.4180\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6598 - accuracy: 0.3940 - val_loss: 1.6097 - val_accuracy: 0.4200\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6201 - accuracy: 0.4022 - val_loss: 1.5759 - val_accuracy: 0.4140\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6044 - accuracy: 0.4004 - val_loss: 1.5478 - val_accuracy: 0.4620\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5667 - accuracy: 0.4249 - val_loss: 1.5541 - val_accuracy: 0.4520\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5468 - accuracy: 0.4340 - val_loss: 1.5071 - val_accuracy: 0.4320\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5026 - accuracy: 0.4491 - val_loss: 1.4856 - val_accuracy: 0.4720\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4769 - accuracy: 0.4644 - val_loss: 1.4544 - val_accuracy: 0.4740\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4583 - accuracy: 0.4664 - val_loss: 1.4276 - val_accuracy: 0.4760\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4380 - accuracy: 0.4729 - val_loss: 1.4440 - val_accuracy: 0.4840\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.4257 - accuracy: 0.4749 - val_loss: 1.4268 - val_accuracy: 0.4860\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 19s 4ms/step - loss: 1.3950 - accuracy: 0.4889 - val_loss: 1.3842 - val_accuracy: 0.4920\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3808 - accuracy: 0.4978 - val_loss: 1.3776 - val_accuracy: 0.5020\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3537 - accuracy: 0.5127 - val_loss: 1.3636 - val_accuracy: 0.4980\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3589 - accuracy: 0.5062 - val_loss: 1.3397 - val_accuracy: 0.4960\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3302 - accuracy: 0.5158 - val_loss: 1.3385 - val_accuracy: 0.5020\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3085 - accuracy: 0.5253 - val_loss: 1.3096 - val_accuracy: 0.5180\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2906 - accuracy: 0.5387 - val_loss: 1.3252 - val_accuracy: 0.5140\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2737 - accuracy: 0.5407 - val_loss: 1.3201 - val_accuracy: 0.5160\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2473 - accuracy: 0.5544 - val_loss: 1.3025 - val_accuracy: 0.5220\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2425 - accuracy: 0.5504 - val_loss: 1.3538 - val_accuracy: 0.5060\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2337 - accuracy: 0.5607 - val_loss: 1.2685 - val_accuracy: 0.5160\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2268 - accuracy: 0.5604 - val_loss: 1.2878 - val_accuracy: 0.5440\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1840 - accuracy: 0.5707 - val_loss: 1.3023 - val_accuracy: 0.5320\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1864 - accuracy: 0.5724 - val_loss: 1.2598 - val_accuracy: 0.5460\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1607 - accuracy: 0.5822 - val_loss: 1.2551 - val_accuracy: 0.5280\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1544 - accuracy: 0.5898 - val_loss: 1.2245 - val_accuracy: 0.5660\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1458 - accuracy: 0.5953 - val_loss: 1.2393 - val_accuracy: 0.5660\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1176 - accuracy: 0.5982 - val_loss: 1.2422 - val_accuracy: 0.5400\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1156 - accuracy: 0.6053 - val_loss: 1.3035 - val_accuracy: 0.5420\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1063 - accuracy: 0.6102 - val_loss: 1.2073 - val_accuracy: 0.5620\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1020 - accuracy: 0.6120 - val_loss: 1.2010 - val_accuracy: 0.5560\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0752 - accuracy: 0.6122 - val_loss: 1.2026 - val_accuracy: 0.5660\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0808 - accuracy: 0.6124 - val_loss: 1.2030 - val_accuracy: 0.5600\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0637 - accuracy: 0.6233 - val_loss: 1.1893 - val_accuracy: 0.5500\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0441 - accuracy: 0.6360 - val_loss: 1.1948 - val_accuracy: 0.5660\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0271 - accuracy: 0.6324 - val_loss: 1.2004 - val_accuracy: 0.5640\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0172 - accuracy: 0.6389 - val_loss: 1.1685 - val_accuracy: 0.5700\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0019 - accuracy: 0.6393 - val_loss: 1.1916 - val_accuracy: 0.5800\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9891 - accuracy: 0.6464 - val_loss: 1.1627 - val_accuracy: 0.5780\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9841 - accuracy: 0.6436 - val_loss: 1.2312 - val_accuracy: 0.5380\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9732 - accuracy: 0.6540 - val_loss: 1.1923 - val_accuracy: 0.5480\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9560 - accuracy: 0.6593 - val_loss: 1.1554 - val_accuracy: 0.5840\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9469 - accuracy: 0.6662 - val_loss: 1.1706 - val_accuracy: 0.5780\n",
            "5000/5000 [==============================] - 4s 882us/step\n",
            "5000/5000 [==============================] - 4s 882us/step\n",
            "5000/5000 [==============================] - 4s 879us/step\n",
            "5000/5000 [==============================] - 4s 886us/step\n",
            "8回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.2791 - accuracy: 0.1349 - val_loss: 2.1755 - val_accuracy: 0.2220\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 2.0757 - accuracy: 0.2242 - val_loss: 1.9861 - val_accuracy: 0.2860\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 19s 4ms/step - loss: 1.9472 - accuracy: 0.2773 - val_loss: 1.8762 - val_accuracy: 0.3040\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.8336 - accuracy: 0.3231 - val_loss: 1.8689 - val_accuracy: 0.3260\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7640 - accuracy: 0.3458 - val_loss: 1.8556 - val_accuracy: 0.3400\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7090 - accuracy: 0.3751 - val_loss: 1.7111 - val_accuracy: 0.3880\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6812 - accuracy: 0.3802 - val_loss: 1.7023 - val_accuracy: 0.4060\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.6303 - accuracy: 0.3964 - val_loss: 1.6740 - val_accuracy: 0.3880\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6221 - accuracy: 0.3998 - val_loss: 1.6386 - val_accuracy: 0.4160\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5929 - accuracy: 0.4087 - val_loss: 1.6659 - val_accuracy: 0.4100\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5800 - accuracy: 0.4244 - val_loss: 1.6386 - val_accuracy: 0.4260\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5596 - accuracy: 0.4307 - val_loss: 1.6311 - val_accuracy: 0.4060\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5194 - accuracy: 0.4402 - val_loss: 1.5765 - val_accuracy: 0.4300\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5061 - accuracy: 0.4511 - val_loss: 1.5674 - val_accuracy: 0.4440\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4856 - accuracy: 0.4524 - val_loss: 1.5710 - val_accuracy: 0.4240\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4713 - accuracy: 0.4556 - val_loss: 1.6058 - val_accuracy: 0.3960\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4628 - accuracy: 0.4622 - val_loss: 1.5726 - val_accuracy: 0.4420\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4458 - accuracy: 0.4718 - val_loss: 1.5284 - val_accuracy: 0.4580\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4165 - accuracy: 0.4824 - val_loss: 1.5182 - val_accuracy: 0.4500\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3978 - accuracy: 0.4860 - val_loss: 1.6170 - val_accuracy: 0.4140\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3898 - accuracy: 0.4938 - val_loss: 1.6305 - val_accuracy: 0.4100\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3705 - accuracy: 0.5024 - val_loss: 1.5102 - val_accuracy: 0.4400\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3592 - accuracy: 0.5067 - val_loss: 1.5201 - val_accuracy: 0.4600\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3558 - accuracy: 0.5060 - val_loss: 1.5413 - val_accuracy: 0.4660\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3329 - accuracy: 0.5153 - val_loss: 1.4667 - val_accuracy: 0.4640\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3320 - accuracy: 0.5173 - val_loss: 1.5207 - val_accuracy: 0.4540\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3133 - accuracy: 0.5322 - val_loss: 1.4708 - val_accuracy: 0.4640\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2943 - accuracy: 0.5278 - val_loss: 1.4455 - val_accuracy: 0.4780\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2785 - accuracy: 0.5464 - val_loss: 1.5377 - val_accuracy: 0.4420\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2726 - accuracy: 0.5407 - val_loss: 1.4594 - val_accuracy: 0.4740\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2555 - accuracy: 0.5464 - val_loss: 1.4697 - val_accuracy: 0.4780\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2436 - accuracy: 0.5522 - val_loss: 1.5124 - val_accuracy: 0.4400\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2386 - accuracy: 0.5593 - val_loss: 1.4016 - val_accuracy: 0.4880\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2118 - accuracy: 0.5629 - val_loss: 1.4819 - val_accuracy: 0.4540\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1954 - accuracy: 0.5720 - val_loss: 1.4289 - val_accuracy: 0.4920\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1891 - accuracy: 0.5740 - val_loss: 1.4297 - val_accuracy: 0.4800\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1856 - accuracy: 0.5720 - val_loss: 1.4004 - val_accuracy: 0.4900\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1652 - accuracy: 0.5784 - val_loss: 1.4249 - val_accuracy: 0.5100\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 20s 5ms/step - loss: 1.1505 - accuracy: 0.5847 - val_loss: 1.4141 - val_accuracy: 0.4940\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1530 - accuracy: 0.5913 - val_loss: 1.4183 - val_accuracy: 0.4920\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1369 - accuracy: 0.5953 - val_loss: 1.4014 - val_accuracy: 0.4880\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1227 - accuracy: 0.5967 - val_loss: 1.3855 - val_accuracy: 0.5040\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0925 - accuracy: 0.6007 - val_loss: 1.4057 - val_accuracy: 0.5020\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0860 - accuracy: 0.6069 - val_loss: 1.4100 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0729 - accuracy: 0.6162 - val_loss: 1.4548 - val_accuracy: 0.5100\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0736 - accuracy: 0.6169 - val_loss: 1.4141 - val_accuracy: 0.5020\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0659 - accuracy: 0.6222 - val_loss: 1.4459 - val_accuracy: 0.4980\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0345 - accuracy: 0.6251 - val_loss: 1.3756 - val_accuracy: 0.5140\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0301 - accuracy: 0.6262 - val_loss: 1.4035 - val_accuracy: 0.5120\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0216 - accuracy: 0.6433 - val_loss: 1.3697 - val_accuracy: 0.4920\n",
            "5000/5000 [==============================] - 4s 889us/step\n",
            "5000/5000 [==============================] - 4s 878us/step\n",
            "5000/5000 [==============================] - 4s 885us/step\n",
            "5000/5000 [==============================] - 4s 882us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.2855 - accuracy: 0.1120 - val_loss: 2.2518 - val_accuracy: 0.1560\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.1186 - accuracy: 0.2138 - val_loss: 1.9668 - val_accuracy: 0.3240\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.9484 - accuracy: 0.2787 - val_loss: 1.8491 - val_accuracy: 0.2860\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.8333 - accuracy: 0.3367 - val_loss: 1.7300 - val_accuracy: 0.3780\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7667 - accuracy: 0.3447 - val_loss: 1.6933 - val_accuracy: 0.3720\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7278 - accuracy: 0.3689 - val_loss: 1.6595 - val_accuracy: 0.4140\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6866 - accuracy: 0.3807 - val_loss: 1.6277 - val_accuracy: 0.4180\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6530 - accuracy: 0.3880 - val_loss: 1.6052 - val_accuracy: 0.4180\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6307 - accuracy: 0.4044 - val_loss: 1.5951 - val_accuracy: 0.4000\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6038 - accuracy: 0.4131 - val_loss: 1.5613 - val_accuracy: 0.4220\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5860 - accuracy: 0.4184 - val_loss: 1.5387 - val_accuracy: 0.4360\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5408 - accuracy: 0.4382 - val_loss: 1.4982 - val_accuracy: 0.4440\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5296 - accuracy: 0.4422 - val_loss: 1.5069 - val_accuracy: 0.4520\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5081 - accuracy: 0.4442 - val_loss: 1.5057 - val_accuracy: 0.4640\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4858 - accuracy: 0.4558 - val_loss: 1.5026 - val_accuracy: 0.4600\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4574 - accuracy: 0.4629 - val_loss: 1.5342 - val_accuracy: 0.4540\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4287 - accuracy: 0.4760 - val_loss: 1.4701 - val_accuracy: 0.4940\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4173 - accuracy: 0.4856 - val_loss: 1.4146 - val_accuracy: 0.4720\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4083 - accuracy: 0.4793 - val_loss: 1.4319 - val_accuracy: 0.4900\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3842 - accuracy: 0.4978 - val_loss: 1.4359 - val_accuracy: 0.4800\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3697 - accuracy: 0.4987 - val_loss: 1.3790 - val_accuracy: 0.4940\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3432 - accuracy: 0.5144 - val_loss: 1.4082 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3522 - accuracy: 0.5073 - val_loss: 1.3705 - val_accuracy: 0.5140\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.3299 - accuracy: 0.5096 - val_loss: 1.3512 - val_accuracy: 0.5240\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 20s 4ms/step - loss: 1.3073 - accuracy: 0.5256 - val_loss: 1.3634 - val_accuracy: 0.5140\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3091 - accuracy: 0.5349 - val_loss: 1.3349 - val_accuracy: 0.5460\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2830 - accuracy: 0.5400 - val_loss: 1.3304 - val_accuracy: 0.5240\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2765 - accuracy: 0.5384 - val_loss: 1.3321 - val_accuracy: 0.5320\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2521 - accuracy: 0.5589 - val_loss: 1.3112 - val_accuracy: 0.5340\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2460 - accuracy: 0.5487 - val_loss: 1.3257 - val_accuracy: 0.5320\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2497 - accuracy: 0.5456 - val_loss: 1.3102 - val_accuracy: 0.5440\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2355 - accuracy: 0.5578 - val_loss: 1.3033 - val_accuracy: 0.5260\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2131 - accuracy: 0.5627 - val_loss: 1.3073 - val_accuracy: 0.5260\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1993 - accuracy: 0.5744 - val_loss: 1.3038 - val_accuracy: 0.5240\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1808 - accuracy: 0.5758 - val_loss: 1.2793 - val_accuracy: 0.5500\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1869 - accuracy: 0.5716 - val_loss: 1.3012 - val_accuracy: 0.5420\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1611 - accuracy: 0.5771 - val_loss: 1.2958 - val_accuracy: 0.5280\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1501 - accuracy: 0.5902 - val_loss: 1.2862 - val_accuracy: 0.5520\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1432 - accuracy: 0.5947 - val_loss: 1.2588 - val_accuracy: 0.5560\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1342 - accuracy: 0.5929 - val_loss: 1.3080 - val_accuracy: 0.5340\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1317 - accuracy: 0.6047 - val_loss: 1.2677 - val_accuracy: 0.5400\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0920 - accuracy: 0.6024 - val_loss: 1.2579 - val_accuracy: 0.5640\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1005 - accuracy: 0.6060 - val_loss: 1.2633 - val_accuracy: 0.5600\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0906 - accuracy: 0.6060 - val_loss: 1.2742 - val_accuracy: 0.5620\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0793 - accuracy: 0.6171 - val_loss: 1.2317 - val_accuracy: 0.5700\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0680 - accuracy: 0.6113 - val_loss: 1.2464 - val_accuracy: 0.5660\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0531 - accuracy: 0.6158 - val_loss: 1.2346 - val_accuracy: 0.5600\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0519 - accuracy: 0.6242 - val_loss: 1.2029 - val_accuracy: 0.5880\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0223 - accuracy: 0.6436 - val_loss: 1.2272 - val_accuracy: 0.5620\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0211 - accuracy: 0.6380 - val_loss: 1.2388 - val_accuracy: 0.5660\n",
            "5000/5000 [==============================] - 4s 866us/step\n",
            "5000/5000 [==============================] - 4s 858us/step\n",
            "5000/5000 [==============================] - 4s 863us/step\n",
            "5000/5000 [==============================] - 4s 858us/step\n",
            "9回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.2995 - accuracy: 0.1176 - val_loss: 2.2787 - val_accuracy: 0.1960\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.1608 - accuracy: 0.1951 - val_loss: 2.0192 - val_accuracy: 0.2480\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.0010 - accuracy: 0.2613 - val_loss: 1.9507 - val_accuracy: 0.3020\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.8883 - accuracy: 0.3144 - val_loss: 1.8368 - val_accuracy: 0.3260\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.8015 - accuracy: 0.3444 - val_loss: 1.7919 - val_accuracy: 0.3800\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7532 - accuracy: 0.3547 - val_loss: 1.7609 - val_accuracy: 0.3920\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7024 - accuracy: 0.3718 - val_loss: 1.7162 - val_accuracy: 0.3760\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6805 - accuracy: 0.3764 - val_loss: 1.6859 - val_accuracy: 0.4060\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6421 - accuracy: 0.3947 - val_loss: 1.6754 - val_accuracy: 0.3940\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 20s 5ms/step - loss: 1.6273 - accuracy: 0.3998 - val_loss: 1.7122 - val_accuracy: 0.3820\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5987 - accuracy: 0.4091 - val_loss: 1.6362 - val_accuracy: 0.4100\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.5721 - accuracy: 0.4213 - val_loss: 1.6330 - val_accuracy: 0.4120\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5516 - accuracy: 0.4291 - val_loss: 1.5897 - val_accuracy: 0.4320\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5305 - accuracy: 0.4382 - val_loss: 1.5775 - val_accuracy: 0.4300\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5009 - accuracy: 0.4411 - val_loss: 1.5658 - val_accuracy: 0.4700\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4826 - accuracy: 0.4631 - val_loss: 1.5338 - val_accuracy: 0.4500\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4568 - accuracy: 0.4724 - val_loss: 1.5360 - val_accuracy: 0.4540\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.4406 - accuracy: 0.4667 - val_loss: 1.5597 - val_accuracy: 0.4340\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3980 - accuracy: 0.4896 - val_loss: 1.5108 - val_accuracy: 0.4800\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4037 - accuracy: 0.4853 - val_loss: 1.5943 - val_accuracy: 0.4460\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.3813 - accuracy: 0.4989 - val_loss: 1.4920 - val_accuracy: 0.4720\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3772 - accuracy: 0.5076 - val_loss: 1.4717 - val_accuracy: 0.4860\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3421 - accuracy: 0.5093 - val_loss: 1.4954 - val_accuracy: 0.4520\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3260 - accuracy: 0.5176 - val_loss: 1.4899 - val_accuracy: 0.4680\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2947 - accuracy: 0.5300 - val_loss: 1.4728 - val_accuracy: 0.4840\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2906 - accuracy: 0.5269 - val_loss: 1.4592 - val_accuracy: 0.4720\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2792 - accuracy: 0.5331 - val_loss: 1.5031 - val_accuracy: 0.4600\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2610 - accuracy: 0.5471 - val_loss: 1.4406 - val_accuracy: 0.4880\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2441 - accuracy: 0.5520 - val_loss: 1.4229 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2338 - accuracy: 0.5573 - val_loss: 1.3937 - val_accuracy: 0.5060\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2178 - accuracy: 0.5680 - val_loss: 1.4203 - val_accuracy: 0.4940\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2103 - accuracy: 0.5602 - val_loss: 1.4014 - val_accuracy: 0.4940\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1922 - accuracy: 0.5689 - val_loss: 1.4228 - val_accuracy: 0.4920\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1794 - accuracy: 0.5736 - val_loss: 1.3861 - val_accuracy: 0.5100\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1688 - accuracy: 0.5838 - val_loss: 1.4266 - val_accuracy: 0.4960\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1475 - accuracy: 0.5809 - val_loss: 1.3909 - val_accuracy: 0.5260\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1430 - accuracy: 0.5918 - val_loss: 1.3617 - val_accuracy: 0.5160\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1159 - accuracy: 0.6022 - val_loss: 1.3937 - val_accuracy: 0.5140\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1350 - accuracy: 0.5964 - val_loss: 1.3780 - val_accuracy: 0.5120\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0826 - accuracy: 0.6098 - val_loss: 1.3774 - val_accuracy: 0.5180\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0875 - accuracy: 0.6178 - val_loss: 1.3407 - val_accuracy: 0.5080\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0679 - accuracy: 0.6149 - val_loss: 1.3518 - val_accuracy: 0.5260\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0536 - accuracy: 0.6278 - val_loss: 1.3465 - val_accuracy: 0.5280\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0542 - accuracy: 0.6211 - val_loss: 1.3040 - val_accuracy: 0.5460\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0336 - accuracy: 0.6240 - val_loss: 1.3170 - val_accuracy: 0.5280\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.0148 - accuracy: 0.6353 - val_loss: 1.3735 - val_accuracy: 0.5440\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.0174 - accuracy: 0.6304 - val_loss: 1.3332 - val_accuracy: 0.5360\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9936 - accuracy: 0.6489 - val_loss: 1.3609 - val_accuracy: 0.5220\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9705 - accuracy: 0.6467 - val_loss: 1.3614 - val_accuracy: 0.5480\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 0.9743 - accuracy: 0.6456 - val_loss: 1.3548 - val_accuracy: 0.5320\n",
            "5000/5000 [==============================] - 4s 859us/step\n",
            "5000/5000 [==============================] - 4s 851us/step\n",
            "5000/5000 [==============================] - 4s 854us/step\n",
            "5000/5000 [==============================] - 4s 856us/step\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 2.2894 - accuracy: 0.1276 - val_loss: 2.2515 - val_accuracy: 0.1640\n",
            "Epoch 2/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 2.1191 - accuracy: 0.2060 - val_loss: 1.9900 - val_accuracy: 0.2880\n",
            "Epoch 3/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.9659 - accuracy: 0.2811 - val_loss: 1.8561 - val_accuracy: 0.3440\n",
            "Epoch 4/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.8626 - accuracy: 0.3273 - val_loss: 1.7624 - val_accuracy: 0.3580\n",
            "Epoch 5/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7850 - accuracy: 0.3413 - val_loss: 1.7037 - val_accuracy: 0.3900\n",
            "Epoch 6/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.7401 - accuracy: 0.3704 - val_loss: 1.6792 - val_accuracy: 0.4400\n",
            "Epoch 7/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.7084 - accuracy: 0.3756 - val_loss: 1.6475 - val_accuracy: 0.4160\n",
            "Epoch 8/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6653 - accuracy: 0.3960 - val_loss: 1.6219 - val_accuracy: 0.4460\n",
            "Epoch 9/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6425 - accuracy: 0.4067 - val_loss: 1.5939 - val_accuracy: 0.4580\n",
            "Epoch 10/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.6272 - accuracy: 0.4084 - val_loss: 1.5898 - val_accuracy: 0.4500\n",
            "Epoch 11/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5836 - accuracy: 0.4211 - val_loss: 1.5538 - val_accuracy: 0.4720\n",
            "Epoch 12/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5594 - accuracy: 0.4282 - val_loss: 1.5353 - val_accuracy: 0.4800\n",
            "Epoch 13/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5440 - accuracy: 0.4338 - val_loss: 1.5272 - val_accuracy: 0.5100\n",
            "Epoch 14/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.5111 - accuracy: 0.4524 - val_loss: 1.5190 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4848 - accuracy: 0.4560 - val_loss: 1.4927 - val_accuracy: 0.4980\n",
            "Epoch 16/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4740 - accuracy: 0.4618 - val_loss: 1.5007 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4445 - accuracy: 0.4787 - val_loss: 1.4852 - val_accuracy: 0.5180\n",
            "Epoch 18/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.4234 - accuracy: 0.4751 - val_loss: 1.4013 - val_accuracy: 0.5340\n",
            "Epoch 19/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3996 - accuracy: 0.4909 - val_loss: 1.4174 - val_accuracy: 0.5260\n",
            "Epoch 20/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3713 - accuracy: 0.5024 - val_loss: 1.3744 - val_accuracy: 0.5380\n",
            "Epoch 21/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3539 - accuracy: 0.5102 - val_loss: 1.3547 - val_accuracy: 0.5400\n",
            "Epoch 22/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3359 - accuracy: 0.5182 - val_loss: 1.3696 - val_accuracy: 0.5420\n",
            "Epoch 23/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3184 - accuracy: 0.5260 - val_loss: 1.3370 - val_accuracy: 0.5460\n",
            "Epoch 24/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.3167 - accuracy: 0.5344 - val_loss: 1.3330 - val_accuracy: 0.5460\n",
            "Epoch 25/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2978 - accuracy: 0.5213 - val_loss: 1.3215 - val_accuracy: 0.5460\n",
            "Epoch 26/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2894 - accuracy: 0.5322 - val_loss: 1.3553 - val_accuracy: 0.5360\n",
            "Epoch 27/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2731 - accuracy: 0.5407 - val_loss: 1.3078 - val_accuracy: 0.5320\n",
            "Epoch 28/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.2466 - accuracy: 0.5489 - val_loss: 1.2758 - val_accuracy: 0.5500\n",
            "Epoch 29/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2475 - accuracy: 0.5500 - val_loss: 1.3275 - val_accuracy: 0.5480\n",
            "Epoch 30/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2257 - accuracy: 0.5669 - val_loss: 1.2737 - val_accuracy: 0.5420\n",
            "Epoch 31/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.2263 - accuracy: 0.5578 - val_loss: 1.3619 - val_accuracy: 0.5400\n",
            "Epoch 32/50\n",
            "4500/4500 [==============================] - 20s 5ms/step - loss: 1.2036 - accuracy: 0.5644 - val_loss: 1.3037 - val_accuracy: 0.5140\n",
            "Epoch 33/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1771 - accuracy: 0.5771 - val_loss: 1.2569 - val_accuracy: 0.5660\n",
            "Epoch 34/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1733 - accuracy: 0.5751 - val_loss: 1.3007 - val_accuracy: 0.5320\n",
            "Epoch 35/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1657 - accuracy: 0.5876 - val_loss: 1.2444 - val_accuracy: 0.5640\n",
            "Epoch 36/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1420 - accuracy: 0.5929 - val_loss: 1.2223 - val_accuracy: 0.5600\n",
            "Epoch 37/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1283 - accuracy: 0.5964 - val_loss: 1.2055 - val_accuracy: 0.5760\n",
            "Epoch 38/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.1211 - accuracy: 0.5891 - val_loss: 1.2631 - val_accuracy: 0.5460\n",
            "Epoch 39/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.1053 - accuracy: 0.6102 - val_loss: 1.2005 - val_accuracy: 0.5620\n",
            "Epoch 40/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0995 - accuracy: 0.6131 - val_loss: 1.2266 - val_accuracy: 0.5680\n",
            "Epoch 41/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0878 - accuracy: 0.6073 - val_loss: 1.2205 - val_accuracy: 0.5600\n",
            "Epoch 42/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0678 - accuracy: 0.6162 - val_loss: 1.1840 - val_accuracy: 0.5820\n",
            "Epoch 43/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0578 - accuracy: 0.6240 - val_loss: 1.1990 - val_accuracy: 0.5700\n",
            "Epoch 44/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0438 - accuracy: 0.6338 - val_loss: 1.1764 - val_accuracy: 0.5840\n",
            "Epoch 45/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0387 - accuracy: 0.6318 - val_loss: 1.1925 - val_accuracy: 0.5840\n",
            "Epoch 46/50\n",
            "4500/4500 [==============================] - 16s 4ms/step - loss: 1.0182 - accuracy: 0.6387 - val_loss: 1.1817 - val_accuracy: 0.5940\n",
            "Epoch 47/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0018 - accuracy: 0.6389 - val_loss: 1.2122 - val_accuracy: 0.5540\n",
            "Epoch 48/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 1.0004 - accuracy: 0.6364 - val_loss: 1.2013 - val_accuracy: 0.5540\n",
            "Epoch 49/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9756 - accuracy: 0.6513 - val_loss: 1.1488 - val_accuracy: 0.5880\n",
            "Epoch 50/50\n",
            "4500/4500 [==============================] - 17s 4ms/step - loss: 0.9700 - accuracy: 0.6569 - val_loss: 1.1534 - val_accuracy: 0.5840\n",
            "5000/5000 [==============================] - 4s 852us/step\n",
            "5000/5000 [==============================] - 4s 857us/step\n",
            "5000/5000 [==============================] - 4s 852us/step\n",
            "5000/5000 [==============================] - 4s 856us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDnSi6X1fmjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "80daa080-e43d-4b55-a618-e378612c5b78"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "y1=[]\n",
        "y2=[]\n",
        "y3=[]\n",
        "y4=[]\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/ABtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y1.append(line)\n",
        "\n",
        "y1=np.ravel(y1)\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/ABtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y2.append(line)\n",
        "\n",
        "y2=np.ravel(y2)\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/BAtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y3.append(line)\n",
        "\n",
        "y3=np.ravel(y3)\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/BAtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y4.append(line)\n",
        "\n",
        "y4=np.ravel(y4)\n",
        "\n",
        "c1,c2,c3,c4 = \"blue\",\"green\",\"red\",\"black\"   # 各プロットの色\n",
        "l1,l2,l3,l4 = \"AtoB_test\",\"AtoB_train\",\"BtoA_test\",\"BtoA_train\"   # 各ラベル\n",
        "\n",
        "  # x軸ラベル\n",
        "ax.set_xlabel('epochs')\n",
        "ax.set_ylabel('accuracy')  # y軸ラベル\n",
        "ax.set_title('accuracy') # グラフタイトル\n",
        "# ax.set_aspect('equal') # スケールを揃える\n",
        "ax.grid()            # 罫線\n",
        "#ax.set_xlim([0, 5]) # x方向の描画範囲を指定\n",
        "ax.set_ylim([0, 1])    # y方向の描画範囲を指定\n",
        "ax.plot(y1, color=c1, label=l1)\n",
        "ax.plot(y2, color=c2, label=l2)\n",
        "ax.plot(y3, color=c3, label=l3)\n",
        "ax.plot(y4, color=c4, label=l4)\n",
        "ax.legend(loc=0)    # 凡例\n",
        "fig.tight_layout()  # レイアウトの設定\n",
        "plt.savefig(f\"/content/drive/My Drive/googlecolab/cifar10/acc/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.png\") # 画像の保存\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3xcVb3//9cnk/s9TdpSmtCE0pa2tE0gwqEFaeHoFywUFLDgV5CL8hVB5XBUQI+K/PR8+YoeFOWICAoi1gJSLIr0iG0KFbkUWkF6v6RteknbtLk2yWQm6/fHTKaTZNJO2kxnkryffezH7Nmz9t4rq8m8Z629Z29zziEiIpJokuJdARERkUgUUCIikpAUUCIikpAUUCIikpAUUCIikpAUUCIikpAUUCIikpAUUCIikpAUUCKDhAXob1aGDf2yi/STmd1tZpvNrMnM1pjZx8Ne+5yZrQ177czg8hIze97M9plZnZn9NLj8XjP7Tdj6pWbmzCw5+LzKzL5nZn8DDgGnmtmNYfvYYmb/p0f9Ljez1WbWGKznxWZ2tZm906PcnWb2h9i1lMjxSY53BUQGoc3A+cAe4GrgN2Z2GnAecC9wBbASGA90mJkH+COwFLgO8AOV/djfdcAlwHrAgEnApcAW4MPAn83sbefcu2Z2NvBr4Crgr8AYIAfYCvzczCY759aGbfe7x9IAIieCelAi/eSce9Y5t8s51+mcWwhsBM4GPgt83zn3tgvY5JzbFnztZOCrzrkW51ybc25FP3b5hHPuA+eczznX4Zz7k3Nuc3Afy4H/IRCYADcDv3TO/SVYv53OuXXOuXZgIfBpADObCpQSCE6RhKSAEuknM7s+OIRWb2b1wBlAEVBCoHfVUwmwzTnnO8Zd7uix/0vM7A0zOxDc/8eC++/aV6Q6ADwJfMrMjEDv6ZlgcIkkJAWUSD+Y2TjgF8DtQKFzLh/4J4Ghtx0EhvV62gGc0nVcqYcWIDPs+UkRyoRuOWBmacDvgR8Ao4P7fym4/659RaoDzrk3AC+B3tangKci/5QiiUEBJdI/WQQCYx+Amd1IoAcF8BjwFTM7K3jG3WnBQHsL2A3cb2ZZZpZuZrOC66wGPmxmp5hZHnDPUfafCqQF9+8zs0uAj4a9/jhwo5ldZGZJZjbWzE4Pe/3XwE+Bjn4OM4qccAookX5wzq0Bfgj8HagFpgF/C772LPA94LdAE/ACMMI55wcuA04DtgM1wPzgOn8hcGzoPeAdjnJMyDnXBHwJeAY4SKAntDjs9beAG4EHgQZgOTAubBNPEQjU3yCS4Ew3LBQZPswsA9gLnOmc2xjv+ogciXpQIsPLrcDbCicZDGIWUGb2SzPba2b/7ON1M7OHzGyTmb3X9YVGEYkNM6sGvgz8e5yrIhKVWPagngAuPsLrlwATgtMtwM9iWBeRYc85V+qcG+ecWxXvuohEI2YB5Zx7FThwhCKXA78OftnwDSDfzMbEqj4iIjK4xPNSR2Pp/gXEmuCy3T0LmtktBHpZZGRknFVSUnJcO+7s7CQpSYffoqX2ip7aKnpqq/4Zyu21YcOG/c65kT2XD4pr8TnnHgUeBaisrHQrV648ru1VVVUxe/bsAajZ8KD2ip7aKnpqq/4Zyu1lZtsiLY9nHO8kcFmWLsXBZSIiInENqMXA9cGz+f4FaHDO9RreExGR4SlmQ3xmtgCYDRSZWQ3wbSAFwDn3CIHrh30M2ETgPjc3xqouIiIy+MQsoJxz1x7ldQfcFqv9i4jI4DY0TwkREZFBTwElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJSQElIiIJKaYBZWYXm9l6M9tkZndHeP0UM1tmZqvM7D0z+1gs6yMiIoNHzALKzDzAw8AlwBTgWjOb0qPYfwDPOOcqgGuA/45VfUREZHCJZQ/qbGCTc26Lc84L/A64vEcZB+QG5/OAXTGsj4iIDCLmnIvNhs2uAi52zn02+Pw64Bzn3O1hZcYA/wMUAFnAvzrn3omwrVuAWwBGjx591u9+97vjqltzczPZ2dnHtY3hRO0VPbVV9NRW/TOU22vOnDnvOOcqey5PjkdlwlwLPOGc+6GZnQs8ZWZnOOc6wws55x4FHgWorKx0s2fPPq6dVlVVcbzbGE7UXtFTW0VPbdU/w7G9YjnEtxMoCXteHFwW7mbgGQDn3N+BdKAohnUSEZFBIpYB9TYwwczKzCyVwEkQi3uU2Q5cBGBmkwkE1L4Y1klERAaJmAWUc84H3A4sAdYSOFvvAzO7z8zmBYv9O/A5M/sHsAC4wcXqoJiIiAwqMT0G5Zx7CXipx7Jvhc2vAWbFsg4iIjI46UoSIiKSkOJ9Fp+IDFG+Th+7mnaxvWE72xu2U32gmg82fMD6teup2VzDwd0HycjJICs/i+z8bPIK8hhROILCwkJGjRzFyMKRFGQUkJeeR25aLnlpwcf0PPLS8shJyyE5SW9hQ5n+d0XkmDS0NYTCJzQ1BoJoy5Yt1FbX4mpd4LSnfcB+wHd4/ZSsFJram2jwNUTegQEZQGbfU1puWiDcRuRRMKKAgrwC8jPyyU09HGThodY13xV4eel5ZCRnYGYxbCk5VgooEenF1+ljZ+POiAHUNd/Y2ggHCAWQ7TdS6lLoqO3A+Q6f6zRyzEgmTZnEmdPPZMa0GUydOpXJkyfz7rvvcsEFF9DS0sL+/fu7Tfv27WPP3j3s3rub2r217N+/nwMHDlC/vZ6m+ib8Pj8A7cF/ddQBYB7Dk+WBLHAZDn+6/4gBRyZ40jzdQuuUvFP42ISPcenESynOLT6RzS49KKBEhhnnHA3tEXo/YdPOpp10dn1fvhM4ANkN2eQ05JC0P4nUPakk1yTj8x7uEpWcUsLU6VOZMmUKU6cGHidPnkxubm7kigBmRnZ2NtnZ2ZSWlkZd/8bGxl6h1te0r3ofBw8cpLOzM+L2LNXw5nppyGmgOauZzdmbeXHMi9xaeitnnn4ml028jHmT5lFxUoV6WieYAioOOjs72b9/Pzt37mTnzp3U1NSwa9cusrKyKC4uDk1jx44lPT093tVNGIcOHWLnzp3s2rWLgwcPkpKSQkpKCqmpqb3mIy3rmk9OTh7ybzTtvnY2HdjE+rr1bKjbQHV9dbcAavI2dSufkpRCcXYxI9tHMr5+POP3jufQrkPs27aPnVt34m330hz8N27cOKZPmc7UTxwOo8mTJ5OTk3NCfjYzIy8vj7y8PMaPHx/VOp2dndTX10cVaOvWrYM3AuutGb2Gd4vf5Tul3+GkaSdxxVlXcNmky7iw7ELSk/W3GWvDLqBu+sNNLNuwjOl7pjO+YDzjC8ZzasGpjB8xntL8UlI9qce1fa/Xy+7du6mpqekWQOGPu3btwuv1dlvPzIj0FbCioqJuoRVpysrKOq4699Ta0Ro4qF1fTW1LLfsO7mN8w3jG5o4lyQb+xE+fz8eePXvYtWtXqH0iPTY09HGs4hh0BVZ/Au5Iodf1uHv3bl5//XXS09OPaUpLS8Pj8UT1Mzjn2N28m/X717O+bv3hx7r1VNdXH+4BAUWZRZySdwoTCicw55Q5ZDZl4q/107SzidqttWzZsIX169ez1bs1tM64ceOYOnUqV156JVOnTmXq1KmcfvrpJyyIBlJSUhIjRoxgxIgRTJw48YhlOzs7ee+991i6dCnLli1j+avLaXqniT2/38PPR/2cR8Y9QtppaVx04UVcedaVzJ0wl9HZo0/QT5I4Dhw4wOrVq5k8eTJjxoyJyT5idrHYWKmsrHQrV6485vV//MaPeWblMzQkNbDl4BZafa2h15IsiZLcEsaPCAuugvGh50kdSUcMnp07d1JbW9trnxkZGYwdOzbUK+p6DJ8fPXo0ra2toe31NdXV1fXafn5+/lFDLDc3N9RraPY2s61+G9satlFdX822+m1UN1SH5mtbev8MABnJGZw24jQmFE5g4oiJgcfCiUwYMYFRWaN69Uqccxw4cOCowVNbW9srnD0eD2PGjOHkk09m7NixvR4LCgrw+/14vV46Ojro6OiI+7zX66W9vT3iB43+SElJ6RValmJ0ejrxJflot3ZaXSstnS34knyBj5nJkJyaTGFuISPzRjImfwwnF5zMKYWnUJxfTO3OWtasWcMHH3zA+vXru31AKi0tDQ3JhQ/NxfrCpIPl2nI+n49Vq1axbNkyXvnrK7y24jXaDrUFXhwNlMHEyonMv2Q+n6z8JFNHTo1JDz1e7eWco6amhlWrVrFq1SpWr17NqlWr2LZtGwCPPfYYN99883Htw8wiXix22AUUHP6Pds6xp3kPG+s2snrzat7f9D4bqjewfcd29u7ey6G6Q9AENAYnb+9t5ebnMrZ4LONKxlFSXNIreIqLi8nPzx+wX9hoQixSSCanJ5Ocn4w/209HdkfgJifBKTk/mVNKTqHs5DLK8ssozS9lXP44SvNLGZU1ij+++kcySzLZWLeRDQc2sLFuI5tqN+Fv8AfapwnSWtPIa88jvTUd1+RoO9BGw/4GvO29G62wsDBi6Jx88smh+ZEjR0bdk0gky5Yt47zzzqOtre2IU2tra6/ne+r3sPPgTvbU72Fvw17qGus42HyQlkMtgbPfglMqqaS5NJL9yZjfwAc+rw9vu5e2trY+61ZWVtYthLp6RPG6QvZgCaieOjo6ePvtt1m6dCkvLnmRd996N3AszoCTIG9yHhdccAE3X3EzF0+9+LhHZbqciPby+/1s2LAhFEJdU9cHYzNjwoQJVFRUUFFRQXl5OWeffTYFBQXHtd++AmrYDfEtWLCA559/np/97Gfdhtw6Ojq6lfN4PIw9aSwjRo8ga3wWnjwPvmwfLekt7E/eT62nFpftaExppJFGtiZvpSy/jPEjxnOw4CCtBa10pneS6k8l059JWnLagNQ/PT2dgpMLaMxqJHN0Jmnj0/DUe6ABfPU+2hvaoZluwZrckkxOWw6pLam4Rkfbzjaa3mvCdQY+nPjwsYUt7Erfxbbibd16XiNHjuTdd98lJSUl1Fa1O2vx1/u71auddvan7icpLwlfpg9GAOOAHMgpymFcyTgmlU1i2qnTmHryVCaMmMBpI04jK3VghyfjzcxCQ3+RhsIa2xtZv389tXW1h4fkDq1nY/NGWmkN3HimAHJSc5hUNIkLCi9gUuEkJhVNYlLhJCYUTiAzJbPP/Tvn8Hq93cKvvb2dsWPHDvhQ8HCVkpLCzJkzmTlzJv/xH/9Be3s7b7zxBotfXsyL//Mim1/dzOKli1l872I8xR4mVk7k8osv57Yrb6O4MHHOCmxra+Of//xntyB67733OHToEACpqamcccYZXHHFFZSXl1NRUcGMGTNO6AeaYdeD+sQnPsGf//xnSkpKIg61hQ+5HekTfIe/g20N29h8YDNbDm5h88HNgelA4PFQx6FQWcMozi0ODRWGDxueWnAqBRmHP30459h3aN/hobf66tBQXNd8s7e5W12yU7MpzS8N9HzyxnV/zB/HyMyRvXpwXcd9jtQT27lzJz6fj6SkpG69m74eu4YR23xtbDm4JdDjqtvAhroNbDwQmN/dvLtbPcbmjA0NE04sPDxseGrBqQP2yfNEqqqq4rwPn0d1fXXEY0N7mveEyiZZEmX5ZaHwCQ+ik7JPGvIncgzWHtTRHDp0iKWvLuXJF57k1apX2btxb+BMSA/kjc/j7Fln85krPsNV/+sq0tKi/+B6PO1VX1/fq1e0du1a/P7AB83c3FzKy8tDQVRRUcHkyZNJTT38N+icY/+h/exo3EFNY01ounrK1VSMqTimenXREF9QW1sbf//735kzZ84A1qo75xy1LbWB4AoGVnh47W3Z2618QXoBpxacSktHC9vqt3U7LgaQn54fMXy6AqggvSAmb2ZdZz6tWrWKiy66aEC22dTexKYDm0KBFXqs20hd6+Hja0mWRGl+6eHgCguwcXnj8CT1/vDgnMPv/HT4O/D6vQM+dXQefbubajexq20XHZ2He+QjMkZ0C5+u+fEF4wesZz0YDdWA6qmxqZFfvvBLnvnTM6z++2pad7SCA0sxSqaW8JGLPsL1V1zPueecS0pKSp/biaa9nHPs2rWrWxCtXr2arVsPn/wyZsyY0PBcVxiNKx1HXWtdKHR6htCOxh3sbNxJu7+92/5SklJ4fN7jXDfjuuNqIwVUmHj/YTR7m7uH14HNbK3fGuoJhfd+xuWNIy89L251hRPXXgdaD4R6XT0DLLzXmOpJZXTWaHydvl4B4YjN73NKUgqpntQjTimeFOyQMWvSrMNhVDSJokzd4iySeP8dxst7297j4ece5uW/vMz2f2yHYKc6OT2ZqWdN5eOXfJxLPnIJZ555JsnJh4/C9Gyvzs5ONm7c2OvkhX37Dt+xaMKECcwon8GEKRM4acJJ5JySQ3Nqc68Q2tm0E6+/+/HilKQUinOLKc4tpiSvhOKcsPng8lFZowbkzF4FVJjh+odxrOLdXqGTWcJ6W3ta9pCadOTA6Bke0ZbttW5SStQ91Hi31WCitgock3xu5XP8evGveWPFG7RvbA/dES89K52Z581k7kfnMmfOHN566y2Sk5NDgfSPf/yDlpYWAJJTkik5rYRR40eRdUoWNsZoGdHCbu9udjV179FD4ENecW4xJbmHwyZ8vji3mJFZI2PytZJIdJKEDFpmxpicMYzJGcOHx3043tURGTC5abncNOsmbpp1E75OH3/f8Xd+9+bvWPTnRex+fzdLVy5l6ZKl3dZJzkgmszgTO9NIKkyic3QnvpE+tiZvZStbSfOkBXo5WcWcP+b8XsFTkltCUWbRoDjGqYASEUkAyUnJnD/ufM4fdz4Pf/JhNtZt5MUNL/LsG8/y5utv4syRWpzKKeNOoSS/pNuwW/jQW2FG4aAIn2gooEREEtCEwgncee6d3HnunTTc2kDVa1XM+9d5QyZ8oqEbFoqIJLi89DzyUvKGVTiBAkpERBKUAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBKSAkpERBJSTAPKzC42s/VmtsnM7u6jzCfNbI2ZfWBmv41lfUREZPBIjtWGzcwDPAx8BKgB3jazxc65NWFlJgD3ALOccwfNbFSs6iMiIoNLLHtQZwObnHNbnHNe4HfA5T3KfA542Dl3EMA5tzeG9RERkUEkZj0oYCywI+x5DXBOjzITAczsb4AHuNc593LPDZnZLcAtAKNHj6aqquq4Ktbc3Hzc2xhO1F7RU1tFT23VP8OxvWIZUNHufwIwGygGXjWzac65+vBCzrlHgUcBKisr3ezZs49rp1VVVRzvNoYTtVf01FbRU1v1z3Bsr6iG+MzseTOba2b9GRLcCZSEPS8OLgtXAyx2znU457YCGwgEloiIDHPRBs5/A58CNprZ/WY2KYp13gYmmFmZmaUC1wCLe5R5gUDvCTMrIjDktyXKOomIyBAWVUA5515xzv1v4EygGnjFzF43sxvNLKWPdXzA7cASYC3wjHPuAzO7z8zmBYstAerMbA2wDPiqc67u+H4kEREZCqI+BmVmhcCngeuAVcDTwHnAZwj2gnpyzr0EvNRj2bfC5h1wZ3ASEREJiSqgzGwRMAl4CrjMObc7+NJCM1sZq8pJbDkHLS3Q2Nj31NICe/aczK5dMGJEYCooCDzm54PHE++fQhKVc9DcDHv3Qm3t4ceu+Q0bTmfRIhg1CkaPDkzh8xkZ8f4JhjafD9raoLU18His85/+NJx9dmzqGG0P6iHn3LJILzjnKgewPhIFvx+amo4cLNFMTU3Q2RnNHif2+Upe3uHACg+vIy0rKICsLDAbsCaRE6SzEw4c6B44PYMn/LG1NfJ2CgogLS2PN98M/C5Gkp3dO7S65nsuy88fGr9PnZ2BUA//G+2af+ed0WzcePyB0jXv80VXJw8+SthBGVtD00S2cpptoZStbEz6KZx9VUzaI9qAmmJmq7pO/zazAuBa59x/x6RWMbR/P9TWplFdHfhlCJ/8/t7Ljjb1d52+yvv9cOhQdMHS0hLdz5qdDbm53acxY3ovO9KUmQkvv/w3Jk+excGDgTenrsfw+a7HmprDzzs6+q5bSkr/Aq3rtfz8wLoycLxe2Lev75AJn9+3L/C72pPHAyNHHg6NiRP7DpeRIyE1Faqq3mT27Nm0th7ef6R91tbCpk3wt78F/n6d673/1NTA9vsKsPDHoiJIHsAv2DgXeOOPFCrRzIc/b24+0p4m91qSkgLp6YHeZnp67/kRIyIv7zaf7iho30Nh41ZGNGwl78BWcvZvJWvvVtL3bCW1dgcW9p/uPB4oKcHKyqBsLqPnjx24xuzBXKT/7Z6FzFY758p7LFvlnKuIWc36UFlZ6VauPPZRxcsugz/+cQArNMCSkvoXIH1N2dkDN/x2LN+/6Bo+jBRi3R7rHPV1fpoO+mg60EFTvY/Wxg6S8ZFC98eu+bxMHzkZPjxJDo91kmQOT5IjyQJT17Ku5Ub3ckbksuHLwsv0tSyJwLpmjqTgaw3NzWSPGIk/ORXnSaEzORW/J5XO5MDkUnrPu5QeU3IKSclJJCUR1eTxHPl1s0B79xU8Bw9G/j9MTz/8Jh96gx/lGDPSx+gCLyeN8DIyz8uovHbyM70k+byBtGtvDzx6j/x889q1jC8tDXyU9/sDU/h8z+c+H50+P+2H/LS1+PG2+Ghv9eM95KejzUdHmx9fe2DqbPfh7/CT5Pwk48ODPzQl4yM1yU+Kx09qko+UJD/J5icZPx58uOQUWrOKaEkvpCm1iIbkQg4kFVFnReztLGRPRxG7O4qoaS1kW0sRNc35+DqPfr6Zx3P47zMnp//z//znm1xwwTndwiXqv/GDB2Hr1shTdXWgSxXupJOgrCzyVFIysAkPmNk7kUbjot2Lx8wseFJD13X2UgeygifKF78IkyevY8qU04/5D/6Y1zFHkr8DT2dwcj6S/B0k+Tswv4/MVB8ZqX6s09/9j/RoU6sfmv2wI8JrXd2z45gmbt8OTz0VeLPo6DjyY3DefD6yOzrI9vk45Wjr9Neh4DSEdZCMl9R+TR2khObbeiz34KcALyWpXvLSveSktZOd6iUr10vmCC8ZSe2kJXlJw0sKXlL87ZjPi3m9sMULa8NCJooPtdEYH2lhcnLgj8njiTif5PGQ4fGQ0fO1PA+M6F7WedLwkUy7z0O7z0Nbh4e2jmRavR4avR4OtSfT0uahpd1Dc6uH1o5ARKXQQWFjHUXsp4jNnGJvUeH2k4Y34s/RaUm0ZY2gPbuIjrwi/AWFUFiEjSzCM7qQ1DFFpBcXkTqmEBtZFOjC5ecH3hT64eDBVoqL+3ixtTUQNJECaMsWaGjoXj4/PxA2U6bA3LndA6i0NGEOAEYbUC8TOCHi58Hn/ye4bND5aNtiTm1+mdNqxwXeILumrjfMY30eTZnoDvjEh9nhP/geU6FzgbG+lJTAH39y8uH58MfwMkcr298yPct2fSIw6z5Fu6w/ZfuxzddXrGBmZWX3HoPXG/j/77kswuTaA1NSu5c0r5fUtsPL8XpxEddrDASJ1wu+jsB8hxcLm/B4sPQ0LDU1MB6WmgppaYfnU1MhLbvH856vD+zz1958k/PnzDn8u9bPN+yj/koDKcEpO4ryra2BHuWhQ4d7LllZwWp1nfFRVxcYZ9y/PzSftH8/mXV1ZIaWb4XVbwfmvZFDjaSkwPhbUREUFnZ/jDRfWEj67t2wdGnkENqzp/v209MDQVNWBueeC6ee2j2E8vOPp2lPmGgD6i4CoXRr8PlfgMdiUqNY+8UvOK3nGF/PN8Ku6UjPU1MPvyFHU/5oz7vefPsIiZhPRzjC/PdheImVY+UtKgq8MRwjC07Dgb9rrCpBZGTAuHF9vGgWGGfLyYn+/7drnLtHoEWc37oV3j5yqP1L+JPgcSDKyuBjH+s9DHfSSUPirJGoAso51wn8LDgNbr/9La+9+irnX3jh4VAYAv+RIpJgzAIHg7Oz+x9qEcJs3Y4dnH7JJTE7DpSIov0e1ATg/wJTgNBHHufcqTGqV+zk5ODPykqYMVYRkZDwUOvRndtTVcXpw2wkI9pB318R6D35gDnAr4HfxKpSIiIi0QZUhnPurwROS9/mnLsXmBu7aomIyHAX7SBme/BWGxvN7HYCt82I5sQYERGRYxJtD+rLQCbwJeAsAheN/UysKiUiInLUHlTwS7nznXNfAZqBG2NeKxERGfaO2oNyzvkJ3FZDRETkhIn2GNQqM1sMPAuELlXqnHs+JrUSEZFhL9qASgfqgAvDljlAASUiIjER7ZUkdNxJREROqGivJPErAj2mbpxzNw14jURERIh+iC/86qrpwMeBXQNfHRERkYBoh/h+H/7czBYAK2JSIxEREaL/om5PE4BRA1kRERGRcNEeg2qi+zGoPQTuESUiIhIT0Q7x5cS6IiIiIuGiGuIzs4+bWV7Y83wzuyJ21RIRkeEu2mNQ33bONXQ9cc7VA9+OTZVERESiD6hI5Yb+/YZFRCRuog2olWb2X2Y2Pjj9F/BOLCsmIiLDW7QB9UXACywEfge0AbfFqlIiIiLRnsXXAtwd47qIiIiERHsW31/MLD/seYGZLYldtUREZLiLdoivKHjmHgDOuYPoShIiIhJD0QZUp5md0vXEzEqJcHVzERGRgRLtqeLfAFaY2XLAgPOBW2JWKxERGfaiPUniZTOrJBBKq4AXgNZYVkxERIa3aE+S+CzwV+Dfga8ATwH3RrHexWa23sw2mVmfZwGa2ZVm5oIhKCIiEvUxqC8DHwK2OefmABVA/ZFWMDMP8DBwCTAFuNbMpkQolxPc/pv9qLeIiAxx0QZUm3OuDcDM0l4RkvoAABX0SURBVJxz64BJR1nnbGCTc26Lc85L4Au+l0co9/8B/4/Al39FRESA6E+SqAl+D+oF4C9mdhDYdpR1xgI7wrcBnBNewMzOBEqcc38ys6/2tSEzu4XgSRmjR4+mqqoqympH1tzcfNzbGE7UXtFTW0VPbdU/w7G9oj1J4uPB2XvNbBmQB7x8PDs2syTgv4Abotj/o8CjAJWVlW727NnHs2uqqqo43m0MJ2qv6Kmtoqe26p/h2F79viK5c255lEV3AiVhz4uDy7rkAGcAVWYGcBKw2MzmOedW9rdeIiIytER7DOpYvA1MMLMyM0sFrgEWd73onGtwzhU550qdc6XAG4DCSUREgBgGlHPOB9wOLAHWAs845z4ws/vMbF6s9isiIkNDTG866Jx7CXipx7Jv9VF2dizrIiIig0ssh/hERESOmQJKREQSkgJKREQSkgJKREQSkgJKREQSkgJKREQSkgJKREQSkgJKREQSkgJKREQSkgJKREQSUkwvdXSidHR0UFNTQ1tbdPc8zMvLY+3atTGu1dCQnp5O8GrzIiIn1JAIqJqaGnJycigtLY3qzbSpqYmcnJwTULPBzTlHXV0dWVlZ8a6KiAxDQ2KIr62tjcLCQn3SH2BmRmFhIR6PJ95VEZFhaEgEFKBwihG1q4jEy5AJKBERGVoUUCIikpAUUAPohRdewMxYt24dAKtXr+all146ylrwxBNPMHLkSMrLy5k6dSpXXXUVhw4dOuJ+1qxZc0x1jLZOIiLxpoAaQAsWLOC8885jwYIFQP/CYP78+axevZoPPviA1NRUFi5c2GdZBZSIDAdD4jTzcHfcAatXH7mM359Bf05MKy+HH/3oyGWam5tZsWIFy5Yt47LLLuMb3/gG3/rWt2htbWXFihXcc889fOQjH+Gmm25iy5YtZGZm8uijjzJ9+vRu2/H5fLS0tFBQUBBxP6+//jqLFy9m+fLlfPe73+X3v/89ALfddhv79u0jMzOTX/ziF5x++uk8++yzfOc738Hj8ZCXl8crr7zSq07z58+PviFERE6gIRdQ8fKHP/yBiy++mIkTJ1JYWMj777/Pfffdx8qVK/npT38KwBe/+EUqKip44YUXWLp0Kddffz2rg2m6cOFCVqxYwe7du5k4cSKXXXZZxP3MnDmTefPmcemll3LVVVcBcNFFF/HII48wYcIE3nzzTb7whS+wdOlS7rvvPpYsWcLYsWOpr68nNTW1V51ERBLVkAuoo/V0AJqaWgf8i7oLFizgy1/+MgDXXHMNCxYs4IwzzuhWZsWKFaEez4UXXkhdXR2NjY1AYIjvpz/9Kc45brvtNh544AHuvvvuo+63ubmZ119/nauvvjq0rL29HYBZs2Zxww038MlPfpJPfOITA/JzioicKEMuoOLhwIEDLF26lPfffx8zw+/3Y2ZMnTq139syMy677DJ+8pOfRBVQnZ2d5Ofnh3pi4R555BHefPNN/vSnP3HWWWfxzjvv9Ls+IiLxopMkBsBzzz3Hddddx7Zt26iurmbHjh2UlZWxfft2mpqaQuXOP/98nn76aQCqqqooKioiNze31/ZWrFjB+PHj+9xfTk5OaLu5ubmUlZXx7LPPAoHLE/3jH/8AYPPmzZxzzjncd999jBw5kh07dnRbV0QkkSmgBsCCBQv4+Mc/3m3ZlVdeyZ49e1izZg3l5eUsXLiQe++9l3feeYfp06dz99138+STT4bKL1y4kPLycqZPn86qVav45je/2ef+rrnmGh544AEqKirYvHkzTz/9NI8//jgzZsxg6tSp/OEPfwDgq1/9KtOmTeOMM85g5syZzJgxgzlz5nSrk4hIojLnXLzr0C+VlZVu5cqV3ZatXbuWyZMnR70NXSy2f1atWkVFRUW8qzEoVFVVMXv27HhXY1BQW/XPUG4vM3vHOVfZc7l6UCIikpB0kkQC+973vhc6ttTl6quv5hvf+EacaiQicuIooBLYN77xDYWRiAxbGuITEZGEpIASEZGEpIASEZGEpIASEZGEpIAaQIl+P6jFixdz//3393s9EZF4UEANoES4H5TP5+tzvXnz5kV1fT8RkUQw5E4zv+PlO1i958g3hPL7/Xj6cUOo8pPK+dHFR75MejzvB3XzzTdTXl7OihUruPbaa5k4cSLf/e538Xq9FBYW8vTTTzN69GieeOKJ0K02brjhBnJzc1m5ciV79uzh+9//fuj2HSIiiSCmAWVmFwM/BjzAY865+3u8fifwWcAH7ANucs5ti2WdYiWe94MC8Hq9dF0C6uDBg7zxxhuYGY899hjf//73+eEPf9hrW7t372bFihWsW7eOefPmKaBEJKHELKDMzAM8DHwEqAHeNrPFzrnwsalVQKVz7pCZ3Qp8HziuW7weracDsbkWX7zuB9Ul/M64NTU1zJ8/n927d+P1eikrK4u4zhVXXEFSUhJTpkyhtra2Xz+viEisxfIY1NnAJufcFuecF/gdcHl4AefcMudc19kAbwDFMaxPzHTdD+qzn/0spaWlPPDAAzzzzDMcy4V4u+4H9eqrr/ZrvaysrND8F7/4RW6//Xbef/99fv7zn9PW1hZxnbS0tND8YLtosIgMfbEc4hsL7Ah7XgOcc4TyNwN/jvSCmd0C3AIwevRoqqqqur2el5fXr3sc+f3+Ab0n0m9+8xuuueYafvzjH4eWXXLJJWzcuJEDBw6E9nXOOefwy1/+krvuuovXXnuNESNGYGa0tbXh9XpD5ZYuXUpJSUmfdUxLS2Pfvn2h1/1+Py0tLaHnBw8eJD8/n6amJh577LHQzxu+n46ODlpbW7vto6/9Oed6tblE1tzcrLaKktqqf4ZjeyXESRJm9mmgErgg0uvOuUeBRyFwu42el5xfu3Ztv4bsBnqIb9GiRdx1113dtvnJT36StWvXsnHjRs4//3zuuece/vM//5ObbrqJWbNmkZmZyVNPPUVOTg7p6eksWrSIt956i87OToqLi3niiSf6rOP111/P5z73OR599FGee+45PB4PWVlZofL33XcfN9xwAwUFBVx44YXU1NSE9pOamkpOTg4pKSlkZGR020df+zOzIXuZ/4E2lG+JMNDUVv0zHNsrZveDMrNzgXudc/8r+PweAOfc/+1R7l+BnwAXOOf2Hm27uh/Uiaf7QUVvOL6JHCu1Vf8M5faKx/2g3gYmmFmZmaUC1wCLe1SqAvg5MC+acBIRkeEjZkN8zjmfmd0OLCFwmvkvnXMfmNl9wErn3GLgASAbeNbMALY75+bFqk6Dje4HJSLDWUyPQTnnXgJe6rHsW2Hz/xrL/Q92uh+UiAxnutSRiIgkJAWUiIgkJAWUiIgkJAWUiIgkJAXUAPF4PJSXlzNjxgzOPPNMXn/9dQCqq6v57W9/G/V27rjjDsaOHUtnZ+cRy1VVVYX20V/9rZOISDwkxJUkBtQdd8DqI99uI8Pvh37cboPycvjRkS9Cm5GREboy+ZIlS7jnnntYvnx5KAw+9alPHXU3nZ2dLFq0iJKSEpYvX86cOXP6LFtVVUV2djYzZ86M/ucI6k+dRETiRT2oGGhsbAzdz+nuu+/mtddeo7y8nAcffJC2tjZuvPFGpk2bRkVFBcuWLQutV1VVxdSpU7n11ltDNz2MpLq6mkceeYQHH3yQ8vJyXnvtNfbt28eVV17Jhz70IT70oQ/xt7/9DYDly5dTXl5OeXk5FRUVNDU19aqTiEhCcs4Nqumss85yPa1Zs6bXsiNpbGzsV/loJCUluRkzZrhJkya53Nxct3LlSuecc8uWLXNz584NlfvBD37gbrzxRuecc2vXrnUlJSWutbXVOefcZz/7WffrX//aNTQ0uJNPPtl5vd4+9/ftb3/bPfDAA6Hn1157rXvttdecc85t27bNnX766c455y699FK3YsUK55xzTU1NrqOjo1edjubdd9+Nuuxwt2zZsnhXYdBQW/XPUG4vAhdv6PV+rx7UAOka4lu3bh0vv/wy119/fcRbWKxYsYJPf/rTAJx++umMGzeODRs24PV6eemll7jiiivIzc3lnHPOYcmSJVHv/5VXXuH222+nvLycefPm0djYSHNzM7NmzeLOO+/koYceor6+nuTkoTeqKyJDk96tYuDcc89l//797Nu3L+p1lixZQn19PdOmTQPg0KFDZGRkcOmll0a1fmdnJ2+88Qbp6endlt99993MnTuXl156iVmzZvUr9ERE4kk9qBhYt24dfr+fwsJCcnJyut1n6fzzz+fpp58GYMOGDWzfvp1JkyaxYMECHnvsMaqrq6murmbr1q385S9/4dChQxH30XO7H/3oR/nJT34Set51wsbmzZuZNm0ad911Fx/60IdYt25dr3VFRBKRAmqAtLa2hk5GmD9/Pk8++SQej4fp06fj8XiYMWMGDz74IF/4whfo7Oxk2rRpzJ8/nyeeeAK/38/LL7/M3LlzQ9vLysrivPPO48UXX4y4v8suu4xFixaFTpJ46KGHWLlyJdOnT2fKlCk88sgjAPzoRz/ijDPOYPr06aSkpHDJJZf0qpOISCLSEN8A8fv9EZenpKSwdOnSbst+9atf9Sp34MCBXsuef/75Pvc3ceJE3nvvvW7LFi5c2KtceK8qXM86iYgkGvWgREQkIakHleB+9atf8eMf/7jbslmzZvHwww/HqUYiIieGAirB3Xjjjdx4443xroaIyAmnIT4REUlICigREUlICigREUlICigREUlICqgBMljuB7Vy5Uq+9KUv9Xs9EZETbcidxXfHHXeELvPTF7/fj6cf94MqLy/nR4PoflA+n6/Pi8JWVlZSWVl51LqIiMSbelAxEI/7Qd1www18/vOf55xzzuFrX/sab731Fueeey4VFRXMnDmT9evXh/bRdQHae++9l5tuuonZs2dz6qmn8tBDD8WwVURE+mfI9aCO1tMBaGpqIicnZ0D323Utvra2Nnbv3h26lND999/PD37wA/74xz8C8MMf/hAz4/3332fdunV89KMfZcOGDaSnp7NgwQKuvfZaLr/8cr7+9a/T0dFBSkpKr32Vlpby+c9/nuzsbL7yla8A8Pjjj1NTU8Prr7+Ox+OhsbGR1157jeTkZF555RW+/vWv8/vf/77XttatW8eyZctoampi0qRJ3HrrrRH3KSJyoqkHNUDifT8ogKuvvjo0dNnQ0MDVV1/NGWecwb/927/xwQcfRFxn7ty5pKWlUVRUxKhRo6itre3nTy4iEhtDrgeVCOJxPygIXAG9yze/+U3mzJnDokWLqK6uZvbs2RHXSUtLC817PB58Pl/U+xMRiSX1oGIgHveD6qmhoYGxY8cC8MQTTwzcDycicoIooAZIvO8H1dPXvvY17rnnHioqKtQrEpFBySIdJ0lklZWVbuXKld2WrV27lsmTJ0e9jVicJDGUrVq1ioqKinhXY1CoqqrqczhVulNb9c9Qbi8ze8c51+v7L+pBiYhIQtJJEglO94MSkeFqyASUcw4zi3c1Bly87wc12IaARWToGBJDfOnp6dTV1enNdIA556irq8Pv98e7KiIyDA2JHlRxcTE1NTVRf++ora2N9PT0GNdqaEhPT6elpSXe1RCRYWhIBFRKSgplZWVRl6+qqtJZaf2wbdu2eFdBRIahmA7xmdnFZrbezDaZ2d0RXk8zs4XB1980s9JY1kdERAaPmAWUmXmAh4FLgCnAtWY2pUexm4GDzrnTgAeB/xer+oiIyOASyx7U2cAm59wW55wX+B1weY8ylwNPBuefAy6yoXgqnoiI9Fssj0GNBXaEPa8BzumrjHPOZ2YNQCGwP7yQmd0C3BJ82mxm64+zbkU99yFHpPaKntoqemqr/hnK7TUu0sJBcZKEc+5R4NGB2p6ZrYx0WQ2JTO0VPbVV9NRW/TMc2yuWQ3w7gZKw58XBZRHLmFkykAfUxbBOIiIySMQyoN4GJphZmZmlAtcAi3uUWQx8Jjh/FbDU6du2IiJCDIf4gseUbgeWAB7gl865D8zsPmClc24x8DjwlJltAg4QCLETYcCGC4cJtVf01FbRU1v1z7Brr0F3uw0RERkehsS1+EREZOhRQImISEIadgF1tMsvSYCZlZjZMjNbY2YfmNmX412nRGdmHjNbZWZ/jHddEp2Z5ZvZc2a2zszWmtm58a5TojKzfwv+Df7TzBaY2bC50vWwCqgoL78kAT7g351zU4B/AW5TWx3Vl4G18a7EIPFj4GXn3OnADNRuEZnZWOBLQKVz7gwCJ5ydqJPJ4m5YBRTRXX5JAOfcbufcu8H5JgJvIGPjW6vEZWbFwFzgsXjXJdGZWR7wYQJn8eKc8zrn6uNbq4SWDGQEvyuaCeyKc31OmOEWUJEuv6Q33aMIXmW+AngzvjVJaD8CvgZ0xrsig0AZsA/4VXBI9DEzy4p3pRKRc24n8ANgO7AbaHDO/U98a3XiDLeAkn4ys2zg98AdzrnGeNcnEZnZpcBe59w78a7LIJEMnAn8zDlXAbQAOh4cgZkVEBjlKQNOBrLM7NPxrdWJM9wCKprLL0mQmaUQCKennXPPx7s+CWwWMM/MqgkMG19oZr+Jb5USWg1Q45zr6pE/RyCwpLd/BbY65/Y55zqA54GZca7TCTPcAiqayy8JELztyePAWufcf8W7PonMOXePc67YOVdK4HdqqXNu2HzK7S/n3B5gh5lNCi66CFgTxyolsu3Av5hZZvBv8iKG0Qklg+Jq5gOlr8svxblaiWoWcB3wvpmtDi77unPupTjWSYaOLwJPBz8obgFujHN9EpJz7k0zew54l8CZtasYRpc80qWOREQkIQ23IT4RERkkFFAiIpKQFFAiIpKQFFAiIpKQFFAiIpKQFFAig4yZzdYV02U4UECJiEhCUkCJxIiZfdrM3jKz1Wb28+D9oprN7MHg/X3+amYjg2XLzewNM3vPzBYFr8GGmZ1mZq+Y2T/M7F0zGx/cfHbY/ZSeDl5lADO7P3gPr/fM7Adx+tFFBoQCSiQGzGwyMB+Y5ZwrB/zA/waygJXOuanAcuDbwVV+DdzlnJsOvB+2/GngYefcDALXYNsdXF4B3EHgvmanArPMrBD4ODA1uJ3vxvanFIktBZRIbFwEnAW8HbxU1EUEgqQTWBgs8xvgvOD9kfKdc8uDy58EPmxmOcBY59wiAOdcm3PuULDMW865GudcJ7AaKAUagDbgcTP7BNBVVmRQUkCJxIYBTzrnyoPTJOfcvRHKHeu1xtrD5v1AsnPOR+CmnM8BlwIvH+O2RRKCAkokNv4KXGVmowDMbISZjSPwN3dVsMyngBXOuQbgoJmdH1x+HbA8eCfjGjO7IriNNDPL7GuHwXt35QUv6PtvBG6lLjJoDaurmYucKM65NWb2H8D/mFkS0AHcRuDmfGcHX9tL4DgVwGeAR4IBFH517+uAn5vZfcFtXH2E3eYAfzCzdAI9uDsH+McSOaF0NXORE8jMmp1z2fGuh8hgoCE+ERFJSOpBiYhIQlIPSkREEpICSkREEpICSkREEpICSkREEpICSkREEtL/D1U9awICBgt5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ii-C5JulM9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0a24df33-3ebd-421a-e205-1fdb07aa5086"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "y1=[]\n",
        "y2=[]\n",
        "y3=[]\n",
        "y4=[]\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/ABtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y1.append(line)\n",
        "\n",
        "y1=np.ravel(y1)\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/ABtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y2.append(line)\n",
        "\n",
        "y2=np.ravel(y2)\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/BAtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y3.append(line)\n",
        "\n",
        "y3=np.ravel(y3)\n",
        "\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/BAtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y4.append(line)\n",
        "\n",
        "y4=np.ravel(y4)\n",
        "\n",
        "c1,c2,c3,c4 = \"blue\",\"green\",\"red\",\"black\"   # 各プロットの色\n",
        "l1,l2,l3,l4 = \"AtoB_test\",\"AtoB_train\",\"BtoA_test\",\"BtoA_train\"   # 各ラベル\n",
        "\n",
        "  # x軸ラベル\n",
        "ax.set_xlabel('epochs')\n",
        "ax.set_ylabel('loss')  # y軸ラベル\n",
        "ax.set_title('loss') # グラフタイトル\n",
        "# ax.set_aspect('equal') # スケールを揃える\n",
        "ax.grid()            # 罫線\n",
        "#ax.set_xlim([0, 5]) # x方向の描画範囲を指定\n",
        "#ax.set_ylim([0, 1])    # y方向の描画範囲を指定\n",
        "ax.plot(y1, color=c1, label=l1)\n",
        "ax.plot(y2, color=c2, label=l2)\n",
        "ax.plot(y3, color=c3, label=l3)\n",
        "ax.plot(y4, color=c4, label=l4)\n",
        "ax.legend(loc=0)    # 凡例\n",
        "fig.tight_layout()  # レイアウトの設定\n",
        "plt.savefig(f\"/content/drive/My Drive/googlecolab/cifar10/loss/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.png\") # 画像の保存\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uduR4Qmnk-SB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQezBzB8AF7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#モデルの保存\n",
        "import numpy as np\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import RMSprop\n",
        "import os\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/model/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_\"\n",
        "# モデル構造の保存\n",
        "open(SAVE_DATA_DIR_PATH  + \"model_AtoB.json\",\"w\").write(model_AtoB.to_json())\n",
        "\n",
        "# 学習済みの重みを保存\n",
        "model_AtoB.save_weights(SAVE_DATA_DIR_PATH + \"AtoB_weight.hdf5\")\n",
        "\n",
        "# モデル構造の保存\n",
        "open(SAVE_DATA_DIR_PATH  + \"model_BtoA.json\",\"w\").write(model_BtoA.to_json())\n",
        "\n",
        "# 学習済みの重みを保存\n",
        "model_BtoA.save_weights(SAVE_DATA_DIR_PATH + \"BtoA_weight.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Q_ugYmCbgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doJN1NWGAs9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 保存したモデル構造の読み込み\n",
        "model3 = model_from_json(open(SAVE_DATA_DIR_PATH + \"model_AtoB.json\", 'r').read())\n",
        "\n",
        "# 保存した学習済みの重みを読み込み\n",
        "model3.load_weights(SAVE_DATA_DIR_PATH + \"AtoB_weight.hdf5\")\n",
        "\n",
        "# 保存したモデル構造の読み込み\n",
        "model4 = model_from_json(open(SAVE_DATA_DIR_PATH + \"model_BtoA.json\", 'r').read())\n",
        "\n",
        "# 保存した学習済みの重みを読み込み\n",
        "model4.load_weights(SAVE_DATA_DIR_PATH + \"BtoA_weight.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYpuZrseDJAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(lr=learningrate),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model4.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(lr=learningrate),\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb5y5fLlCxc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6215c9c6-3888-4cac-8a40-8765e3cd73a3"
      },
      "source": [
        "xx3=model3.evaluate(xx,yy)[1]\n",
        "print(xx3)\n",
        "xx4=model4.evaluate(xx,yy)[1]\n",
        "print(xx4)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 35s 873us/step\n",
            "0.4955250024795532\n",
            "40000/40000 [==============================] - 35s 863us/step\n",
            "0.5731499791145325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSJfPf0OiJGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/ABtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_test_acc))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/ABtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_train_acc))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/BAtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_test_acc))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/BAtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_train_acc))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/ABtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_test_loss))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/ABtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_train_loss))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/BAtest_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_test_loss))\n",
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/loss/BAtrain_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_train_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgRML1HAH45f",
        "colab_type": "code",
        "outputId": "48708800-6d73-4a04-877c-e4a914ffe70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#精度を確かめる\n",
        "xx=data.train_images[10000:]\n",
        "xx=xx.astype('float32')/255.0\n",
        "print(xx.shape)\n",
        "yy=data.train_labels[10000:]\n",
        "yy=to_categorical(yy,10)\n",
        "print(yy.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 32, 32, 3)\n",
            "(40000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrmAz9NWIZKt",
        "colab_type": "code",
        "outputId": "4c259328-5765-46e8-8570-20c6bb3f669c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "xx1=model_AtoB.evaluate(xx,yy)[1]\n",
        "xx2=model_BtoA.evaluate(xx,yy)[1]\n",
        "xx3=model_AtoB.evaluate(xx,yy)[0]\n",
        "xx4=model_BtoA.evaluate(xx,yy)[0]\n",
        "print(xx1)\n",
        "print(xx2)\n",
        "print(xx3)\n",
        "print(xx4)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 35s 884us/step\n",
            "40000/40000 [==============================] - 39s 977us/step\n",
            "40000/40000 [==============================] - 35s 875us/step\n",
            "40000/40000 [==============================] - 35s 867us/step\n",
            "0.5116999745368958\n",
            "0.564424991607666\n",
            "5.5970186433792115\n",
            "2.356930879545212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnMTAWv4J37l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f\"/content/drive/My Drive/googlecolab/cifar10/acc/xx40000_random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}.text\",\"w\") as f:\n",
        "  f.writelines(str(xx1))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}