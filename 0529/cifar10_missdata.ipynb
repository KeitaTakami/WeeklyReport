{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_missdata.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xTHG7ynw49-Qr6DygUxI0zHJ7J9wV_r8",
      "authorship_tag": "ABX9TyMObvqFu0ARtsX6hxGIP3Qz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeitaTakami/WeeklyReport/blob/master/0529/cifar10_missdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRBJpJGx26FY",
        "colab_type": "code",
        "outputId": "7ee75b55-ebf3-4439-ec78-10cd0bb92e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "!pip install dlt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dlt in /usr/local/lib/python3.6/dist-packages (0.2.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from dlt) (2.3.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from dlt) (2.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from dlt) (3.2.1)\n",
            "Requirement already satisfied: Numpy in /usr/local/lib/python3.6/dist-packages (from dlt) (1.18.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from dlt) (0.22.2.post1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->dlt) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (2.2.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (2.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (1.29.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->dlt) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dlt) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dlt) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dlt) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->dlt) (1.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dlt) (0.15.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.6.0.post3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (46.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.6.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->dlt) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9omqi5h3yI-",
        "colab_type": "code",
        "outputId": "0723cff9-8fed-4e2a-f025-29d2e3efe691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#dlt=Deep Learning Tools\n",
        "\n",
        "# parameter\n",
        "random_AB=0\n",
        "learningrate=0.001\n",
        "batch_s=128\n",
        "change_num=10000\n",
        "epoch=25\n",
        "repetition=40\n",
        "data_num=10000\n",
        "data_num_ab=int(data_num/2)\n",
        "import dlt\n",
        "data=dlt.cifar.load_cifar10()\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation,Conv2D,MaxPooling2D,Flatten\n",
        "from keras.optimizers import Adam\n",
        "#データの取得,確認\n",
        "x=data.train_images[:data_num]\n",
        "x=x.astype('float32')/255.0\n",
        "print(x.shape)\n",
        "y=data.train_labels[:data_num]\n",
        "y=to_categorical(y,10)\n",
        "print(y.shape)\n",
        "#print(x[0])\n",
        "#print(y[0])\n",
        "#AとBに二分割\n",
        "x_a,x_b=train_test_split(x,test_size=0.5,random_state=random_AB)\n",
        "print(x_a.shape)\n",
        "print(x_b.shape)\n",
        "y_a,y_b=train_test_split(y,test_size=0.5,random_state=random_AB)\n",
        "print(y_a.shape)\n",
        "print(y_b.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading CIFAR-10 dataset\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 10)\n",
            "(5000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(5000, 10)\n",
            "(5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5RJicvZ32RD",
        "colab_type": "code",
        "outputId": "7c2dfe18-f053-45f8-e679-175a35499fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "y_a=np.argmax(y_a,axis=1)\n",
        "y_b=np.argmax(y_b,axis=1)\n",
        "y_a_num=[]\n",
        "y_a_num = [0 for i in range(10)]\n",
        "print(y_a_num)\n",
        "y_b_num=[]\n",
        "y_b_num = [0 for i in range(10)]\n",
        "print(y_b_num)\n",
        "for i in range(10):\n",
        "  for k in range(data_num_ab):\n",
        "    if y_a[k]==i:\n",
        "      y_a_num[i]+=1\n",
        "for i in range(10):\n",
        "  for k in range(data_num_ab):\n",
        "    if y_b[k]==i:\n",
        "      y_b_num[i]+=1\n",
        "print(y_a_num)\n",
        "print(y_b_num)\n",
        "y_a=to_categorical(y_a,10)\n",
        "y_b=to_categorical(y_b,10)\n",
        "print(y_a.shape)\n",
        "print(y_b.shape)\n",
        "\n",
        "y_a_num_history=[]\n",
        "y_b_num_history=[]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[499, 484, 516, 523, 508, 493, 503, 490, 497, 487]\n",
            "[506, 490, 516, 493, 491, 444, 527, 511, 528, 494]\n",
            "(5000, 10)\n",
            "(5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-LleiLl395i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model():\n",
        "  model=Sequential()\n",
        "\n",
        "  # 1層目\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(32,32,3)))\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # 2層目\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # 出力層\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsaWqcKO4KOs",
        "colab_type": "code",
        "outputId": "30ab5278-176e-496d-cf7e-ebd4befbd834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "AtoB_train_loss=[]\n",
        "AtoB_train_acc=[]\n",
        "AtoB_test_loss=[]\n",
        "AtoB_test_acc=[]\n",
        "BtoA_train_loss=[]\n",
        "BtoA_train_acc=[]\n",
        "BtoA_test_loss=[]\n",
        "BtoA_test_acc=[]\n",
        "#前処理 間違えやすいデータを半分取り出す\n",
        "print('前処理')\n",
        "for i in range(2):\n",
        "  print('%d回目' % i)\n",
        "  \n",
        "  model_AtoB=model()\n",
        "  model_BtoA=model()\n",
        "  model_AtoB.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(lr=learningrate),\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  model_BtoA.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(lr=learningrate),\n",
        "        metrics=['accuracy'])\n",
        "  \n",
        "  #A->train,B->test\n",
        "  model_AtoB.fit(x_a,y_a,\n",
        "    batch_size=batch_s,\n",
        "    epochs=epoch,\n",
        "    verbose=1,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "  \"\"\"\n",
        "  AtoB_train_loss.append(model_AtoB.evaluate(x_a,y_a)[0])\n",
        "  AtoB_train_acc.append(model_AtoB.evaluate(x_a,y_a)[1])\n",
        "  AtoB_test_loss.append(model_AtoB.evaluate(x_b,y_b)[0])\n",
        "  AtoB_test_acc.append(model_AtoB.evaluate(x_b,y_b)[1])\n",
        "  \"\"\"\n",
        "  y_b_pred=model_AtoB.predict_classes(x_b)\n",
        "  y_b_true=np.argmax(y_b,axis=1)\n",
        "\n",
        "  data_num_ab=len(x_a)\n",
        "\n",
        "  # Bの間違い\n",
        "  B_miss=[]\n",
        "  for j in range(data_num_ab):\n",
        "    if y_b_pred[j] != y_b_true[j]:\n",
        "      B_miss.append(j)\n",
        "\n",
        "  #B->train,A->test\n",
        "  model_BtoA.fit(x_b,y_b,\n",
        "    batch_size=batch_s,\n",
        "    epochs=epoch,\n",
        "    verbose=1,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "  \"\"\"\n",
        "  BtoA_train_loss.append(model_BtoA.evaluate(x_b,y_b)[0])\n",
        "  BtoA_train_acc.append(model_BtoA.evaluate(x_b,y_b)[1])\n",
        "  BtoA_test_loss.append(model_BtoA.evaluate(x_a,y_a)[0])\n",
        "  BtoA_test_acc.append(model_BtoA.evaluate(x_a,y_a)[1])\n",
        "  \"\"\"\n",
        "  y_a_pred=model_BtoA.predict_classes(x_a)\n",
        "  y_a_true=np.argmax(y_a,axis=1)\n",
        "  # Aの間違い\n",
        "  A_miss=[]\n",
        "  for j in range(data_num_ab):\n",
        "    if y_a_pred[j] != y_a_true[j]:\n",
        "      A_miss.append(j)\n",
        "\n",
        "\n",
        "  random.shuffle(A_miss)\n",
        "  random.shuffle(B_miss)\n",
        "    \n",
        "  length=len(A_miss)-len(B_miss)\n",
        "  if length>0:\n",
        "    A_miss=A_miss[length:]\n",
        "  if length<0:\n",
        "    B_miss=B_miss[-length:]\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  if i==0:\n",
        "    x_a_miss=x_a[A_miss]\n",
        "    y_a_miss=y_a[A_miss]\n",
        "    x_b_miss=x_b[B_miss]\n",
        "    y_b_miss=y_b[B_miss]\n",
        "\n",
        "  if i>0:\n",
        "    x_a_miss_tmp=x_a[A_miss]\n",
        "    x_a_miss=np.concatenate([x_a_miss,x_a_miss_tmp])\n",
        "    y_a_miss_tmp=y_a[A_miss]\n",
        "    y_a_miss=np.concatenate([y_a_miss,y_a_miss_tmp])\n",
        "    x_b_miss_tmp=x_b[B_miss]\n",
        "    x_b_miss=np.concatenate([x_b_miss,x_b_miss_tmp])\n",
        "    y_b_miss_tmp=y_b[B_miss]\n",
        "    y_b_miss=np.concatenate([y_b_miss,y_b_miss_tmp])\n",
        "\n",
        "\n",
        "  x_a=np.delete(x_a,A_miss,0)\n",
        "  y_a=np.delete(y_a,A_miss,0)\n",
        "  x_b=np.delete(x_b,B_miss,0)\n",
        "  y_b=np.delete(y_b,B_miss,0)\n",
        "\n",
        "\n",
        "x_a=x_a_miss\n",
        "y_a=y_a_miss\n",
        "x_b=x_b_miss\n",
        "y_b=y_b_miss\n",
        "data_num_ab=len(x_a)\n",
        "y_a=np.argmax(y_a,axis=1)\n",
        "y_b=np.argmax(y_b,axis=1)\n",
        "y_a_num=[]\n",
        "y_a_num = [0 for l in range(10)]\n",
        "y_b_num=[]\n",
        "y_b_num = [0 for l in range(10)]\n",
        "for j in range(10):\n",
        "  for k in range(data_num_ab):\n",
        "    if y_a[k]==j:\n",
        "      y_a_num[j]+=1\n",
        "for j in range(10):\n",
        "  for k in range(data_num_ab):\n",
        "    if y_b[k]==j:\n",
        "      y_b_num[j]+=1\n",
        "y_a=to_categorical(y_a,10)\n",
        "y_b=to_categorical(y_b,10)\n",
        "\n",
        "\n",
        "y_a_num_history.append(y_a_num)\n",
        "y_b_num_history.append(y_b_num)\n",
        "\n",
        "#間違えやすいデータで実験\n",
        "print('本実験')\n",
        "for i in range(repetition):\n",
        "  print('%d回目' % i)\n",
        "  \n",
        "\n",
        "\n",
        "  model_AtoB=model()\n",
        "  model_BtoA=model()\n",
        "  model_AtoB.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(lr=learningrate),\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  model_BtoA.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(lr=learningrate),\n",
        "        metrics=['accuracy'])\n",
        "  \n",
        "  #A->train,B->test\n",
        "  model_AtoB.fit(x_a,y_a,\n",
        "    batch_size=batch_s,\n",
        "    epochs=epoch,\n",
        "    verbose=1,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "  AtoB_train_loss.append(model_AtoB.evaluate(x_a,y_a)[0])\n",
        "  AtoB_train_acc.append(model_AtoB.evaluate(x_a,y_a)[1])\n",
        "  AtoB_test_loss.append(model_AtoB.evaluate(x_b,y_b)[0])\n",
        "  AtoB_test_acc.append(model_AtoB.evaluate(x_b,y_b)[1])\n",
        "  y_b_pred=model_AtoB.predict_classes(x_b)\n",
        "  y_b_true=np.argmax(y_b,axis=1)\n",
        "\n",
        "  \n",
        "\n",
        "  # Bの間違い\n",
        "  B_miss=[]\n",
        "  for j in range(data_num_ab):\n",
        "    if y_b_pred[j] != y_b_true[j]:\n",
        "      B_miss.append(j)\n",
        "\n",
        "  #B->train,A->test\n",
        "  model_BtoA.fit(x_b,y_b,\n",
        "    batch_size=batch_s,\n",
        "    epochs=epoch,\n",
        "    verbose=1,\n",
        "    validation_split=0.1\n",
        "    )\n",
        "  BtoA_train_loss.append(model_BtoA.evaluate(x_b,y_b)[0])\n",
        "  BtoA_train_acc.append(model_BtoA.evaluate(x_b,y_b)[1])\n",
        "  BtoA_test_loss.append(model_BtoA.evaluate(x_a,y_a)[0])\n",
        "  BtoA_test_acc.append(model_BtoA.evaluate(x_a,y_a)[1])\n",
        "  y_a_pred=model_BtoA.predict_classes(x_a)\n",
        "  y_a_true=np.argmax(y_a,axis=1)\n",
        "  # Aの間違い\n",
        "  A_miss=[]\n",
        "  for j in range(data_num_ab):\n",
        "    if y_a_pred[j] != y_a_true[j]:\n",
        "      A_miss.append(j)\n",
        "\n",
        "\n",
        "  random.shuffle(A_miss)\n",
        "  random.shuffle(B_miss)\n",
        "    \n",
        "  length=len(A_miss)-len(B_miss)\n",
        "  if length>0:\n",
        "    A_miss=A_miss[length:]\n",
        "  if length<0:\n",
        "    B_miss=B_miss[-length:]\n",
        "\n",
        "  x_a=np.delete(x_a,A_miss,0)\n",
        "  y_a=np.delete(y_a,A_miss,0)\n",
        "  x_b=np.delete(x_b,B_miss,0)\n",
        "  y_b=np.delete(y_b,B_miss,0)\n",
        "\n",
        "  data_num_ab=len(x_a)\n",
        "\n",
        "  # ラベルの数え上げ\n",
        "  y_a=np.argmax(y_a,axis=1)\n",
        "  y_b=np.argmax(y_b,axis=1)\n",
        "  y_a_num=[]\n",
        "  y_a_num = [0 for l in range(10)]\n",
        "  y_b_num=[]\n",
        "  y_b_num = [0 for l in range(10)]\n",
        "  for j in range(10):\n",
        "    for k in range(data_num_ab):\n",
        "      if y_a[k]==j:\n",
        "        y_a_num[j]+=1\n",
        "  for j in range(10):\n",
        "    for k in range(data_num_ab):\n",
        "      if y_b[k]==j:\n",
        "        y_b_num[j]+=1\n",
        "  y_a=to_categorical(y_a,10)\n",
        "  y_b=to_categorical(y_b,10)\n",
        "\n",
        "\n",
        "  y_a_num_history.append(y_a_num)\n",
        "  y_b_num_history.append(y_b_num)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/missdata/acc/data/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_data_num{data_num}/\"\n",
        "if not os.path.exists(SAVE_DATA_DIR_PATH):\n",
        "    os.mkdir(SAVE_DATA_DIR_PATH)\n",
        "with open(SAVE_DATA_DIR_PATH + f\"ABtest.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_test_acc))\n",
        "with open(SAVE_DATA_DIR_PATH + f\"ABtrain.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_train_acc))\n",
        "with open(SAVE_DATA_DIR_PATH + f\"BAtest.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_test_acc))\n",
        "with open(SAVE_DATA_DIR_PATH + f\"BAtrain.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_train_acc))\n",
        "\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/missdata/loss/data/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_data_num{data_num}/\"\n",
        "if not os.path.exists(SAVE_DATA_DIR_PATH):\n",
        "    os.mkdir(SAVE_DATA_DIR_PATH)\n",
        "with open(SAVE_DATA_DIR_PATH + f\"ABtest.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_test_loss))\n",
        "with open(SAVE_DATA_DIR_PATH + f\"ABtrain.text\", \"w\")as f:\n",
        "  f.writelines(str(AtoB_train_loss))\n",
        "with open(SAVE_DATA_DIR_PATH + f\"BAtest.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_test_loss))\n",
        "with open(SAVE_DATA_DIR_PATH + f\"BAtrain.text\", \"w\")as f:\n",
        "  f.writelines(str(BtoA_train_loss))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "\n",
        "\n",
        "y1=[]\n",
        "y2=[]\n",
        "y3=[]\n",
        "y4=[]\n",
        "\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/missdata/acc/data/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_data_num{data_num}/\"\n",
        "\n",
        "with open(SAVE_DATA_DIR_PATH + f\"ABtest.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y1.append(line)\n",
        "\n",
        "y1=np.ravel(y1)\n",
        "\n",
        "with open(SAVE_DATA_DIR_PATH + f\"ABtrain.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y2.append(line)\n",
        "\n",
        "y2=np.ravel(y2)\n",
        "\n",
        "with open(SAVE_DATA_DIR_PATH + f\"BAtest.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y3.append(line)\n",
        "\n",
        "y3=np.ravel(y3)\n",
        "\n",
        "with open(SAVE_DATA_DIR_PATH + f\"BAtrain.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y4.append(line)\n",
        "\n",
        "y4=np.ravel(y4)\n",
        "#print(type(y1))\n",
        "#print(y1)\n",
        "\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/missdata/acc/picture/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_data_num{data_num}\"\n",
        "\n",
        "\n",
        "c1,c2,c3,c4 = \"blue\",\"green\",\"red\",\"black\"   # 各プロットの色\n",
        "l1,l2,l3,l4 = \"AtoB_test\",\"AtoB_train\",\"BtoA_test\",\"BtoA_train\"   # 各ラベル\n",
        "\n",
        "  # x軸ラベル\n",
        "ax.set_xlabel('iteration')\n",
        "ax.set_ylabel('accuracy')  # y軸ラベル\n",
        "ax.set_title('accuracy') # グラフタイトル\n",
        "# ax.set_aspect('equal') # スケールを揃える\n",
        "ax.grid()            # 罫線\n",
        "#ax.set_xlim([0, 5]) # x方向の描画範囲を指定\n",
        "ax.set_ylim([0, 1])    # y方向の描画範囲を指定\n",
        "ax.plot(y1, color=c1, label=l1)\n",
        "ax.plot(y2, color=c2, label=l2)\n",
        "ax.plot(y3, color=c3, label=l3)\n",
        "ax.plot(y4, color=c4, label=l4)\n",
        "ax.legend(loc=0)    # 凡例\n",
        "fig.tight_layout()  # レイアウトの設定\n",
        "plt.savefig(SAVE_DATA_DIR_PATH + f\".png\") # 画像の保存\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "\n",
        "\n",
        "y1=[]\n",
        "y2=[]\n",
        "y3=[]\n",
        "y4=[]\n",
        "\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/missdata/loss/data/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_data_num{data_num}/\"\n",
        "\n",
        "with open(SAVE_DATA_DIR_PATH + f\"ABtest.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y1.append(line)\n",
        "\n",
        "y1=np.ravel(y1)\n",
        "\n",
        "with open(SAVE_DATA_DIR_PATH + f\"ABtrain.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y2.append(line)\n",
        "\n",
        "y2=np.ravel(y2)\n",
        "\n",
        "with open(SAVE_DATA_DIR_PATH + f\"BAtest.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y3.append(line)\n",
        "\n",
        "y3=np.ravel(y3)\n",
        "\n",
        "with open(SAVE_DATA_DIR_PATH + f\"BAtrain.text\", \"r\") as f:\n",
        "  for line in f:\n",
        "    \n",
        "    line=line.strip() #前後空白削除\n",
        "    line=line.replace('\\n','') #末尾の\\nの削除\n",
        "    line=line[1:-1]\n",
        "    line=line.split(\",\") #分割\n",
        "    line=[float(s) for s in line]\n",
        "    y4.append(line)\n",
        "\n",
        "y4=np.ravel(y4)\n",
        "#print(type(y1))\n",
        "#print(y1)\n",
        "\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/missdata/loss/picture/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_data_num{data_num}\"\n",
        "\n",
        "\n",
        "c1,c2,c3,c4 = \"blue\",\"green\",\"red\",\"black\"   # 各プロットの色\n",
        "l1,l2,l3,l4 = \"AtoB_test\",\"AtoB_train\",\"BtoA_test\",\"BtoA_train\"   # 各ラベル\n",
        "\n",
        "  # x軸ラベル\n",
        "ax.set_xlabel('iteration')\n",
        "ax.set_ylabel('loss')  # y軸ラベル\n",
        "ax.set_title('loss') # グラフタイトル\n",
        "# ax.set_aspect('equal') # スケールを揃える\n",
        "ax.grid()            # 罫線\n",
        "#ax.set_xlim([0, 5]) # x方向の描画範囲を指定\n",
        "#ax.set_ylim([0, 1])    # y方向の描画範囲を指定\n",
        "ax.plot(y1, color=c1, label=l1)\n",
        "ax.plot(y2, color=c2, label=l2)\n",
        "ax.plot(y3, color=c3, label=l3)\n",
        "ax.plot(y4, color=c4, label=l4)\n",
        "ax.legend(loc=0)    # 凡例\n",
        "fig.tight_layout()  # レイアウトの設定\n",
        "plt.savefig(SAVE_DATA_DIR_PATH + f\".png\") # 画像の保存\n",
        "plt.show()\n",
        "\n",
        "\n",
        "SAVE_DATA_DIR_PATH = f\"/content/drive/My Drive/googlecolab/cifar10/missdata/picture/random{random_AB}_lr{learningrate}_batch{batch_s}_epoch{epoch}_change{change_num}_repe{repetition}_data_num{data_num}/\"\n",
        "if not os.path.exists(SAVE_DATA_DIR_PATH):\n",
        "    os.mkdir(SAVE_DATA_DIR_PATH)\n",
        "\n",
        "dataset = pd.DataFrame(y_a_num_history, \n",
        "             columns=['airplane', 'automobile', 'bird', 'cat','deer','dog','frog','horse','ship','truck'])\n",
        "print(dataset)\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlabel('iteration') # x軸ラベル\n",
        "ax.set_ylabel('number')  # y軸ラベル\n",
        "ax.set_title('label number') # グラフタイトル\n",
        "dataset.plot(kind='bar', stacked=True, ax=ax)\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "fig.tight_layout()\n",
        "plt.savefig(SAVE_DATA_DIR_PATH + f\"A_label.png\") # 画像の保存\n",
        "plt.show()\n",
        "dataset.to_csv(SAVE_DATA_DIR_PATH + f\"A_label.csv\")\n",
        "\n",
        "dataset = pd.DataFrame(y_b_num_history, \n",
        "             columns=['airplane', 'automobile', 'bird', 'cat','deer','dog','frog','horse','ship','truck'])\n",
        "print(dataset)\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlabel('iteration') # x軸ラベル\n",
        "ax.set_ylabel('number')  # y軸ラベル\n",
        "ax.set_title('label number') # グラフタイトル\n",
        "dataset.plot(kind='bar', stacked=True, ax=ax)\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "fig.tight_layout()\n",
        "plt.savefig(SAVE_DATA_DIR_PATH + f\"B_label.png\") # 画像の保存\n",
        "plt.show()\n",
        "dataset.to_csv(SAVE_DATA_DIR_PATH + f\"B_label.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "前処理\n",
            "0回目\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 2.1910 - accuracy: 0.1782 - val_loss: 2.0304 - val_accuracy: 0.2420\n",
            "Epoch 2/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.9027 - accuracy: 0.2982 - val_loss: 1.8396 - val_accuracy: 0.3040\n",
            "Epoch 3/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.7561 - accuracy: 0.3476 - val_loss: 1.7637 - val_accuracy: 0.3320\n",
            "Epoch 4/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.6624 - accuracy: 0.3909 - val_loss: 1.7750 - val_accuracy: 0.3360\n",
            "Epoch 5/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.6277 - accuracy: 0.4007 - val_loss: 1.6437 - val_accuracy: 0.3900\n",
            "Epoch 6/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.5188 - accuracy: 0.4367 - val_loss: 1.6254 - val_accuracy: 0.4040\n",
            "Epoch 7/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.4528 - accuracy: 0.4722 - val_loss: 1.5653 - val_accuracy: 0.4620\n",
            "Epoch 8/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.4063 - accuracy: 0.4911 - val_loss: 1.5076 - val_accuracy: 0.4720\n",
            "Epoch 9/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.3445 - accuracy: 0.5107 - val_loss: 1.6674 - val_accuracy: 0.4140\n",
            "Epoch 10/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.3305 - accuracy: 0.5218 - val_loss: 1.5435 - val_accuracy: 0.4380\n",
            "Epoch 11/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.2650 - accuracy: 0.5476 - val_loss: 1.4013 - val_accuracy: 0.4820\n",
            "Epoch 12/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.2239 - accuracy: 0.5533 - val_loss: 1.3981 - val_accuracy: 0.4860\n",
            "Epoch 13/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.1749 - accuracy: 0.5760 - val_loss: 1.3928 - val_accuracy: 0.4920\n",
            "Epoch 14/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.1411 - accuracy: 0.5878 - val_loss: 1.3583 - val_accuracy: 0.4960\n",
            "Epoch 15/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.0729 - accuracy: 0.6109 - val_loss: 1.3918 - val_accuracy: 0.4980\n",
            "Epoch 16/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.0052 - accuracy: 0.6340 - val_loss: 1.3629 - val_accuracy: 0.5420\n",
            "Epoch 17/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.9695 - accuracy: 0.6507 - val_loss: 1.4908 - val_accuracy: 0.5060\n",
            "Epoch 18/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.9535 - accuracy: 0.6549 - val_loss: 1.3757 - val_accuracy: 0.5300\n",
            "Epoch 19/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.9261 - accuracy: 0.6653 - val_loss: 1.4469 - val_accuracy: 0.4920\n",
            "Epoch 20/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.8487 - accuracy: 0.6940 - val_loss: 1.4324 - val_accuracy: 0.5200\n",
            "Epoch 21/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.8202 - accuracy: 0.7071 - val_loss: 1.3961 - val_accuracy: 0.5260\n",
            "Epoch 22/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.7569 - accuracy: 0.7333 - val_loss: 1.4254 - val_accuracy: 0.5440\n",
            "Epoch 23/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.7150 - accuracy: 0.7418 - val_loss: 1.4025 - val_accuracy: 0.5460\n",
            "Epoch 24/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.6919 - accuracy: 0.7511 - val_loss: 1.5239 - val_accuracy: 0.5160\n",
            "Epoch 25/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.6643 - accuracy: 0.7689 - val_loss: 1.4567 - val_accuracy: 0.5360\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 2.2345 - accuracy: 0.1493 - val_loss: 2.1520 - val_accuracy: 0.2260\n",
            "Epoch 2/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.9913 - accuracy: 0.2693 - val_loss: 1.7954 - val_accuracy: 0.3620\n",
            "Epoch 3/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.7975 - accuracy: 0.3478 - val_loss: 1.7171 - val_accuracy: 0.3620\n",
            "Epoch 4/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.7110 - accuracy: 0.3751 - val_loss: 1.5935 - val_accuracy: 0.4380\n",
            "Epoch 5/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.6233 - accuracy: 0.4036 - val_loss: 1.5731 - val_accuracy: 0.4100\n",
            "Epoch 6/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.5662 - accuracy: 0.4191 - val_loss: 1.5113 - val_accuracy: 0.4700\n",
            "Epoch 7/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.4888 - accuracy: 0.4520 - val_loss: 1.4800 - val_accuracy: 0.4660\n",
            "Epoch 8/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.4424 - accuracy: 0.4807 - val_loss: 1.3968 - val_accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.3622 - accuracy: 0.5000 - val_loss: 1.4030 - val_accuracy: 0.5040\n",
            "Epoch 10/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.3229 - accuracy: 0.5240 - val_loss: 1.3736 - val_accuracy: 0.5080\n",
            "Epoch 11/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.2840 - accuracy: 0.5302 - val_loss: 1.2739 - val_accuracy: 0.5280\n",
            "Epoch 12/25\n",
            "4500/4500 [==============================] - 18s 4ms/step - loss: 1.1984 - accuracy: 0.5618 - val_loss: 1.2382 - val_accuracy: 0.5440\n",
            "Epoch 13/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.1925 - accuracy: 0.5596 - val_loss: 1.3368 - val_accuracy: 0.5100\n",
            "Epoch 14/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.1404 - accuracy: 0.5858 - val_loss: 1.2872 - val_accuracy: 0.5360\n",
            "Epoch 15/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.1012 - accuracy: 0.6031 - val_loss: 1.2078 - val_accuracy: 0.5780\n",
            "Epoch 16/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.0728 - accuracy: 0.6153 - val_loss: 1.1821 - val_accuracy: 0.5820\n",
            "Epoch 17/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 1.0348 - accuracy: 0.6378 - val_loss: 1.1735 - val_accuracy: 0.6020\n",
            "Epoch 18/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.9761 - accuracy: 0.6476 - val_loss: 1.1575 - val_accuracy: 0.5860\n",
            "Epoch 19/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.9671 - accuracy: 0.6580 - val_loss: 1.1319 - val_accuracy: 0.6080\n",
            "Epoch 20/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.8861 - accuracy: 0.6898 - val_loss: 1.1313 - val_accuracy: 0.5940\n",
            "Epoch 21/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.8442 - accuracy: 0.7002 - val_loss: 1.1700 - val_accuracy: 0.5860\n",
            "Epoch 22/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.8285 - accuracy: 0.7082 - val_loss: 1.1447 - val_accuracy: 0.6240\n",
            "Epoch 23/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.7832 - accuracy: 0.7204 - val_loss: 1.1025 - val_accuracy: 0.6260\n",
            "Epoch 24/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.7342 - accuracy: 0.7351 - val_loss: 1.1333 - val_accuracy: 0.6180\n",
            "Epoch 25/25\n",
            "4500/4500 [==============================] - 14s 3ms/step - loss: 0.7149 - accuracy: 0.7487 - val_loss: 1.1084 - val_accuracy: 0.6140\n",
            "1回目\n",
            "Train on 2561 samples, validate on 285 samples\n",
            "Epoch 1/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 2.2426 - accuracy: 0.1464 - val_loss: 2.1176 - val_accuracy: 0.2035\n",
            "Epoch 2/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.9669 - accuracy: 0.2788 - val_loss: 1.9463 - val_accuracy: 0.3404\n",
            "Epoch 3/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.7404 - accuracy: 0.3698 - val_loss: 2.1709 - val_accuracy: 0.2912\n",
            "Epoch 4/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.7491 - accuracy: 0.3866 - val_loss: 1.6717 - val_accuracy: 0.4000\n",
            "Epoch 5/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.5130 - accuracy: 0.4572 - val_loss: 1.4787 - val_accuracy: 0.4667\n",
            "Epoch 6/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.3743 - accuracy: 0.5029 - val_loss: 1.8617 - val_accuracy: 0.3684\n",
            "Epoch 7/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.6502 - accuracy: 0.4268 - val_loss: 1.5662 - val_accuracy: 0.4316\n",
            "Epoch 8/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.3405 - accuracy: 0.5201 - val_loss: 1.3245 - val_accuracy: 0.5228\n",
            "Epoch 9/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.2612 - accuracy: 0.5439 - val_loss: 1.2728 - val_accuracy: 0.5193\n",
            "Epoch 10/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.1541 - accuracy: 0.5853 - val_loss: 1.2635 - val_accuracy: 0.5474\n",
            "Epoch 11/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.0596 - accuracy: 0.6216 - val_loss: 1.1706 - val_accuracy: 0.5860\n",
            "Epoch 12/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.0691 - accuracy: 0.6173 - val_loss: 1.6377 - val_accuracy: 0.4772\n",
            "Epoch 13/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.3137 - accuracy: 0.5357 - val_loss: 1.4114 - val_accuracy: 0.4737\n",
            "Epoch 14/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.1094 - accuracy: 0.6142 - val_loss: 1.2805 - val_accuracy: 0.5404\n",
            "Epoch 15/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.2326 - accuracy: 0.5595 - val_loss: 1.2670 - val_accuracy: 0.5053\n",
            "Epoch 16/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.1883 - accuracy: 0.5693 - val_loss: 1.1623 - val_accuracy: 0.5719\n",
            "Epoch 17/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.9137 - accuracy: 0.6712 - val_loss: 1.0818 - val_accuracy: 0.5965\n",
            "Epoch 18/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.9359 - accuracy: 0.6622 - val_loss: 1.1001 - val_accuracy: 0.5825\n",
            "Epoch 19/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.8114 - accuracy: 0.6982 - val_loss: 0.9772 - val_accuracy: 0.6351\n",
            "Epoch 20/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.7241 - accuracy: 0.7329 - val_loss: 0.9562 - val_accuracy: 0.6421\n",
            "Epoch 21/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.7126 - accuracy: 0.7341 - val_loss: 0.9688 - val_accuracy: 0.6632\n",
            "Epoch 22/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.6609 - accuracy: 0.7614 - val_loss: 0.8802 - val_accuracy: 0.6456\n",
            "Epoch 23/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.5850 - accuracy: 0.7821 - val_loss: 0.8706 - val_accuracy: 0.7018\n",
            "Epoch 24/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.5724 - accuracy: 0.7899 - val_loss: 0.8985 - val_accuracy: 0.6491\n",
            "Epoch 25/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.5353 - accuracy: 0.8094 - val_loss: 1.7064 - val_accuracy: 0.5088\n",
            "Train on 2561 samples, validate on 285 samples\n",
            "Epoch 1/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 2.2188 - accuracy: 0.1882 - val_loss: 1.9956 - val_accuracy: 0.2632\n",
            "Epoch 2/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.9990 - accuracy: 0.2932 - val_loss: 1.7576 - val_accuracy: 0.3544\n",
            "Epoch 3/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.7212 - accuracy: 0.3838 - val_loss: 1.5762 - val_accuracy: 0.4526\n",
            "Epoch 4/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.7007 - accuracy: 0.4198 - val_loss: 1.4657 - val_accuracy: 0.4772\n",
            "Epoch 5/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.4545 - accuracy: 0.4881 - val_loss: 1.3175 - val_accuracy: 0.5684\n",
            "Epoch 6/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.3365 - accuracy: 0.5213 - val_loss: 1.4325 - val_accuracy: 0.4947\n",
            "Epoch 7/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.2938 - accuracy: 0.5365 - val_loss: 1.1295 - val_accuracy: 0.6386\n",
            "Epoch 8/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.2559 - accuracy: 0.5615 - val_loss: 1.1321 - val_accuracy: 0.5930\n",
            "Epoch 9/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.1260 - accuracy: 0.5982 - val_loss: 1.0739 - val_accuracy: 0.6281\n",
            "Epoch 10/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.0486 - accuracy: 0.6291 - val_loss: 1.0148 - val_accuracy: 0.6702\n",
            "Epoch 11/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.0209 - accuracy: 0.6294 - val_loss: 1.2087 - val_accuracy: 0.5754\n",
            "Epoch 12/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.0613 - accuracy: 0.6248 - val_loss: 0.9257 - val_accuracy: 0.7053\n",
            "Epoch 13/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.8571 - accuracy: 0.6947 - val_loss: 0.8471 - val_accuracy: 0.7053\n",
            "Epoch 14/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.7836 - accuracy: 0.7161 - val_loss: 0.8232 - val_accuracy: 0.6982\n",
            "Epoch 15/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.7646 - accuracy: 0.7220 - val_loss: 0.7257 - val_accuracy: 0.7860\n",
            "Epoch 16/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.6655 - accuracy: 0.7544 - val_loss: 0.6856 - val_accuracy: 0.7649\n",
            "Epoch 17/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.6643 - accuracy: 0.7606 - val_loss: 0.8544 - val_accuracy: 0.7333\n",
            "Epoch 18/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.8161 - accuracy: 0.7138 - val_loss: 0.8639 - val_accuracy: 0.7018\n",
            "Epoch 19/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.6938 - accuracy: 0.7450 - val_loss: 1.5693 - val_accuracy: 0.5719\n",
            "Epoch 20/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.0755 - accuracy: 0.6552 - val_loss: 1.1553 - val_accuracy: 0.5965\n",
            "Epoch 21/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 1.0412 - accuracy: 0.6337 - val_loss: 1.0223 - val_accuracy: 0.6386\n",
            "Epoch 22/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.8564 - accuracy: 0.6935 - val_loss: 0.7659 - val_accuracy: 0.7298\n",
            "Epoch 23/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.7221 - accuracy: 0.7474 - val_loss: 0.7701 - val_accuracy: 0.7579\n",
            "Epoch 24/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.6193 - accuracy: 0.7751 - val_loss: 0.7784 - val_accuracy: 0.7404\n",
            "Epoch 25/25\n",
            "2561/2561 [==============================] - 8s 3ms/step - loss: 0.7537 - accuracy: 0.7349 - val_loss: 0.8783 - val_accuracy: 0.6877\n",
            "本実験\n",
            "0回目\n",
            "Train on 2772 samples, validate on 309 samples\n",
            "Epoch 1/25\n",
            "2772/2772 [==============================] - 13s 5ms/step - loss: 2.2839 - accuracy: 0.1338 - val_loss: 2.2766 - val_accuracy: 0.1392\n",
            "Epoch 2/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 2.2196 - accuracy: 0.1742 - val_loss: 2.1223 - val_accuracy: 0.1877\n",
            "Epoch 3/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 2.1510 - accuracy: 0.1840 - val_loss: 2.1695 - val_accuracy: 0.2071\n",
            "Epoch 4/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 2.0824 - accuracy: 0.2017 - val_loss: 1.9801 - val_accuracy: 0.3010\n",
            "Epoch 5/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 2.0061 - accuracy: 0.2388 - val_loss: 1.8739 - val_accuracy: 0.2945\n",
            "Epoch 6/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.9477 - accuracy: 0.2594 - val_loss: 1.8128 - val_accuracy: 0.3301\n",
            "Epoch 7/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.9509 - accuracy: 0.2579 - val_loss: 1.8156 - val_accuracy: 0.2880\n",
            "Epoch 8/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.8683 - accuracy: 0.2886 - val_loss: 1.6893 - val_accuracy: 0.3592\n",
            "Epoch 9/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.8238 - accuracy: 0.3110 - val_loss: 1.6662 - val_accuracy: 0.3819\n",
            "Epoch 10/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.7720 - accuracy: 0.3373 - val_loss: 1.6177 - val_accuracy: 0.3269\n",
            "Epoch 11/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.7623 - accuracy: 0.3330 - val_loss: 1.8223 - val_accuracy: 0.3010\n",
            "Epoch 12/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.7273 - accuracy: 0.3539 - val_loss: 1.5960 - val_accuracy: 0.4045\n",
            "Epoch 13/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.6232 - accuracy: 0.3903 - val_loss: 1.5225 - val_accuracy: 0.4304\n",
            "Epoch 14/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.6133 - accuracy: 0.3939 - val_loss: 1.5509 - val_accuracy: 0.4304\n",
            "Epoch 15/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.5668 - accuracy: 0.4152 - val_loss: 1.5573 - val_accuracy: 0.4013\n",
            "Epoch 16/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.5197 - accuracy: 0.4307 - val_loss: 1.4558 - val_accuracy: 0.4304\n",
            "Epoch 17/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.4442 - accuracy: 0.4625 - val_loss: 1.5133 - val_accuracy: 0.4531\n",
            "Epoch 18/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.4081 - accuracy: 0.4766 - val_loss: 1.4965 - val_accuracy: 0.4175\n",
            "Epoch 19/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.3270 - accuracy: 0.5079 - val_loss: 1.5245 - val_accuracy: 0.4725\n",
            "Epoch 20/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.2794 - accuracy: 0.5375 - val_loss: 1.4155 - val_accuracy: 0.4757\n",
            "Epoch 21/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.1834 - accuracy: 0.5671 - val_loss: 1.4154 - val_accuracy: 0.4984\n",
            "Epoch 22/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.1056 - accuracy: 0.5970 - val_loss: 1.3596 - val_accuracy: 0.5146\n",
            "Epoch 23/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.0654 - accuracy: 0.6118 - val_loss: 1.3707 - val_accuracy: 0.5243\n",
            "Epoch 24/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.0067 - accuracy: 0.6230 - val_loss: 1.4002 - val_accuracy: 0.4919\n",
            "Epoch 25/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 0.9517 - accuracy: 0.6512 - val_loss: 1.5180 - val_accuracy: 0.4272\n",
            "3081/3081 [==============================] - 3s 845us/step\n",
            "3081/3081 [==============================] - 3s 843us/step\n",
            "3081/3081 [==============================] - 3s 829us/step\n",
            "3081/3081 [==============================] - 3s 831us/step\n",
            "Train on 2772 samples, validate on 309 samples\n",
            "Epoch 1/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 2.2809 - accuracy: 0.1324 - val_loss: 2.2282 - val_accuracy: 0.1586\n",
            "Epoch 2/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 2.1725 - accuracy: 0.1861 - val_loss: 1.9901 - val_accuracy: 0.3172\n",
            "Epoch 3/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 2.0459 - accuracy: 0.2395 - val_loss: 1.7443 - val_accuracy: 0.3722\n",
            "Epoch 4/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 2.0146 - accuracy: 0.2572 - val_loss: 1.7278 - val_accuracy: 0.3398\n",
            "Epoch 5/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.9158 - accuracy: 0.2781 - val_loss: 1.6614 - val_accuracy: 0.3560\n",
            "Epoch 6/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.8737 - accuracy: 0.2922 - val_loss: 1.6372 - val_accuracy: 0.3592\n",
            "Epoch 7/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.8209 - accuracy: 0.3185 - val_loss: 1.5671 - val_accuracy: 0.4498\n",
            "Epoch 8/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.8081 - accuracy: 0.3214 - val_loss: 1.5568 - val_accuracy: 0.4304\n",
            "Epoch 9/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.7706 - accuracy: 0.3395 - val_loss: 1.5227 - val_accuracy: 0.4045\n",
            "Epoch 10/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.6794 - accuracy: 0.3730 - val_loss: 1.4906 - val_accuracy: 0.4304\n",
            "Epoch 11/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.6606 - accuracy: 0.3737 - val_loss: 1.5197 - val_accuracy: 0.4175\n",
            "Epoch 12/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.6184 - accuracy: 0.3831 - val_loss: 1.5328 - val_accuracy: 0.4175\n",
            "Epoch 13/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.5884 - accuracy: 0.3979 - val_loss: 1.5264 - val_accuracy: 0.4175\n",
            "Epoch 14/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.5390 - accuracy: 0.4217 - val_loss: 1.4364 - val_accuracy: 0.4466\n",
            "Epoch 15/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.4554 - accuracy: 0.4625 - val_loss: 1.5128 - val_accuracy: 0.4401\n",
            "Epoch 16/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.4110 - accuracy: 0.4805 - val_loss: 1.4187 - val_accuracy: 0.4531\n",
            "Epoch 17/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.3875 - accuracy: 0.4993 - val_loss: 1.3805 - val_accuracy: 0.4887\n",
            "Epoch 18/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.3003 - accuracy: 0.5350 - val_loss: 1.4076 - val_accuracy: 0.4628\n",
            "Epoch 19/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.2484 - accuracy: 0.5346 - val_loss: 1.4719 - val_accuracy: 0.4531\n",
            "Epoch 20/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.1988 - accuracy: 0.5657 - val_loss: 1.4307 - val_accuracy: 0.4595\n",
            "Epoch 21/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.1330 - accuracy: 0.5841 - val_loss: 1.4058 - val_accuracy: 0.4498\n",
            "Epoch 22/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.0947 - accuracy: 0.6165 - val_loss: 1.5021 - val_accuracy: 0.4369\n",
            "Epoch 23/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 1.0396 - accuracy: 0.6227 - val_loss: 1.4548 - val_accuracy: 0.4563\n",
            "Epoch 24/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 0.9536 - accuracy: 0.6645 - val_loss: 1.4822 - val_accuracy: 0.4757\n",
            "Epoch 25/25\n",
            "2772/2772 [==============================] - 9s 3ms/step - loss: 0.9149 - accuracy: 0.6692 - val_loss: 1.4564 - val_accuracy: 0.4951\n",
            "3081/3081 [==============================] - 3s 845us/step\n",
            "3081/3081 [==============================] - 3s 852us/step\n",
            "3081/3081 [==============================] - 3s 856us/step\n",
            "3081/3081 [==============================] - 3s 850us/step\n",
            "1回目\n",
            "Train on 865 samples, validate on 97 samples\n",
            "Epoch 1/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 2.2296 - accuracy: 0.1676 - val_loss: 2.1894 - val_accuracy: 0.2680\n",
            "Epoch 2/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 2.1744 - accuracy: 0.2173 - val_loss: 2.1475 - val_accuracy: 0.2990\n",
            "Epoch 3/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 2.1217 - accuracy: 0.2486 - val_loss: 2.1198 - val_accuracy: 0.2990\n",
            "Epoch 4/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 2.0662 - accuracy: 0.2809 - val_loss: 1.9823 - val_accuracy: 0.3505\n",
            "Epoch 5/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.9731 - accuracy: 0.3006 - val_loss: 1.9698 - val_accuracy: 0.3196\n",
            "Epoch 6/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.9178 - accuracy: 0.3260 - val_loss: 1.9016 - val_accuracy: 0.3814\n",
            "Epoch 7/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.8829 - accuracy: 0.3376 - val_loss: 1.9212 - val_accuracy: 0.3711\n",
            "Epoch 8/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.8222 - accuracy: 0.3607 - val_loss: 1.8305 - val_accuracy: 0.3402\n",
            "Epoch 9/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.7298 - accuracy: 0.3734 - val_loss: 1.7764 - val_accuracy: 0.4227\n",
            "Epoch 10/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.6523 - accuracy: 0.4116 - val_loss: 1.7135 - val_accuracy: 0.3711\n",
            "Epoch 11/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.5647 - accuracy: 0.4416 - val_loss: 1.6397 - val_accuracy: 0.4742\n",
            "Epoch 12/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.4588 - accuracy: 0.4717 - val_loss: 1.6734 - val_accuracy: 0.3711\n",
            "Epoch 13/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.4933 - accuracy: 0.4613 - val_loss: 1.5396 - val_accuracy: 0.3918\n",
            "Epoch 14/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.3811 - accuracy: 0.5098 - val_loss: 1.4707 - val_accuracy: 0.4536\n",
            "Epoch 15/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.2809 - accuracy: 0.5410 - val_loss: 1.3982 - val_accuracy: 0.4330\n",
            "Epoch 16/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.2583 - accuracy: 0.5376 - val_loss: 1.4547 - val_accuracy: 0.4845\n",
            "Epoch 17/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.2232 - accuracy: 0.5549 - val_loss: 1.5334 - val_accuracy: 0.4433\n",
            "Epoch 18/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.1312 - accuracy: 0.6000 - val_loss: 1.4486 - val_accuracy: 0.4742\n",
            "Epoch 19/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.0774 - accuracy: 0.6197 - val_loss: 1.3846 - val_accuracy: 0.4845\n",
            "Epoch 20/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.9963 - accuracy: 0.6277 - val_loss: 1.4372 - val_accuracy: 0.4536\n",
            "Epoch 21/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.9628 - accuracy: 0.6543 - val_loss: 1.3294 - val_accuracy: 0.5155\n",
            "Epoch 22/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.9377 - accuracy: 0.6647 - val_loss: 1.2858 - val_accuracy: 0.5258\n",
            "Epoch 23/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.8794 - accuracy: 0.6960 - val_loss: 1.4344 - val_accuracy: 0.4639\n",
            "Epoch 24/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.7958 - accuracy: 0.7110 - val_loss: 1.3171 - val_accuracy: 0.5361\n",
            "Epoch 25/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.8071 - accuracy: 0.7075 - val_loss: 1.9730 - val_accuracy: 0.4742\n",
            "962/962 [==============================] - 1s 843us/step\n",
            "962/962 [==============================] - 1s 838us/step\n",
            "962/962 [==============================] - 1s 836us/step\n",
            "962/962 [==============================] - 1s 840us/step\n",
            "Train on 865 samples, validate on 97 samples\n",
            "Epoch 1/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 2.2497 - accuracy: 0.1457 - val_loss: 2.1927 - val_accuracy: 0.1753\n",
            "Epoch 2/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 2.1941 - accuracy: 0.1457 - val_loss: 2.1272 - val_accuracy: 0.2474\n",
            "Epoch 3/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 2.0948 - accuracy: 0.2382 - val_loss: 2.0004 - val_accuracy: 0.3093\n",
            "Epoch 4/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.9872 - accuracy: 0.2855 - val_loss: 2.0652 - val_accuracy: 0.2990\n",
            "Epoch 5/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.9152 - accuracy: 0.3121 - val_loss: 1.8844 - val_accuracy: 0.3402\n",
            "Epoch 6/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.8590 - accuracy: 0.3410 - val_loss: 1.7639 - val_accuracy: 0.3505\n",
            "Epoch 7/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.7696 - accuracy: 0.3746 - val_loss: 1.6773 - val_accuracy: 0.3608\n",
            "Epoch 8/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.6472 - accuracy: 0.3884 - val_loss: 1.6489 - val_accuracy: 0.4330\n",
            "Epoch 9/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.6415 - accuracy: 0.4058 - val_loss: 1.5844 - val_accuracy: 0.4021\n",
            "Epoch 10/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.5454 - accuracy: 0.4254 - val_loss: 1.6683 - val_accuracy: 0.3814\n",
            "Epoch 11/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.5074 - accuracy: 0.4370 - val_loss: 1.4510 - val_accuracy: 0.5155\n",
            "Epoch 12/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.4531 - accuracy: 0.4647 - val_loss: 1.5304 - val_accuracy: 0.4124\n",
            "Epoch 13/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.4039 - accuracy: 0.4798 - val_loss: 1.4405 - val_accuracy: 0.5361\n",
            "Epoch 14/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.3699 - accuracy: 0.4994 - val_loss: 1.5492 - val_accuracy: 0.4227\n",
            "Epoch 15/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.3143 - accuracy: 0.5121 - val_loss: 1.4531 - val_accuracy: 0.4845\n",
            "Epoch 16/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.2346 - accuracy: 0.5422 - val_loss: 1.4630 - val_accuracy: 0.5155\n",
            "Epoch 17/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.2057 - accuracy: 0.5642 - val_loss: 1.5197 - val_accuracy: 0.4742\n",
            "Epoch 18/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.1457 - accuracy: 0.5630 - val_loss: 1.4262 - val_accuracy: 0.5155\n",
            "Epoch 19/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.1544 - accuracy: 0.5595 - val_loss: 1.3093 - val_accuracy: 0.5052\n",
            "Epoch 20/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.0787 - accuracy: 0.6012 - val_loss: 1.3041 - val_accuracy: 0.5258\n",
            "Epoch 21/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 1.0160 - accuracy: 0.6185 - val_loss: 1.3136 - val_accuracy: 0.5361\n",
            "Epoch 22/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.9563 - accuracy: 0.6590 - val_loss: 1.4166 - val_accuracy: 0.4742\n",
            "Epoch 23/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.9513 - accuracy: 0.6486 - val_loss: 1.3381 - val_accuracy: 0.5567\n",
            "Epoch 24/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.9174 - accuracy: 0.6428 - val_loss: 1.3714 - val_accuracy: 0.5567\n",
            "Epoch 25/25\n",
            "865/865 [==============================] - 3s 3ms/step - loss: 0.8452 - accuracy: 0.6994 - val_loss: 1.3556 - val_accuracy: 0.5155\n",
            "962/962 [==============================] - 1s 1ms/step\n",
            "962/962 [==============================] - 1s 2ms/step\n",
            "962/962 [==============================] - 1s 1ms/step\n",
            "962/962 [==============================] - 1s 1ms/step\n",
            "2回目\n",
            "Train on 393 samples, validate on 44 samples\n",
            "Epoch 1/25\n",
            "393/393 [==============================] - 2s 4ms/step - loss: 2.2048 - accuracy: 0.1679 - val_loss: 2.1030 - val_accuracy: 0.2500\n",
            "Epoch 2/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 2.1630 - accuracy: 0.1959 - val_loss: 2.1144 - val_accuracy: 0.1364\n",
            "Epoch 3/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 2.1508 - accuracy: 0.1450 - val_loss: 2.1563 - val_accuracy: 0.1364\n",
            "Epoch 4/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 2.1279 - accuracy: 0.2163 - val_loss: 2.1178 - val_accuracy: 0.2500\n",
            "Epoch 5/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 2.0967 - accuracy: 0.2137 - val_loss: 2.0524 - val_accuracy: 0.2727\n",
            "Epoch 6/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 2.0615 - accuracy: 0.2036 - val_loss: 2.0078 - val_accuracy: 0.2500\n",
            "Epoch 7/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 2.0902 - accuracy: 0.2137 - val_loss: 2.0488 - val_accuracy: 0.2045\n",
            "Epoch 8/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 2.0636 - accuracy: 0.2290 - val_loss: 2.1087 - val_accuracy: 0.2955\n",
            "Epoch 9/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 2.0230 - accuracy: 0.2926 - val_loss: 1.9846 - val_accuracy: 0.2727\n",
            "Epoch 10/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.9992 - accuracy: 0.2443 - val_loss: 1.9494 - val_accuracy: 0.3182\n",
            "Epoch 11/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.9134 - accuracy: 0.2926 - val_loss: 1.8800 - val_accuracy: 0.4091\n",
            "Epoch 12/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.8493 - accuracy: 0.3384 - val_loss: 1.8914 - val_accuracy: 0.4545\n",
            "Epoch 13/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.8286 - accuracy: 0.4020 - val_loss: 1.7674 - val_accuracy: 0.4091\n",
            "Epoch 14/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.8052 - accuracy: 0.3435 - val_loss: 1.8922 - val_accuracy: 0.3409\n",
            "Epoch 15/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.8187 - accuracy: 0.3511 - val_loss: 1.7208 - val_accuracy: 0.4318\n",
            "Epoch 16/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.7372 - accuracy: 0.4427 - val_loss: 1.6792 - val_accuracy: 0.4318\n",
            "Epoch 17/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.7094 - accuracy: 0.4122 - val_loss: 1.6521 - val_accuracy: 0.4773\n",
            "Epoch 18/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.6267 - accuracy: 0.4478 - val_loss: 1.6074 - val_accuracy: 0.4091\n",
            "Epoch 19/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.5125 - accuracy: 0.5369 - val_loss: 1.4795 - val_accuracy: 0.4545\n",
            "Epoch 20/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.4865 - accuracy: 0.5038 - val_loss: 1.5668 - val_accuracy: 0.4091\n",
            "Epoch 21/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.5402 - accuracy: 0.4911 - val_loss: 1.4680 - val_accuracy: 0.5455\n",
            "Epoch 22/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.4442 - accuracy: 0.5420 - val_loss: 1.4178 - val_accuracy: 0.5000\n",
            "Epoch 23/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.3982 - accuracy: 0.5165 - val_loss: 1.3190 - val_accuracy: 0.4773\n",
            "Epoch 24/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.2976 - accuracy: 0.5471 - val_loss: 1.3553 - val_accuracy: 0.4545\n",
            "Epoch 25/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.3457 - accuracy: 0.5216 - val_loss: 1.3547 - val_accuracy: 0.5227\n",
            "437/437 [==============================] - 0s 849us/step\n",
            "437/437 [==============================] - 0s 836us/step\n",
            "437/437 [==============================] - 0s 831us/step\n",
            "437/437 [==============================] - 0s 848us/step\n",
            "Train on 393 samples, validate on 44 samples\n",
            "Epoch 1/25\n",
            "393/393 [==============================] - 2s 4ms/step - loss: 2.1562 - accuracy: 0.1908 - val_loss: 1.9358 - val_accuracy: 0.2955\n",
            "Epoch 2/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.9717 - accuracy: 0.3028 - val_loss: 1.9633 - val_accuracy: 0.0682\n",
            "Epoch 3/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.9249 - accuracy: 0.2570 - val_loss: 2.0374 - val_accuracy: 0.2500\n",
            "Epoch 4/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.9511 - accuracy: 0.2494 - val_loss: 1.9011 - val_accuracy: 0.2500\n",
            "Epoch 5/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.8707 - accuracy: 0.2723 - val_loss: 1.8131 - val_accuracy: 0.2955\n",
            "Epoch 6/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.8587 - accuracy: 0.2850 - val_loss: 1.9055 - val_accuracy: 0.2955\n",
            "Epoch 7/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.8581 - accuracy: 0.3232 - val_loss: 1.9497 - val_accuracy: 0.2955\n",
            "Epoch 8/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.8642 - accuracy: 0.3282 - val_loss: 1.8427 - val_accuracy: 0.3182\n",
            "Epoch 9/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.7618 - accuracy: 0.3486 - val_loss: 1.7364 - val_accuracy: 0.3636\n",
            "Epoch 10/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.7506 - accuracy: 0.3740 - val_loss: 1.6956 - val_accuracy: 0.4545\n",
            "Epoch 11/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.6212 - accuracy: 0.4427 - val_loss: 1.6881 - val_accuracy: 0.4545\n",
            "Epoch 12/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.5629 - accuracy: 0.5013 - val_loss: 1.8247 - val_accuracy: 0.3409\n",
            "Epoch 13/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.5610 - accuracy: 0.4733 - val_loss: 1.6320 - val_accuracy: 0.2500\n",
            "Epoch 14/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.4671 - accuracy: 0.5344 - val_loss: 2.0129 - val_accuracy: 0.3636\n",
            "Epoch 15/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.6055 - accuracy: 0.4885 - val_loss: 1.5284 - val_accuracy: 0.4091\n",
            "Epoch 16/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.4879 - accuracy: 0.4835 - val_loss: 1.4025 - val_accuracy: 0.5227\n",
            "Epoch 17/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.3488 - accuracy: 0.5420 - val_loss: 1.5267 - val_accuracy: 0.4318\n",
            "Epoch 18/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.3685 - accuracy: 0.5267 - val_loss: 1.3710 - val_accuracy: 0.4545\n",
            "Epoch 19/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.2529 - accuracy: 0.5852 - val_loss: 1.2453 - val_accuracy: 0.4545\n",
            "Epoch 20/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.2201 - accuracy: 0.5827 - val_loss: 1.2765 - val_accuracy: 0.5000\n",
            "Epoch 21/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.1568 - accuracy: 0.6336 - val_loss: 1.2969 - val_accuracy: 0.5000\n",
            "Epoch 22/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.0969 - accuracy: 0.6361 - val_loss: 1.1167 - val_accuracy: 0.5455\n",
            "Epoch 23/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 1.0319 - accuracy: 0.6463 - val_loss: 1.0487 - val_accuracy: 0.5682\n",
            "Epoch 24/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 0.9416 - accuracy: 0.6896 - val_loss: 1.0556 - val_accuracy: 0.6364\n",
            "Epoch 25/25\n",
            "393/393 [==============================] - 1s 3ms/step - loss: 0.9276 - accuracy: 0.6819 - val_loss: 1.2080 - val_accuracy: 0.5455\n",
            "437/437 [==============================] - 0s 841us/step\n",
            "437/437 [==============================] - 0s 824us/step\n",
            "437/437 [==============================] - 0s 829us/step\n",
            "437/437 [==============================] - 0s 839us/step\n",
            "3回目\n",
            "Train on 259 samples, validate on 29 samples\n",
            "Epoch 1/25\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 2.1672 - accuracy: 0.2124 - val_loss: 1.9496 - val_accuracy: 0.3103\n",
            "Epoch 2/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.9943 - accuracy: 0.2703 - val_loss: 1.9989 - val_accuracy: 0.3448\n",
            "Epoch 3/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.9718 - accuracy: 0.2317 - val_loss: 1.9873 - val_accuracy: 0.4138\n",
            "Epoch 4/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.9117 - accuracy: 0.3243 - val_loss: 1.9148 - val_accuracy: 0.3103\n",
            "Epoch 5/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.9174 - accuracy: 0.2780 - val_loss: 1.8778 - val_accuracy: 0.3103\n",
            "Epoch 6/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.9404 - accuracy: 0.2703 - val_loss: 1.9087 - val_accuracy: 0.3103\n",
            "Epoch 7/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.8882 - accuracy: 0.3050 - val_loss: 2.0172 - val_accuracy: 0.3103\n",
            "Epoch 8/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.9691 - accuracy: 0.2780 - val_loss: 1.9473 - val_accuracy: 0.3103\n",
            "Epoch 9/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.9026 - accuracy: 0.2857 - val_loss: 1.8306 - val_accuracy: 0.3103\n",
            "Epoch 10/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.8746 - accuracy: 0.2857 - val_loss: 1.8358 - val_accuracy: 0.3103\n",
            "Epoch 11/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.8959 - accuracy: 0.2857 - val_loss: 1.8327 - val_accuracy: 0.3103\n",
            "Epoch 12/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.8072 - accuracy: 0.3127 - val_loss: 1.8493 - val_accuracy: 0.4483\n",
            "Epoch 13/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.7684 - accuracy: 0.3977 - val_loss: 1.8061 - val_accuracy: 0.4483\n",
            "Epoch 14/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.7476 - accuracy: 0.4054 - val_loss: 1.8076 - val_accuracy: 0.3793\n",
            "Epoch 15/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.7249 - accuracy: 0.4286 - val_loss: 1.7626 - val_accuracy: 0.3103\n",
            "Epoch 16/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.6769 - accuracy: 0.4440 - val_loss: 1.7745 - val_accuracy: 0.3448\n",
            "Epoch 17/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.7290 - accuracy: 0.4170 - val_loss: 1.8658 - val_accuracy: 0.3103\n",
            "Epoch 18/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.7568 - accuracy: 0.3629 - val_loss: 1.7381 - val_accuracy: 0.4138\n",
            "Epoch 19/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.6802 - accuracy: 0.4479 - val_loss: 1.7621 - val_accuracy: 0.4483\n",
            "Epoch 20/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.6926 - accuracy: 0.4324 - val_loss: 1.7228 - val_accuracy: 0.4483\n",
            "Epoch 21/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.5820 - accuracy: 0.5174 - val_loss: 1.7385 - val_accuracy: 0.3793\n",
            "Epoch 22/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.5816 - accuracy: 0.4672 - val_loss: 1.7384 - val_accuracy: 0.4483\n",
            "Epoch 23/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.5941 - accuracy: 0.4942 - val_loss: 1.7563 - val_accuracy: 0.4138\n",
            "Epoch 24/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.5792 - accuracy: 0.5019 - val_loss: 1.6780 - val_accuracy: 0.4828\n",
            "Epoch 25/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.5139 - accuracy: 0.5058 - val_loss: 1.6635 - val_accuracy: 0.4483\n",
            "288/288 [==============================] - 0s 820us/step\n",
            "288/288 [==============================] - 0s 872us/step\n",
            "288/288 [==============================] - 0s 833us/step\n",
            "288/288 [==============================] - 0s 830us/step\n",
            "Train on 259 samples, validate on 29 samples\n",
            "Epoch 1/25\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 2.2287 - accuracy: 0.1544 - val_loss: 1.9115 - val_accuracy: 0.3793\n",
            "Epoch 2/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.7321 - accuracy: 0.3552 - val_loss: 1.7348 - val_accuracy: 0.3793\n",
            "Epoch 3/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.7848 - accuracy: 0.3475 - val_loss: 1.7419 - val_accuracy: 0.1724\n",
            "Epoch 4/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.6869 - accuracy: 0.2741 - val_loss: 1.6947 - val_accuracy: 0.3448\n",
            "Epoch 5/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.5494 - accuracy: 0.3784 - val_loss: 1.5846 - val_accuracy: 0.5172\n",
            "Epoch 6/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.5240 - accuracy: 0.3977 - val_loss: 1.5161 - val_accuracy: 0.3793\n",
            "Epoch 7/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.5535 - accuracy: 0.3707 - val_loss: 1.5000 - val_accuracy: 0.3793\n",
            "Epoch 8/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.4602 - accuracy: 0.4633 - val_loss: 1.4373 - val_accuracy: 0.5172\n",
            "Epoch 9/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.3975 - accuracy: 0.4093 - val_loss: 1.4361 - val_accuracy: 0.4828\n",
            "Epoch 10/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.3517 - accuracy: 0.4208 - val_loss: 1.4503 - val_accuracy: 0.6897\n",
            "Epoch 11/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.3100 - accuracy: 0.6216 - val_loss: 1.2981 - val_accuracy: 0.6552\n",
            "Epoch 12/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.2130 - accuracy: 0.5946 - val_loss: 1.2237 - val_accuracy: 0.6207\n",
            "Epoch 13/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.1655 - accuracy: 0.5444 - val_loss: 1.1171 - val_accuracy: 0.5517\n",
            "Epoch 14/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 1.0488 - accuracy: 0.6216 - val_loss: 1.0587 - val_accuracy: 0.6552\n",
            "Epoch 15/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.9654 - accuracy: 0.6873 - val_loss: 1.0280 - val_accuracy: 0.6552\n",
            "Epoch 16/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.9099 - accuracy: 0.6988 - val_loss: 0.8866 - val_accuracy: 0.6552\n",
            "Epoch 17/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.8129 - accuracy: 0.7336 - val_loss: 0.8004 - val_accuracy: 0.6897\n",
            "Epoch 18/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.7383 - accuracy: 0.7799 - val_loss: 0.7882 - val_accuracy: 0.6897\n",
            "Epoch 19/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.6783 - accuracy: 0.7722 - val_loss: 0.7996 - val_accuracy: 0.6552\n",
            "Epoch 20/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.7915 - val_loss: 0.7591 - val_accuracy: 0.7931\n",
            "Epoch 21/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.6485 - accuracy: 0.7915 - val_loss: 0.6500 - val_accuracy: 0.7931\n",
            "Epoch 22/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.5955 - accuracy: 0.7915 - val_loss: 0.9609 - val_accuracy: 0.6552\n",
            "Epoch 23/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.5343 - accuracy: 0.8108 - val_loss: 0.8668 - val_accuracy: 0.5862\n",
            "Epoch 24/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.6412 - accuracy: 0.7761 - val_loss: 1.4097 - val_accuracy: 0.5862\n",
            "Epoch 25/25\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.7846 - accuracy: 0.7375 - val_loss: 0.8045 - val_accuracy: 0.6897\n",
            "288/288 [==============================] - 0s 837us/step\n",
            "288/288 [==============================] - 0s 841us/step\n",
            "288/288 [==============================] - 0s 849us/step\n",
            "288/288 [==============================] - 0s 831us/step\n",
            "4回目\n",
            "Train on 171 samples, validate on 19 samples\n",
            "Epoch 1/25\n",
            "171/171 [==============================] - 1s 4ms/step - loss: 2.2689 - accuracy: 0.1404 - val_loss: 1.9608 - val_accuracy: 0.3684\n",
            "Epoch 2/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.8550 - accuracy: 0.3041 - val_loss: 1.6105 - val_accuracy: 0.3158\n",
            "Epoch 3/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.7683 - accuracy: 0.3041 - val_loss: 1.6619 - val_accuracy: 0.4737\n",
            "Epoch 4/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.6807 - accuracy: 0.3275 - val_loss: 1.6935 - val_accuracy: 0.4737\n",
            "Epoch 5/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.6487 - accuracy: 0.3567 - val_loss: 1.7065 - val_accuracy: 0.4211\n",
            "Epoch 6/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.5939 - accuracy: 0.4269 - val_loss: 1.5922 - val_accuracy: 0.5263\n",
            "Epoch 7/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.5973 - accuracy: 0.3450 - val_loss: 1.4693 - val_accuracy: 0.5789\n",
            "Epoch 8/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.5214 - accuracy: 0.3860 - val_loss: 1.4217 - val_accuracy: 0.6842\n",
            "Epoch 9/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.4068 - accuracy: 0.6140 - val_loss: 1.3924 - val_accuracy: 0.6842\n",
            "Epoch 10/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.3551 - accuracy: 0.5848 - val_loss: 1.2099 - val_accuracy: 0.7368\n",
            "Epoch 11/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.2907 - accuracy: 0.6257 - val_loss: 1.1652 - val_accuracy: 0.7368\n",
            "Epoch 12/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.1888 - accuracy: 0.6725 - val_loss: 1.2015 - val_accuracy: 0.7895\n",
            "Epoch 13/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.1123 - accuracy: 0.6842 - val_loss: 1.1149 - val_accuracy: 0.6316\n",
            "Epoch 14/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.0904 - accuracy: 0.6667 - val_loss: 0.9850 - val_accuracy: 0.7368\n",
            "Epoch 15/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.0151 - accuracy: 0.7485 - val_loss: 0.9507 - val_accuracy: 0.7895\n",
            "Epoch 16/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.9851 - accuracy: 0.7661 - val_loss: 0.8474 - val_accuracy: 0.7895\n",
            "Epoch 17/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.9624 - accuracy: 0.7719 - val_loss: 0.7992 - val_accuracy: 0.8947\n",
            "Epoch 18/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.8133 - accuracy: 0.7836 - val_loss: 0.8208 - val_accuracy: 0.7368\n",
            "Epoch 19/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.7896 - accuracy: 0.8012 - val_loss: 0.7003 - val_accuracy: 0.8947\n",
            "Epoch 20/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.7178 - accuracy: 0.8304 - val_loss: 0.7058 - val_accuracy: 0.8947\n",
            "Epoch 21/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.7595 - accuracy: 0.7953 - val_loss: 0.7584 - val_accuracy: 0.7368\n",
            "Epoch 22/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.7730 - accuracy: 0.8070 - val_loss: 0.5603 - val_accuracy: 0.8947\n",
            "Epoch 23/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.6447 - accuracy: 0.8363 - val_loss: 0.5272 - val_accuracy: 0.8947\n",
            "Epoch 24/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.6262 - accuracy: 0.8421 - val_loss: 0.5775 - val_accuracy: 0.8421\n",
            "Epoch 25/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.6209 - accuracy: 0.8421 - val_loss: 0.5983 - val_accuracy: 0.8947\n",
            "190/190 [==============================] - 0s 850us/step\n",
            "190/190 [==============================] - 0s 854us/step\n",
            "190/190 [==============================] - 0s 836us/step\n",
            "190/190 [==============================] - 0s 833us/step\n",
            "Train on 171 samples, validate on 19 samples\n",
            "Epoch 1/25\n",
            "171/171 [==============================] - 1s 5ms/step - loss: 2.1660 - accuracy: 0.1813 - val_loss: 1.4769 - val_accuracy: 0.5263\n",
            "Epoch 2/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.4925 - accuracy: 0.4386 - val_loss: 1.3165 - val_accuracy: 0.2105\n",
            "Epoch 3/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.3976 - accuracy: 0.4561 - val_loss: 1.2700 - val_accuracy: 0.2105\n",
            "Epoch 4/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.2056 - accuracy: 0.4795 - val_loss: 1.1914 - val_accuracy: 0.6842\n",
            "Epoch 5/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.2120 - accuracy: 0.4561 - val_loss: 1.2138 - val_accuracy: 0.7368\n",
            "Epoch 6/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.0688 - accuracy: 0.6023 - val_loss: 1.0616 - val_accuracy: 0.7368\n",
            "Epoch 7/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 1.0167 - accuracy: 0.6842 - val_loss: 1.0122 - val_accuracy: 0.6842\n",
            "Epoch 8/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.8677 - accuracy: 0.7251 - val_loss: 0.7453 - val_accuracy: 0.7368\n",
            "Epoch 9/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.7539 - accuracy: 0.7427 - val_loss: 0.7133 - val_accuracy: 0.8421\n",
            "Epoch 10/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.6461 - accuracy: 0.7719 - val_loss: 0.5741 - val_accuracy: 0.7368\n",
            "Epoch 11/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.5659 - accuracy: 0.7310 - val_loss: 0.5195 - val_accuracy: 0.7895\n",
            "Epoch 12/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.5045 - accuracy: 0.7953 - val_loss: 0.4591 - val_accuracy: 0.8947\n",
            "Epoch 13/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.4154 - accuracy: 0.8655 - val_loss: 0.4519 - val_accuracy: 0.9474\n",
            "Epoch 14/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.3946 - accuracy: 0.8596 - val_loss: 0.3240 - val_accuracy: 0.8947\n",
            "Epoch 15/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8538 - val_loss: 0.3073 - val_accuracy: 0.9474\n",
            "Epoch 16/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.4633 - accuracy: 0.8070 - val_loss: 0.2525 - val_accuracy: 0.8947\n",
            "Epoch 17/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.2928 - accuracy: 0.9006 - val_loss: 0.3350 - val_accuracy: 0.9474\n",
            "Epoch 18/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8830 - val_loss: 0.2272 - val_accuracy: 0.9474\n",
            "Epoch 19/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.3613 - accuracy: 0.8596 - val_loss: 0.1501 - val_accuracy: 0.9474\n",
            "Epoch 20/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.2308 - accuracy: 0.9123 - val_loss: 0.1468 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.2144 - accuracy: 0.9357 - val_loss: 0.1160 - val_accuracy: 0.9474\n",
            "Epoch 22/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9298 - val_loss: 0.1208 - val_accuracy: 0.9474\n",
            "Epoch 23/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9415 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.9357 - val_loss: 0.0879 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "171/171 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9649 - val_loss: 0.0862 - val_accuracy: 0.9474\n",
            "190/190 [==============================] - 0s 845us/step\n",
            "190/190 [==============================] - 0s 831us/step\n",
            "190/190 [==============================] - 0s 861us/step\n",
            "190/190 [==============================] - 0s 833us/step\n",
            "5回目\n",
            "Train on 162 samples, validate on 18 samples\n",
            "Epoch 1/25\n",
            "162/162 [==============================] - 1s 4ms/step - loss: 2.2099 - accuracy: 0.2160 - val_loss: 1.7775 - val_accuracy: 0.3889\n",
            "Epoch 2/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.7312 - accuracy: 0.3580 - val_loss: 1.6158 - val_accuracy: 0.2778\n",
            "Epoch 3/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.6825 - accuracy: 0.2469 - val_loss: 1.6019 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.5855 - accuracy: 0.3333 - val_loss: 1.6471 - val_accuracy: 0.4444\n",
            "Epoch 5/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.5882 - accuracy: 0.3827 - val_loss: 1.6284 - val_accuracy: 0.4444\n",
            "Epoch 6/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.5863 - accuracy: 0.3704 - val_loss: 1.5472 - val_accuracy: 0.6111\n",
            "Epoch 7/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.5526 - accuracy: 0.3210 - val_loss: 1.4904 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.4955 - accuracy: 0.4383 - val_loss: 1.4608 - val_accuracy: 0.5556\n",
            "Epoch 9/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.3390 - accuracy: 0.5741 - val_loss: 1.3859 - val_accuracy: 0.6667\n",
            "Epoch 10/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.3231 - accuracy: 0.5617 - val_loss: 1.2313 - val_accuracy: 0.6111\n",
            "Epoch 11/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.2793 - accuracy: 0.5432 - val_loss: 1.3141 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.1940 - accuracy: 0.6111 - val_loss: 1.1678 - val_accuracy: 0.7222\n",
            "Epoch 13/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.1007 - accuracy: 0.6420 - val_loss: 1.0606 - val_accuracy: 0.7222\n",
            "Epoch 14/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.1087 - accuracy: 0.6667 - val_loss: 1.1114 - val_accuracy: 0.6667\n",
            "Epoch 15/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.0245 - accuracy: 0.6790 - val_loss: 1.1270 - val_accuracy: 0.6111\n",
            "Epoch 16/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.9706 - accuracy: 0.7284 - val_loss: 0.9161 - val_accuracy: 0.7778\n",
            "Epoch 17/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.8622 - accuracy: 0.7716 - val_loss: 0.8504 - val_accuracy: 0.8333\n",
            "Epoch 18/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.7789 - accuracy: 0.8333 - val_loss: 0.7880 - val_accuracy: 0.8889\n",
            "Epoch 19/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.7282 - accuracy: 0.8210 - val_loss: 0.7964 - val_accuracy: 0.8333\n",
            "Epoch 20/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.7615 - accuracy: 0.8210 - val_loss: 0.7283 - val_accuracy: 0.8889\n",
            "Epoch 21/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.6755 - accuracy: 0.8210 - val_loss: 0.6259 - val_accuracy: 0.8889\n",
            "Epoch 22/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.6622 - accuracy: 0.8395 - val_loss: 0.5993 - val_accuracy: 0.9444\n",
            "Epoch 23/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.5857 - accuracy: 0.8704 - val_loss: 0.5836 - val_accuracy: 0.8889\n",
            "Epoch 24/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.5669 - accuracy: 0.8642 - val_loss: 0.5917 - val_accuracy: 0.8889\n",
            "Epoch 25/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.5757 - accuracy: 0.8580 - val_loss: 0.6186 - val_accuracy: 0.8333\n",
            "180/180 [==============================] - 0s 850us/step\n",
            "180/180 [==============================] - 0s 852us/step\n",
            "180/180 [==============================] - 0s 851us/step\n",
            "180/180 [==============================] - 0s 886us/step\n",
            "Train on 162 samples, validate on 18 samples\n",
            "Epoch 1/25\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 2.2416 - accuracy: 0.1235 - val_loss: 1.6673 - val_accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.5659 - accuracy: 0.4136 - val_loss: 1.3082 - val_accuracy: 0.2778\n",
            "Epoch 3/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.3858 - accuracy: 0.4444 - val_loss: 1.3007 - val_accuracy: 0.2222\n",
            "Epoch 4/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.3331 - accuracy: 0.4198 - val_loss: 1.2159 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.3389 - accuracy: 0.4198 - val_loss: 1.2993 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.3011 - accuracy: 0.4136 - val_loss: 1.3654 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.2551 - accuracy: 0.4506 - val_loss: 1.2960 - val_accuracy: 0.6111\n",
            "Epoch 8/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.2044 - accuracy: 0.5247 - val_loss: 1.1722 - val_accuracy: 0.6667\n",
            "Epoch 9/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.1711 - accuracy: 0.5679 - val_loss: 1.0912 - val_accuracy: 0.6667\n",
            "Epoch 10/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.0831 - accuracy: 0.6296 - val_loss: 0.9473 - val_accuracy: 0.8333\n",
            "Epoch 11/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.9652 - accuracy: 0.7099 - val_loss: 0.8258 - val_accuracy: 0.7778\n",
            "Epoch 12/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.8859 - accuracy: 0.7222 - val_loss: 0.8899 - val_accuracy: 0.8889\n",
            "Epoch 13/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.7702 - accuracy: 0.7716 - val_loss: 0.6637 - val_accuracy: 0.7222\n",
            "Epoch 14/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.6613 - accuracy: 0.7654 - val_loss: 0.6553 - val_accuracy: 0.8889\n",
            "Epoch 15/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.5333 - accuracy: 0.8025 - val_loss: 0.5411 - val_accuracy: 0.8889\n",
            "Epoch 16/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.8519 - val_loss: 0.4311 - val_accuracy: 0.8889\n",
            "Epoch 17/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.3921 - accuracy: 0.8642 - val_loss: 0.5006 - val_accuracy: 0.7778\n",
            "Epoch 18/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.4738 - accuracy: 0.8025 - val_loss: 0.3018 - val_accuracy: 0.9444\n",
            "Epoch 19/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.3789 - accuracy: 0.8765 - val_loss: 0.2492 - val_accuracy: 0.8889\n",
            "Epoch 20/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.9259 - val_loss: 0.2190 - val_accuracy: 0.9444\n",
            "Epoch 21/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8765 - val_loss: 0.1750 - val_accuracy: 0.9444\n",
            "Epoch 22/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.2312 - accuracy: 0.9136 - val_loss: 0.2231 - val_accuracy: 0.9444\n",
            "Epoch 23/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.1730 - accuracy: 0.9630 - val_loss: 0.2275 - val_accuracy: 0.9444\n",
            "Epoch 24/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.1753 - accuracy: 0.9444 - val_loss: 0.1196 - val_accuracy: 0.9444\n",
            "Epoch 25/25\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 0.1702 - accuracy: 0.9321 - val_loss: 0.1438 - val_accuracy: 0.9444\n",
            "180/180 [==============================] - 0s 880us/step\n",
            "180/180 [==============================] - 0s 839us/step\n",
            "180/180 [==============================] - 0s 849us/step\n",
            "180/180 [==============================] - 0s 836us/step\n",
            "6回目\n",
            "Train on 148 samples, validate on 17 samples\n",
            "Epoch 1/25\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.2186 - accuracy: 0.1419 - val_loss: 1.5989 - val_accuracy: 0.3529\n",
            "Epoch 2/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.5705 - accuracy: 0.3311 - val_loss: 1.4896 - val_accuracy: 0.3529\n",
            "Epoch 3/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.6304 - accuracy: 0.3311 - val_loss: 1.4940 - val_accuracy: 0.5882\n",
            "Epoch 4/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.4537 - accuracy: 0.3851 - val_loss: 1.5451 - val_accuracy: 0.5294\n",
            "Epoch 5/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.4490 - accuracy: 0.3986 - val_loss: 1.5601 - val_accuracy: 0.4706\n",
            "Epoch 6/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.5022 - accuracy: 0.3919 - val_loss: 1.5092 - val_accuracy: 0.4706\n",
            "Epoch 7/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.4480 - accuracy: 0.4122 - val_loss: 1.4497 - val_accuracy: 0.5294\n",
            "Epoch 8/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.3776 - accuracy: 0.4392 - val_loss: 1.4732 - val_accuracy: 0.4706\n",
            "Epoch 9/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.3243 - accuracy: 0.5000 - val_loss: 1.3220 - val_accuracy: 0.5882\n",
            "Epoch 10/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.2431 - accuracy: 0.4932 - val_loss: 1.2624 - val_accuracy: 0.6471\n",
            "Epoch 11/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.1728 - accuracy: 0.6419 - val_loss: 1.3093 - val_accuracy: 0.5882\n",
            "Epoch 12/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.1252 - accuracy: 0.6284 - val_loss: 1.1575 - val_accuracy: 0.5882\n",
            "Epoch 13/25\n",
            "148/148 [==============================] - 1s 3ms/step - loss: 1.0819 - accuracy: 0.6014 - val_loss: 1.1183 - val_accuracy: 0.5882\n",
            "Epoch 14/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.9280 - accuracy: 0.6892 - val_loss: 1.1565 - val_accuracy: 0.6471\n",
            "Epoch 15/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.9560 - accuracy: 0.6892 - val_loss: 1.0055 - val_accuracy: 0.6471\n",
            "Epoch 16/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.9529 - accuracy: 0.6554 - val_loss: 0.9238 - val_accuracy: 0.7059\n",
            "Epoch 17/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.8537 - accuracy: 0.7027 - val_loss: 1.0277 - val_accuracy: 0.7059\n",
            "Epoch 18/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.8219 - accuracy: 0.7568 - val_loss: 0.8741 - val_accuracy: 0.5882\n",
            "Epoch 19/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.7869 - accuracy: 0.7365 - val_loss: 0.8219 - val_accuracy: 0.6471\n",
            "Epoch 20/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.7838 - val_loss: 0.9302 - val_accuracy: 0.7647\n",
            "Epoch 21/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.7635 - val_loss: 0.6696 - val_accuracy: 0.8235\n",
            "Epoch 22/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.8649 - val_loss: 0.8756 - val_accuracy: 0.7647\n",
            "Epoch 23/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.8443 - accuracy: 0.7500 - val_loss: 0.5992 - val_accuracy: 0.9412\n",
            "Epoch 24/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.8784 - val_loss: 0.7973 - val_accuracy: 0.7059\n",
            "Epoch 25/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.8446 - val_loss: 1.0341 - val_accuracy: 0.5882\n",
            "165/165 [==============================] - 0s 900us/step\n",
            "165/165 [==============================] - 0s 852us/step\n",
            "165/165 [==============================] - 0s 884us/step\n",
            "165/165 [==============================] - 0s 858us/step\n",
            "Train on 148 samples, validate on 17 samples\n",
            "Epoch 1/25\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 2.2389 - accuracy: 0.1554 - val_loss: 1.6800 - val_accuracy: 0.2941\n",
            "Epoch 2/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.5748 - accuracy: 0.3514 - val_loss: 1.2947 - val_accuracy: 0.5294\n",
            "Epoch 3/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.4169 - accuracy: 0.3851 - val_loss: 1.2633 - val_accuracy: 0.2941\n",
            "Epoch 4/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.2645 - accuracy: 0.4662 - val_loss: 1.2614 - val_accuracy: 0.2353\n",
            "Epoch 5/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.2053 - accuracy: 0.5135 - val_loss: 1.1928 - val_accuracy: 0.6471\n",
            "Epoch 6/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.1783 - accuracy: 0.5405 - val_loss: 1.1792 - val_accuracy: 0.6471\n",
            "Epoch 7/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.1821 - accuracy: 0.5135 - val_loss: 1.1932 - val_accuracy: 0.5882\n",
            "Epoch 8/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 1.0622 - accuracy: 0.6149 - val_loss: 1.0692 - val_accuracy: 0.4706\n",
            "Epoch 9/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.9582 - accuracy: 0.6284 - val_loss: 0.8306 - val_accuracy: 0.6471\n",
            "Epoch 10/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.7884 - accuracy: 0.7162 - val_loss: 0.7262 - val_accuracy: 0.6471\n",
            "Epoch 11/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7365 - val_loss: 0.6706 - val_accuracy: 0.7647\n",
            "Epoch 12/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.7568 - val_loss: 0.5986 - val_accuracy: 0.8824\n",
            "Epoch 13/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7500 - val_loss: 0.7608 - val_accuracy: 0.6471\n",
            "Epoch 14/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7838 - val_loss: 0.4406 - val_accuracy: 0.8824\n",
            "Epoch 15/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7568 - val_loss: 0.3938 - val_accuracy: 0.8824\n",
            "Epoch 16/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8378 - val_loss: 0.3789 - val_accuracy: 0.8235\n",
            "Epoch 17/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8649 - val_loss: 0.4043 - val_accuracy: 0.8824\n",
            "Epoch 18/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7973 - val_loss: 0.3584 - val_accuracy: 0.9412\n",
            "Epoch 19/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8784 - val_loss: 0.3289 - val_accuracy: 0.8824\n",
            "Epoch 20/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8581 - val_loss: 0.2757 - val_accuracy: 0.8824\n",
            "Epoch 21/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8311 - val_loss: 0.3268 - val_accuracy: 0.8824\n",
            "Epoch 22/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8514 - val_loss: 0.1791 - val_accuracy: 0.9412\n",
            "Epoch 23/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.9257 - val_loss: 0.2901 - val_accuracy: 0.8824\n",
            "Epoch 24/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8514 - val_loss: 0.1674 - val_accuracy: 0.9412\n",
            "Epoch 25/25\n",
            "148/148 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9189 - val_loss: 0.2213 - val_accuracy: 0.9412\n",
            "165/165 [==============================] - 0s 844us/step\n",
            "165/165 [==============================] - 0s 909us/step\n",
            "165/165 [==============================] - 0s 846us/step\n",
            "165/165 [==============================] - 0s 851us/step\n",
            "7回目\n",
            "Train on 117 samples, validate on 14 samples\n",
            "Epoch 1/25\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 2.4017 - accuracy: 0.0427 - val_loss: 2.2273 - val_accuracy: 0.2857\n",
            "Epoch 2/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 2.1883 - accuracy: 0.3504 - val_loss: 2.0992 - val_accuracy: 0.2857\n",
            "Epoch 3/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.9851 - accuracy: 0.4701 - val_loss: 1.8989 - val_accuracy: 0.2857\n",
            "Epoch 4/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.7280 - accuracy: 0.4872 - val_loss: 1.6447 - val_accuracy: 0.2857\n",
            "Epoch 5/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.5016 - accuracy: 0.4444 - val_loss: 1.5269 - val_accuracy: 0.2857\n",
            "Epoch 6/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.5668 - accuracy: 0.4786 - val_loss: 1.4655 - val_accuracy: 0.5714\n",
            "Epoch 7/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.4047 - accuracy: 0.4359 - val_loss: 1.4140 - val_accuracy: 0.5714\n",
            "Epoch 8/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.4186 - accuracy: 0.4274 - val_loss: 1.4262 - val_accuracy: 0.5714\n",
            "Epoch 9/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.3385 - accuracy: 0.4017 - val_loss: 1.4525 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.3505 - accuracy: 0.3932 - val_loss: 1.4690 - val_accuracy: 0.4286\n",
            "Epoch 11/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.2604 - accuracy: 0.4872 - val_loss: 1.4851 - val_accuracy: 0.4286\n",
            "Epoch 12/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.2510 - accuracy: 0.5385 - val_loss: 1.4899 - val_accuracy: 0.4286\n",
            "Epoch 13/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.2252 - accuracy: 0.5385 - val_loss: 1.4754 - val_accuracy: 0.4286\n",
            "Epoch 14/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.1740 - accuracy: 0.6154 - val_loss: 1.4085 - val_accuracy: 0.5714\n",
            "Epoch 15/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.1558 - accuracy: 0.6325 - val_loss: 1.3247 - val_accuracy: 0.7143\n",
            "Epoch 16/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.1371 - accuracy: 0.6154 - val_loss: 1.2615 - val_accuracy: 0.7143\n",
            "Epoch 17/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.9952 - accuracy: 0.6752 - val_loss: 1.2345 - val_accuracy: 0.6429\n",
            "Epoch 18/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.9423 - accuracy: 0.7179 - val_loss: 1.1539 - val_accuracy: 0.7143\n",
            "Epoch 19/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.8582 - accuracy: 0.7179 - val_loss: 1.0650 - val_accuracy: 0.7143\n",
            "Epoch 20/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.7997 - accuracy: 0.7607 - val_loss: 1.0389 - val_accuracy: 0.7857\n",
            "Epoch 21/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7265 - val_loss: 1.0385 - val_accuracy: 0.7857\n",
            "Epoch 22/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.7692 - val_loss: 0.9704 - val_accuracy: 0.7143\n",
            "Epoch 23/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.7863 - val_loss: 0.9864 - val_accuracy: 0.7143\n",
            "Epoch 24/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7607 - val_loss: 1.0439 - val_accuracy: 0.7143\n",
            "Epoch 25/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.7949 - val_loss: 0.9035 - val_accuracy: 0.7143\n",
            "131/131 [==============================] - 0s 882us/step\n",
            "131/131 [==============================] - 0s 845us/step\n",
            "131/131 [==============================] - 0s 840us/step\n",
            "131/131 [==============================] - 0s 867us/step\n",
            "Train on 117 samples, validate on 14 samples\n",
            "Epoch 1/25\n",
            "117/117 [==============================] - 1s 5ms/step - loss: 2.2759 - accuracy: 0.0684 - val_loss: 1.8005 - val_accuracy: 0.7857\n",
            "Epoch 2/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.6343 - accuracy: 0.4957 - val_loss: 1.3060 - val_accuracy: 0.8571\n",
            "Epoch 3/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.0740 - accuracy: 0.5470 - val_loss: 1.1869 - val_accuracy: 0.2857\n",
            "Epoch 4/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.0307 - accuracy: 0.5641 - val_loss: 1.2251 - val_accuracy: 0.4286\n",
            "Epoch 5/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.0268 - accuracy: 0.5470 - val_loss: 1.2431 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.6325 - val_loss: 1.2590 - val_accuracy: 0.2857\n",
            "Epoch 7/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.9949 - accuracy: 0.6496 - val_loss: 1.0473 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.9001 - accuracy: 0.6068 - val_loss: 0.9696 - val_accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.7685 - accuracy: 0.6410 - val_loss: 0.9184 - val_accuracy: 0.5714\n",
            "Epoch 10/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.7009 - val_loss: 0.9034 - val_accuracy: 0.5714\n",
            "Epoch 11/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.7778 - val_loss: 0.8674 - val_accuracy: 0.7143\n",
            "Epoch 12/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.7146 - accuracy: 0.7607 - val_loss: 0.8476 - val_accuracy: 0.6429\n",
            "Epoch 13/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.8205 - val_loss: 0.7738 - val_accuracy: 0.7857\n",
            "Epoch 14/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.9145 - val_loss: 0.7066 - val_accuracy: 0.8571\n",
            "Epoch 15/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.9060 - val_loss: 0.5257 - val_accuracy: 0.9286\n",
            "Epoch 16/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.9402 - val_loss: 0.8061 - val_accuracy: 0.5000\n",
            "Epoch 17/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.9145 - val_loss: 0.5736 - val_accuracy: 0.8571\n",
            "Epoch 18/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.3060 - accuracy: 0.9402 - val_loss: 0.3414 - val_accuracy: 0.9286\n",
            "Epoch 19/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.9402 - val_loss: 0.4071 - val_accuracy: 0.9286\n",
            "Epoch 20/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.9402 - val_loss: 0.4363 - val_accuracy: 0.9286\n",
            "Epoch 21/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9487 - val_loss: 0.2485 - val_accuracy: 0.9286\n",
            "Epoch 22/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9573 - val_loss: 0.2844 - val_accuracy: 0.9286\n",
            "Epoch 23/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9573 - val_loss: 0.4101 - val_accuracy: 0.9286\n",
            "Epoch 24/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9402 - val_loss: 0.2505 - val_accuracy: 0.9286\n",
            "Epoch 25/25\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9658 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
            "131/131 [==============================] - 0s 872us/step\n",
            "131/131 [==============================] - 0s 848us/step\n",
            "131/131 [==============================] - 0s 849us/step\n",
            "131/131 [==============================] - 0s 1ms/step\n",
            "8回目\n",
            "Train on 113 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 2.3171 - accuracy: 0.0708 - val_loss: 2.1479 - val_accuracy: 0.3077\n",
            "Epoch 2/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 2.0688 - accuracy: 0.4336 - val_loss: 1.9332 - val_accuracy: 0.3077\n",
            "Epoch 3/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.7566 - accuracy: 0.4513 - val_loss: 1.6514 - val_accuracy: 0.3077\n",
            "Epoch 4/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.4651 - accuracy: 0.4159 - val_loss: 1.5599 - val_accuracy: 0.3077\n",
            "Epoch 5/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.4337 - accuracy: 0.5044 - val_loss: 1.5462 - val_accuracy: 0.4615\n",
            "Epoch 6/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.4755 - accuracy: 0.4690 - val_loss: 1.4699 - val_accuracy: 0.5385\n",
            "Epoch 7/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.3400 - accuracy: 0.4779 - val_loss: 1.4421 - val_accuracy: 0.5385\n",
            "Epoch 8/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.3468 - accuracy: 0.4071 - val_loss: 1.4577 - val_accuracy: 0.5385\n",
            "Epoch 9/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.3323 - accuracy: 0.3982 - val_loss: 1.4697 - val_accuracy: 0.4615\n",
            "Epoch 10/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.2700 - accuracy: 0.4425 - val_loss: 1.4850 - val_accuracy: 0.5385\n",
            "Epoch 11/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.2008 - accuracy: 0.5133 - val_loss: 1.4995 - val_accuracy: 0.4615\n",
            "Epoch 12/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.2127 - accuracy: 0.6106 - val_loss: 1.5137 - val_accuracy: 0.4615\n",
            "Epoch 13/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1651 - accuracy: 0.5929 - val_loss: 1.5137 - val_accuracy: 0.4615\n",
            "Epoch 14/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1333 - accuracy: 0.6637 - val_loss: 1.4562 - val_accuracy: 0.5385\n",
            "Epoch 15/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0976 - accuracy: 0.6460 - val_loss: 1.3631 - val_accuracy: 0.6923\n",
            "Epoch 16/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0477 - accuracy: 0.7168 - val_loss: 1.3091 - val_accuracy: 0.6154\n",
            "Epoch 17/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.9527 - accuracy: 0.7168 - val_loss: 1.2865 - val_accuracy: 0.6154\n",
            "Epoch 18/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.8784 - accuracy: 0.7434 - val_loss: 1.1920 - val_accuracy: 0.6923\n",
            "Epoch 19/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.8168 - accuracy: 0.7257 - val_loss: 1.1100 - val_accuracy: 0.6923\n",
            "Epoch 20/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.7675 - accuracy: 0.7522 - val_loss: 1.1092 - val_accuracy: 0.6923\n",
            "Epoch 21/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.8053 - val_loss: 1.0500 - val_accuracy: 0.6923\n",
            "Epoch 22/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.7876 - val_loss: 1.0267 - val_accuracy: 0.6923\n",
            "Epoch 23/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7788 - val_loss: 1.1073 - val_accuracy: 0.6923\n",
            "Epoch 24/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.7876 - val_loss: 1.0120 - val_accuracy: 0.6923\n",
            "Epoch 25/25\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.8230 - val_loss: 1.0059 - val_accuracy: 0.6923\n",
            "126/126 [==============================] - 0s 856us/step\n",
            "126/126 [==============================] - 0s 851us/step\n",
            "126/126 [==============================] - 0s 848us/step\n",
            "126/126 [==============================] - 0s 844us/step\n",
            "Train on 113 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 2.2896 - accuracy: 0.0531 - val_loss: 1.7983 - val_accuracy: 0.6154\n",
            "Epoch 2/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.6588 - accuracy: 0.5044 - val_loss: 1.2471 - val_accuracy: 0.3077\n",
            "Epoch 3/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0896 - accuracy: 0.5221 - val_loss: 0.8267 - val_accuracy: 0.3077\n",
            "Epoch 4/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.7565 - accuracy: 0.5752 - val_loss: 0.6389 - val_accuracy: 0.8462\n",
            "Epoch 5/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.7317 - accuracy: 0.6018 - val_loss: 0.8433 - val_accuracy: 0.3077\n",
            "Epoch 6/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.9259 - accuracy: 0.5487 - val_loss: 0.4546 - val_accuracy: 0.8462\n",
            "Epoch 7/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.8700 - accuracy: 0.6283 - val_loss: 0.5756 - val_accuracy: 0.7692\n",
            "Epoch 8/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7522 - val_loss: 0.7726 - val_accuracy: 0.3846\n",
            "Epoch 9/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.7698 - accuracy: 0.7345 - val_loss: 0.4389 - val_accuracy: 0.8462\n",
            "Epoch 10/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.7345 - val_loss: 0.3042 - val_accuracy: 0.9231\n",
            "Epoch 11/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.7611 - val_loss: 0.3654 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8407 - val_loss: 0.4896 - val_accuracy: 0.7692\n",
            "Epoch 13/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.8230 - val_loss: 0.2788 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.9204 - val_loss: 0.1515 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3157 - accuracy: 0.9115 - val_loss: 0.1249 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.9735 - val_loss: 0.1330 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9558 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9469 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9735 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9823 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9735 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9735 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9823 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9912 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9823 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
            "126/126 [==============================] - 0s 821us/step\n",
            "126/126 [==============================] - 0s 880us/step\n",
            "126/126 [==============================] - 0s 833us/step\n",
            "126/126 [==============================] - 0s 844us/step\n",
            "9回目\n",
            "Train on 112 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.3586 - accuracy: 0.0446 - val_loss: 2.2014 - val_accuracy: 0.4615\n",
            "Epoch 2/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 2.1617 - accuracy: 0.5446 - val_loss: 2.0045 - val_accuracy: 0.4615\n",
            "Epoch 3/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.8947 - accuracy: 0.5536 - val_loss: 1.7118 - val_accuracy: 0.5385\n",
            "Epoch 4/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.6109 - accuracy: 0.4286 - val_loss: 1.5491 - val_accuracy: 0.3846\n",
            "Epoch 5/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.4594 - accuracy: 0.5000 - val_loss: 1.6065 - val_accuracy: 0.3077\n",
            "Epoch 6/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.4831 - accuracy: 0.5357 - val_loss: 1.4402 - val_accuracy: 0.4615\n",
            "Epoch 7/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2795 - accuracy: 0.5536 - val_loss: 1.3313 - val_accuracy: 0.7692\n",
            "Epoch 8/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2240 - accuracy: 0.5446 - val_loss: 1.3696 - val_accuracy: 0.6154\n",
            "Epoch 9/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2428 - accuracy: 0.4286 - val_loss: 1.4024 - val_accuracy: 0.6154\n",
            "Epoch 10/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2609 - accuracy: 0.5179 - val_loss: 1.3885 - val_accuracy: 0.6154\n",
            "Epoch 11/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1309 - accuracy: 0.6607 - val_loss: 1.3279 - val_accuracy: 0.6154\n",
            "Epoch 12/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.0538 - accuracy: 0.7054 - val_loss: 1.2143 - val_accuracy: 0.7692\n",
            "Epoch 13/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9665 - accuracy: 0.7054 - val_loss: 1.2048 - val_accuracy: 0.7692\n",
            "Epoch 14/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9194 - accuracy: 0.7321 - val_loss: 1.2568 - val_accuracy: 0.6154\n",
            "Epoch 15/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9069 - accuracy: 0.7143 - val_loss: 1.1179 - val_accuracy: 0.7692\n",
            "Epoch 16/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.8958 - accuracy: 0.7232 - val_loss: 1.0348 - val_accuracy: 0.7692\n",
            "Epoch 17/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.8221 - accuracy: 0.7143 - val_loss: 1.0495 - val_accuracy: 0.7692\n",
            "Epoch 18/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7232 - val_loss: 0.9847 - val_accuracy: 0.7692\n",
            "Epoch 19/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.7589 - val_loss: 0.9226 - val_accuracy: 0.7692\n",
            "Epoch 20/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.7679 - val_loss: 0.9583 - val_accuracy: 0.7692\n",
            "Epoch 21/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.7946 - val_loss: 0.9151 - val_accuracy: 0.7692\n",
            "Epoch 22/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.8304 - val_loss: 0.8636 - val_accuracy: 0.7692\n",
            "Epoch 23/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8125 - val_loss: 0.9428 - val_accuracy: 0.7692\n",
            "Epoch 24/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.8125 - val_loss: 0.8896 - val_accuracy: 0.7692\n",
            "Epoch 25/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7946 - val_loss: 0.8740 - val_accuracy: 0.7692\n",
            "125/125 [==============================] - 0s 856us/step\n",
            "125/125 [==============================] - 0s 835us/step\n",
            "125/125 [==============================] - 0s 824us/step\n",
            "125/125 [==============================] - 0s 816us/step\n",
            "Train on 112 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.2794 - accuracy: 0.1250 - val_loss: 1.8570 - val_accuracy: 0.3077\n",
            "Epoch 2/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.7195 - accuracy: 0.5000 - val_loss: 1.2901 - val_accuracy: 0.6923\n",
            "Epoch 3/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1360 - accuracy: 0.5714 - val_loss: 0.8099 - val_accuracy: 0.7692\n",
            "Epoch 4/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7981 - accuracy: 0.5625 - val_loss: 0.7163 - val_accuracy: 0.4615\n",
            "Epoch 5/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.6518 - val_loss: 0.6853 - val_accuracy: 0.5385\n",
            "Epoch 6/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7089 - accuracy: 0.7143 - val_loss: 0.6214 - val_accuracy: 0.7692\n",
            "Epoch 7/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.8403 - accuracy: 0.6071 - val_loss: 0.5060 - val_accuracy: 0.7692\n",
            "Epoch 8/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.6429 - val_loss: 1.0811 - val_accuracy: 0.3077\n",
            "Epoch 9/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9693 - accuracy: 0.6339 - val_loss: 0.5388 - val_accuracy: 0.7692\n",
            "Epoch 10/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.7679 - val_loss: 0.3575 - val_accuracy: 0.9231\n",
            "Epoch 11/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.7232 - val_loss: 0.4544 - val_accuracy: 0.8462\n",
            "Epoch 12/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7500 - val_loss: 0.6430 - val_accuracy: 0.5385\n",
            "Epoch 13/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7946 - val_loss: 0.5745 - val_accuracy: 0.6154\n",
            "Epoch 14/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8929 - val_loss: 0.3108 - val_accuracy: 0.9231\n",
            "Epoch 15/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.9107 - val_loss: 0.1994 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.9107 - val_loss: 0.1993 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2397 - accuracy: 0.9375 - val_loss: 0.2767 - val_accuracy: 0.9231\n",
            "Epoch 18/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9643 - val_loss: 0.2445 - val_accuracy: 0.9231\n",
            "Epoch 19/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9554 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9732 - val_loss: 0.0957 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9732 - val_loss: 0.0879 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9911 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9643 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9911 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9911 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "125/125 [==============================] - 0s 835us/step\n",
            "125/125 [==============================] - 0s 842us/step\n",
            "125/125 [==============================] - 0s 812us/step\n",
            "125/125 [==============================] - 0s 826us/step\n",
            "10回目\n",
            "Train on 112 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.3286 - accuracy: 0.0446 - val_loss: 2.1502 - val_accuracy: 0.5385\n",
            "Epoch 2/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 2.1092 - accuracy: 0.4554 - val_loss: 1.9244 - val_accuracy: 0.6154\n",
            "Epoch 3/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.8501 - accuracy: 0.3304 - val_loss: 1.6196 - val_accuracy: 0.7692\n",
            "Epoch 4/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.5470 - accuracy: 0.5179 - val_loss: 1.4548 - val_accuracy: 0.6154\n",
            "Epoch 5/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.5230 - accuracy: 0.5000 - val_loss: 1.4571 - val_accuracy: 0.4615\n",
            "Epoch 6/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.4231 - accuracy: 0.5536 - val_loss: 1.3980 - val_accuracy: 0.4615\n",
            "Epoch 7/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.3533 - accuracy: 0.5268 - val_loss: 1.3239 - val_accuracy: 0.6923\n",
            "Epoch 8/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2453 - accuracy: 0.6161 - val_loss: 1.3128 - val_accuracy: 0.7692\n",
            "Epoch 9/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.2403 - accuracy: 0.5000 - val_loss: 1.3084 - val_accuracy: 0.8462\n",
            "Epoch 10/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1576 - accuracy: 0.6161 - val_loss: 1.3062 - val_accuracy: 0.6923\n",
            "Epoch 11/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.1018 - accuracy: 0.6429 - val_loss: 1.2307 - val_accuracy: 0.6923\n",
            "Epoch 12/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9606 - accuracy: 0.6875 - val_loss: 1.0758 - val_accuracy: 0.7692\n",
            "Epoch 13/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.8675 - accuracy: 0.7500 - val_loss: 1.0189 - val_accuracy: 0.7692\n",
            "Epoch 14/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.8762 - accuracy: 0.7589 - val_loss: 1.0571 - val_accuracy: 0.7692\n",
            "Epoch 15/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7979 - accuracy: 0.7500 - val_loss: 1.0559 - val_accuracy: 0.7692\n",
            "Epoch 16/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7313 - accuracy: 0.7500 - val_loss: 0.9419 - val_accuracy: 0.7692\n",
            "Epoch 17/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.7768 - val_loss: 0.9159 - val_accuracy: 0.7692\n",
            "Epoch 18/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.7500 - val_loss: 0.9715 - val_accuracy: 0.7692\n",
            "Epoch 19/25\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.8214 - val_loss: 1.0451 - val_accuracy: 0.8462\n",
            "Epoch 20/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.8125 - val_loss: 0.9580 - val_accuracy: 0.8462\n",
            "Epoch 21/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7411 - val_loss: 0.8996 - val_accuracy: 0.8462\n",
            "Epoch 22/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.7500 - val_loss: 0.9176 - val_accuracy: 0.8462\n",
            "Epoch 23/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7857 - val_loss: 1.0034 - val_accuracy: 0.8462\n",
            "Epoch 24/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.7768 - val_loss: 0.8829 - val_accuracy: 0.7692\n",
            "Epoch 25/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.8482 - val_loss: 0.8303 - val_accuracy: 0.7692\n",
            "125/125 [==============================] - 0s 825us/step\n",
            "125/125 [==============================] - 0s 848us/step\n",
            "125/125 [==============================] - 0s 819us/step\n",
            "125/125 [==============================] - 0s 817us/step\n",
            "Train on 112 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.3723 - accuracy: 0.0268 - val_loss: 2.0811 - val_accuracy: 0.3846\n",
            "Epoch 2/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.9298 - accuracy: 0.4911 - val_loss: 1.5880 - val_accuracy: 0.3077\n",
            "Epoch 3/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 1.3751 - accuracy: 0.5714 - val_loss: 0.9541 - val_accuracy: 0.3846\n",
            "Epoch 4/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9060 - accuracy: 0.5179 - val_loss: 0.6442 - val_accuracy: 0.8462\n",
            "Epoch 5/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.6607 - val_loss: 0.6169 - val_accuracy: 0.6154\n",
            "Epoch 6/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.8424 - accuracy: 0.6071 - val_loss: 0.5081 - val_accuracy: 0.8462\n",
            "Epoch 7/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.9693 - accuracy: 0.5714 - val_loss: 0.6360 - val_accuracy: 0.5385\n",
            "Epoch 8/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.6696 - val_loss: 0.4558 - val_accuracy: 0.8462\n",
            "Epoch 9/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.8374 - accuracy: 0.6696 - val_loss: 0.3618 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.7169 - accuracy: 0.7321 - val_loss: 0.6402 - val_accuracy: 0.5385\n",
            "Epoch 11/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7768 - val_loss: 0.3845 - val_accuracy: 0.8462\n",
            "Epoch 12/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7679 - val_loss: 0.2624 - val_accuracy: 0.9231\n",
            "Epoch 13/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8214 - val_loss: 0.3269 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8750 - val_loss: 0.3495 - val_accuracy: 0.9231\n",
            "Epoch 15/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8750 - val_loss: 0.2203 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.9375 - val_loss: 0.1962 - val_accuracy: 0.9231\n",
            "Epoch 17/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.9018 - val_loss: 0.2304 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2263 - accuracy: 0.9286 - val_loss: 0.2987 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.9375 - val_loss: 0.1519 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9554 - val_loss: 0.1508 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.9196 - val_loss: 0.1268 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9732 - val_loss: 0.2283 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9286 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9554 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9821 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
            "125/125 [==============================] - 0s 886us/step\n",
            "125/125 [==============================] - 0s 844us/step\n",
            "125/125 [==============================] - 0s 895us/step\n",
            "125/125 [==============================] - 0s 836us/step\n",
            "11回目\n",
            "Train on 109 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.2643 - accuracy: 0.1927 - val_loss: 1.9766 - val_accuracy: 0.4615\n",
            "Epoch 2/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.8537 - accuracy: 0.4220 - val_loss: 1.5939 - val_accuracy: 0.6923\n",
            "Epoch 3/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.4478 - accuracy: 0.4954 - val_loss: 1.4732 - val_accuracy: 0.5385\n",
            "Epoch 4/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.5003 - accuracy: 0.4954 - val_loss: 1.3761 - val_accuracy: 0.6923\n",
            "Epoch 5/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.3850 - accuracy: 0.5688 - val_loss: 1.3883 - val_accuracy: 0.4615\n",
            "Epoch 6/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2228 - accuracy: 0.6055 - val_loss: 1.3904 - val_accuracy: 0.6154\n",
            "Epoch 7/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2269 - accuracy: 0.5872 - val_loss: 1.3481 - val_accuracy: 0.6923\n",
            "Epoch 8/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.1480 - accuracy: 0.6055 - val_loss: 1.3055 - val_accuracy: 0.6923\n",
            "Epoch 9/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.1127 - accuracy: 0.6422 - val_loss: 1.3080 - val_accuracy: 0.6923\n",
            "Epoch 10/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.0042 - accuracy: 0.7615 - val_loss: 1.2558 - val_accuracy: 0.6923\n",
            "Epoch 11/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.9450 - accuracy: 0.7431 - val_loss: 1.1362 - val_accuracy: 0.7692\n",
            "Epoch 12/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.9495 - accuracy: 0.7615 - val_loss: 1.2086 - val_accuracy: 0.6923\n",
            "Epoch 13/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.7523 - val_loss: 1.0503 - val_accuracy: 0.7692\n",
            "Epoch 14/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.8234 - accuracy: 0.7615 - val_loss: 0.9640 - val_accuracy: 0.7692\n",
            "Epoch 15/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7990 - accuracy: 0.7798 - val_loss: 0.9810 - val_accuracy: 0.7692\n",
            "Epoch 16/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.7431 - val_loss: 0.9083 - val_accuracy: 0.7692\n",
            "Epoch 17/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.8073 - val_loss: 0.8496 - val_accuracy: 0.7692\n",
            "Epoch 18/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.7706 - val_loss: 0.8853 - val_accuracy: 0.8462\n",
            "Epoch 19/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.8073 - val_loss: 0.7885 - val_accuracy: 0.8462\n",
            "Epoch 20/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.8349 - val_loss: 0.7609 - val_accuracy: 0.7692\n",
            "Epoch 21/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.8349 - val_loss: 0.7962 - val_accuracy: 0.8462\n",
            "Epoch 22/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.8257 - val_loss: 0.7715 - val_accuracy: 0.7692\n",
            "Epoch 23/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.8349 - val_loss: 0.7874 - val_accuracy: 0.7692\n",
            "Epoch 24/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.8257 - val_loss: 0.7620 - val_accuracy: 0.7692\n",
            "Epoch 25/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8716 - val_loss: 0.7493 - val_accuracy: 0.7692\n",
            "122/122 [==============================] - 0s 834us/step\n",
            "122/122 [==============================] - 0s 889us/step\n",
            "122/122 [==============================] - 0s 847us/step\n",
            "122/122 [==============================] - 0s 826us/step\n",
            "Train on 109 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.3393 - accuracy: 0.0000e+00 - val_loss: 2.1017 - val_accuracy: 0.7692\n",
            "Epoch 2/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.0282 - accuracy: 0.5688 - val_loss: 1.7465 - val_accuracy: 0.5385\n",
            "Epoch 3/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.5938 - accuracy: 0.6239 - val_loss: 1.2146 - val_accuracy: 0.3077\n",
            "Epoch 4/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.0377 - accuracy: 0.5963 - val_loss: 0.8009 - val_accuracy: 0.3846\n",
            "Epoch 5/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.6147 - val_loss: 0.6285 - val_accuracy: 0.8462\n",
            "Epoch 6/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.6147 - val_loss: 0.6643 - val_accuracy: 0.5385\n",
            "Epoch 7/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7149 - accuracy: 0.6606 - val_loss: 0.4827 - val_accuracy: 0.9231\n",
            "Epoch 8/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.6422 - val_loss: 0.4637 - val_accuracy: 0.9231\n",
            "Epoch 9/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7493 - accuracy: 0.5963 - val_loss: 0.4163 - val_accuracy: 0.9231\n",
            "Epoch 10/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7248 - val_loss: 0.2172 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7431 - val_loss: 0.6746 - val_accuracy: 0.3846\n",
            "Epoch 12/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7706 - val_loss: 0.3280 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9174 - val_loss: 0.1081 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8716 - val_loss: 0.1463 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9817 - val_loss: 0.4432 - val_accuracy: 0.8462\n",
            "Epoch 16/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.8991 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9908 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9725 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9908 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9908 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9817 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "122/122 [==============================] - 0s 844us/step\n",
            "122/122 [==============================] - 0s 849us/step\n",
            "122/122 [==============================] - 0s 829us/step\n",
            "122/122 [==============================] - 0s 903us/step\n",
            "12回目\n",
            "Train on 109 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.2798 - accuracy: 0.1284 - val_loss: 1.9920 - val_accuracy: 0.3077\n",
            "Epoch 2/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.8891 - accuracy: 0.4587 - val_loss: 1.6739 - val_accuracy: 0.3077\n",
            "Epoch 3/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.5082 - accuracy: 0.4771 - val_loss: 1.5811 - val_accuracy: 0.3077\n",
            "Epoch 4/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.4405 - accuracy: 0.4495 - val_loss: 1.5282 - val_accuracy: 0.4615\n",
            "Epoch 5/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.4051 - accuracy: 0.4862 - val_loss: 1.4416 - val_accuracy: 0.6154\n",
            "Epoch 6/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.3762 - accuracy: 0.5138 - val_loss: 1.4191 - val_accuracy: 0.6154\n",
            "Epoch 7/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.3170 - accuracy: 0.5413 - val_loss: 1.4707 - val_accuracy: 0.4615\n",
            "Epoch 8/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2775 - accuracy: 0.5229 - val_loss: 1.5121 - val_accuracy: 0.3077\n",
            "Epoch 9/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2729 - accuracy: 0.5413 - val_loss: 1.5161 - val_accuracy: 0.3077\n",
            "Epoch 10/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2260 - accuracy: 0.5046 - val_loss: 1.4991 - val_accuracy: 0.3077\n",
            "Epoch 11/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.1517 - accuracy: 0.5963 - val_loss: 1.4624 - val_accuracy: 0.3846\n",
            "Epoch 12/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.1220 - accuracy: 0.5872 - val_loss: 1.3875 - val_accuracy: 0.6154\n",
            "Epoch 13/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.0265 - accuracy: 0.6881 - val_loss: 1.3047 - val_accuracy: 0.7692\n",
            "Epoch 14/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.0173 - accuracy: 0.6789 - val_loss: 1.2689 - val_accuracy: 0.7692\n",
            "Epoch 15/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.9886 - accuracy: 0.7156 - val_loss: 1.2879 - val_accuracy: 0.6154\n",
            "Epoch 16/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.9203 - accuracy: 0.7248 - val_loss: 1.1585 - val_accuracy: 0.7692\n",
            "Epoch 17/25\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8212 - accuracy: 0.7431 - val_loss: 1.0723 - val_accuracy: 0.7692\n",
            "Epoch 18/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.7890 - val_loss: 1.0746 - val_accuracy: 0.7692\n",
            "Epoch 19/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.7523 - val_loss: 1.0906 - val_accuracy: 0.7692\n",
            "Epoch 20/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.7615 - val_loss: 1.0790 - val_accuracy: 0.7692\n",
            "Epoch 21/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.8073 - val_loss: 1.0434 - val_accuracy: 0.7692\n",
            "Epoch 22/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.7890 - val_loss: 1.0824 - val_accuracy: 0.7692\n",
            "Epoch 23/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.7982 - val_loss: 0.9534 - val_accuracy: 0.7692\n",
            "Epoch 24/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.8165 - val_loss: 0.9923 - val_accuracy: 0.7692\n",
            "Epoch 25/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.8440 - val_loss: 1.0239 - val_accuracy: 0.8462\n",
            "122/122 [==============================] - 0s 890us/step\n",
            "122/122 [==============================] - 0s 865us/step\n",
            "122/122 [==============================] - 0s 845us/step\n",
            "122/122 [==============================] - 0s 827us/step\n",
            "Train on 109 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.3831 - accuracy: 0.0092 - val_loss: 2.0623 - val_accuracy: 0.3077\n",
            "Epoch 2/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.9320 - accuracy: 0.6147 - val_loss: 1.6956 - val_accuracy: 0.3077\n",
            "Epoch 3/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.4787 - accuracy: 0.5688 - val_loss: 1.1946 - val_accuracy: 0.3077\n",
            "Epoch 4/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.9590 - accuracy: 0.6239 - val_loss: 0.8251 - val_accuracy: 0.3077\n",
            "Epoch 5/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.6789 - val_loss: 0.6630 - val_accuracy: 0.5385\n",
            "Epoch 6/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6147 - val_loss: 0.6331 - val_accuracy: 0.6154\n",
            "Epoch 7/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.6789 - val_loss: 1.3022 - val_accuracy: 0.3077\n",
            "Epoch 8/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.9132 - accuracy: 0.6239 - val_loss: 0.3734 - val_accuracy: 0.9231\n",
            "Epoch 9/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.7327 - accuracy: 0.6239 - val_loss: 0.5296 - val_accuracy: 0.8462\n",
            "Epoch 10/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7156 - val_loss: 1.2652 - val_accuracy: 0.3077\n",
            "Epoch 11/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.7064 - val_loss: 0.9018 - val_accuracy: 0.3077\n",
            "Epoch 12/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7706 - val_loss: 0.2618 - val_accuracy: 0.9231\n",
            "Epoch 13/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7156 - val_loss: 0.2301 - val_accuracy: 0.9231\n",
            "Epoch 14/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7982 - val_loss: 0.5577 - val_accuracy: 0.6154\n",
            "Epoch 15/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.9083 - val_loss: 0.8521 - val_accuracy: 0.3846\n",
            "Epoch 16/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8349 - val_loss: 0.3993 - val_accuracy: 0.9231\n",
            "Epoch 17/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.2427 - accuracy: 0.8991 - val_loss: 0.1168 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.8991 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.8899 - val_loss: 0.1358 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9725 - val_loss: 0.3424 - val_accuracy: 0.9231\n",
            "Epoch 21/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9266 - val_loss: 0.2502 - val_accuracy: 0.9231\n",
            "Epoch 22/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9633 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9725 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9541 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
            "122/122 [==============================] - 0s 827us/step\n",
            "122/122 [==============================] - 0s 830us/step\n",
            "122/122 [==============================] - 0s 833us/step\n",
            "122/122 [==============================] - 0s 867us/step\n",
            "13回目\n",
            "Train on 108 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 2.2640 - accuracy: 0.1111 - val_loss: 2.0285 - val_accuracy: 0.3077\n",
            "Epoch 2/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.9282 - accuracy: 0.3981 - val_loss: 1.6759 - val_accuracy: 0.3077\n",
            "Epoch 3/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.5502 - accuracy: 0.5093 - val_loss: 1.4728 - val_accuracy: 0.3077\n",
            "Epoch 4/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.3186 - accuracy: 0.5278 - val_loss: 1.4854 - val_accuracy: 0.6154\n",
            "Epoch 5/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.3852 - accuracy: 0.5000 - val_loss: 1.4690 - val_accuracy: 0.6154\n",
            "Epoch 6/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.3550 - accuracy: 0.5000 - val_loss: 1.4533 - val_accuracy: 0.6154\n",
            "Epoch 7/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.2786 - accuracy: 0.5278 - val_loss: 1.4446 - val_accuracy: 0.6154\n",
            "Epoch 8/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.2545 - accuracy: 0.5093 - val_loss: 1.3856 - val_accuracy: 0.6154\n",
            "Epoch 9/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.1821 - accuracy: 0.4907 - val_loss: 1.3421 - val_accuracy: 0.6154\n",
            "Epoch 10/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.0594 - accuracy: 0.6574 - val_loss: 1.3034 - val_accuracy: 0.6923\n",
            "Epoch 11/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.0488 - accuracy: 0.6759 - val_loss: 1.2755 - val_accuracy: 0.6923\n",
            "Epoch 12/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.9945 - accuracy: 0.7315 - val_loss: 1.2368 - val_accuracy: 0.6923\n",
            "Epoch 13/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.9184 - accuracy: 0.7593 - val_loss: 1.1213 - val_accuracy: 0.7692\n",
            "Epoch 14/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.8999 - accuracy: 0.7593 - val_loss: 1.0668 - val_accuracy: 0.7692\n",
            "Epoch 15/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.8084 - accuracy: 0.7870 - val_loss: 1.0010 - val_accuracy: 0.7692\n",
            "Epoch 16/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7788 - accuracy: 0.7778 - val_loss: 0.8981 - val_accuracy: 0.7692\n",
            "Epoch 17/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7238 - accuracy: 0.7685 - val_loss: 0.9546 - val_accuracy: 0.7692\n",
            "Epoch 18/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.7870 - val_loss: 0.9184 - val_accuracy: 0.8462\n",
            "Epoch 19/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.8148 - val_loss: 0.8070 - val_accuracy: 0.7692\n",
            "Epoch 20/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.8148 - val_loss: 0.7972 - val_accuracy: 0.8462\n",
            "Epoch 21/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.8426 - val_loss: 0.8594 - val_accuracy: 0.9231\n",
            "Epoch 22/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.8519 - val_loss: 0.8237 - val_accuracy: 0.9231\n",
            "Epoch 23/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.8519 - val_loss: 0.7464 - val_accuracy: 0.7692\n",
            "Epoch 24/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8426 - val_loss: 0.7501 - val_accuracy: 0.7692\n",
            "Epoch 25/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.8241 - val_loss: 0.7706 - val_accuracy: 0.7692\n",
            "121/121 [==============================] - 0s 837us/step\n",
            "121/121 [==============================] - 0s 833us/step\n",
            "121/121 [==============================] - 0s 862us/step\n",
            "121/121 [==============================] - 0s 888us/step\n",
            "Train on 108 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 2.2629 - accuracy: 0.2315 - val_loss: 1.9096 - val_accuracy: 0.2308\n",
            "Epoch 2/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.7377 - accuracy: 0.5556 - val_loss: 1.3564 - val_accuracy: 0.3077\n",
            "Epoch 3/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.1197 - accuracy: 0.5556 - val_loss: 0.8868 - val_accuracy: 0.3846\n",
            "Epoch 4/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7906 - accuracy: 0.5463 - val_loss: 0.6124 - val_accuracy: 0.7692\n",
            "Epoch 5/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.6111 - val_loss: 0.6733 - val_accuracy: 0.6923\n",
            "Epoch 6/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.5741 - val_loss: 0.7679 - val_accuracy: 0.4615\n",
            "Epoch 7/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.8368 - accuracy: 0.5648 - val_loss: 0.4312 - val_accuracy: 0.7692\n",
            "Epoch 8/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5833 - val_loss: 0.4480 - val_accuracy: 0.8462\n",
            "Epoch 9/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6667 - val_loss: 0.7398 - val_accuracy: 0.5385\n",
            "Epoch 10/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6944 - val_loss: 0.6104 - val_accuracy: 0.6923\n",
            "Epoch 11/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6759 - val_loss: 0.3804 - val_accuracy: 0.8462\n",
            "Epoch 12/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7222 - val_loss: 0.3424 - val_accuracy: 0.8462\n",
            "Epoch 13/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.6852 - val_loss: 0.3484 - val_accuracy: 0.8462\n",
            "Epoch 14/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7870 - val_loss: 0.4330 - val_accuracy: 0.8462\n",
            "Epoch 15/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8333 - val_loss: 0.3741 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8704 - val_loss: 0.2742 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.2938 - accuracy: 0.9074 - val_loss: 0.2033 - val_accuracy: 0.8462\n",
            "Epoch 18/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.2403 - accuracy: 0.9074 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9722 - val_loss: 0.1665 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1858 - accuracy: 0.9630 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9722 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9815 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9907 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9907 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "121/121 [==============================] - 0s 895us/step\n",
            "121/121 [==============================] - 0s 833us/step\n",
            "121/121 [==============================] - 0s 839us/step\n",
            "121/121 [==============================] - 0s 825us/step\n",
            "14回目\n",
            "Train on 108 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 2.3044 - accuracy: 0.1111 - val_loss: 2.0426 - val_accuracy: 0.3077\n",
            "Epoch 2/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.9676 - accuracy: 0.4630 - val_loss: 1.7148 - val_accuracy: 0.3077\n",
            "Epoch 3/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.5540 - accuracy: 0.5370 - val_loss: 1.5429 - val_accuracy: 0.3077\n",
            "Epoch 4/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.4261 - accuracy: 0.4630 - val_loss: 1.5199 - val_accuracy: 0.6154\n",
            "Epoch 5/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.4334 - accuracy: 0.4537 - val_loss: 1.4494 - val_accuracy: 0.6154\n",
            "Epoch 6/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.4337 - accuracy: 0.4815 - val_loss: 1.4251 - val_accuracy: 0.4615\n",
            "Epoch 7/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.2776 - accuracy: 0.4907 - val_loss: 1.4562 - val_accuracy: 0.3846\n",
            "Epoch 8/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.2907 - accuracy: 0.4907 - val_loss: 1.4461 - val_accuracy: 0.3846\n",
            "Epoch 9/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.2816 - accuracy: 0.4907 - val_loss: 1.4311 - val_accuracy: 0.4615\n",
            "Epoch 10/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.1689 - accuracy: 0.5926 - val_loss: 1.4212 - val_accuracy: 0.4615\n",
            "Epoch 11/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.1029 - accuracy: 0.6481 - val_loss: 1.4087 - val_accuracy: 0.4615\n",
            "Epoch 12/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.0540 - accuracy: 0.6574 - val_loss: 1.3686 - val_accuracy: 0.6923\n",
            "Epoch 13/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.0431 - accuracy: 0.6667 - val_loss: 1.3141 - val_accuracy: 0.6923\n",
            "Epoch 14/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.0289 - accuracy: 0.7315 - val_loss: 1.2555 - val_accuracy: 0.6923\n",
            "Epoch 15/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.9360 - accuracy: 0.7593 - val_loss: 1.1493 - val_accuracy: 0.7692\n",
            "Epoch 16/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.8713 - accuracy: 0.7685 - val_loss: 1.0412 - val_accuracy: 0.7692\n",
            "Epoch 17/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7738 - accuracy: 0.7593 - val_loss: 1.0541 - val_accuracy: 0.7692\n",
            "Epoch 18/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.7870 - val_loss: 0.9441 - val_accuracy: 0.7692\n",
            "Epoch 19/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.8056 - val_loss: 0.9051 - val_accuracy: 0.7692\n",
            "Epoch 20/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.8241 - val_loss: 0.8441 - val_accuracy: 0.7692\n",
            "Epoch 21/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.8426 - val_loss: 1.0322 - val_accuracy: 0.8462\n",
            "Epoch 22/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.8704 - val_loss: 0.8149 - val_accuracy: 0.7692\n",
            "Epoch 23/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8611 - val_loss: 0.7740 - val_accuracy: 0.7692\n",
            "Epoch 24/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8611 - val_loss: 0.8483 - val_accuracy: 0.8462\n",
            "Epoch 25/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8981 - val_loss: 0.9659 - val_accuracy: 0.8462\n",
            "121/121 [==============================] - 0s 905us/step\n",
            "121/121 [==============================] - 0s 841us/step\n",
            "121/121 [==============================] - 0s 828us/step\n",
            "121/121 [==============================] - 0s 877us/step\n",
            "Train on 108 samples, validate on 13 samples\n",
            "Epoch 1/25\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 2.2528 - accuracy: 0.1296 - val_loss: 1.4229 - val_accuracy: 0.7692\n",
            "Epoch 2/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 1.3303 - accuracy: 0.4537 - val_loss: 0.8372 - val_accuracy: 0.8462\n",
            "Epoch 3/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7721 - accuracy: 0.6111 - val_loss: 0.8011 - val_accuracy: 0.3077\n",
            "Epoch 4/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.5370 - val_loss: 0.5237 - val_accuracy: 0.8462\n",
            "Epoch 5/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7495 - accuracy: 0.6296 - val_loss: 0.6257 - val_accuracy: 0.7692\n",
            "Epoch 6/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.7160 - accuracy: 0.6296 - val_loss: 0.6249 - val_accuracy: 0.7692\n",
            "Epoch 7/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6667 - val_loss: 0.4717 - val_accuracy: 0.6923\n",
            "Epoch 8/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.6667 - val_loss: 0.7597 - val_accuracy: 0.5385\n",
            "Epoch 9/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6759 - val_loss: 0.6643 - val_accuracy: 0.6923\n",
            "Epoch 10/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7407 - val_loss: 0.4352 - val_accuracy: 0.7692\n",
            "Epoch 11/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6389 - val_loss: 0.4068 - val_accuracy: 0.7692\n",
            "Epoch 12/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7778 - val_loss: 0.5873 - val_accuracy: 0.6923\n",
            "Epoch 13/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7963 - val_loss: 0.5813 - val_accuracy: 0.6923\n",
            "Epoch 14/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8148 - val_loss: 0.3822 - val_accuracy: 0.7692\n",
            "Epoch 15/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8426 - val_loss: 0.3390 - val_accuracy: 0.9231\n",
            "Epoch 16/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.9167 - val_loss: 0.3852 - val_accuracy: 0.7692\n",
            "Epoch 17/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.9259 - val_loss: 0.3085 - val_accuracy: 0.9231\n",
            "Epoch 18/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9630 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9630 - val_loss: 0.1548 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9630 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9815 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9815 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9815 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9907 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "121/121 [==============================] - 0s 849us/step\n",
            "121/121 [==============================] - 0s 912us/step\n",
            "121/121 [==============================] - 0s 840us/step\n",
            "121/121 [==============================] - 0s 837us/step\n",
            "15回目\n",
            "Train on 107 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 2.2781 - accuracy: 0.1215 - val_loss: 2.0837 - val_accuracy: 0.6667\n",
            "Epoch 2/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 2.0156 - accuracy: 0.5234 - val_loss: 1.7668 - val_accuracy: 0.6667\n",
            "Epoch 3/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.5938 - accuracy: 0.5047 - val_loss: 1.6167 - val_accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.4579 - val_loss: 1.7449 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4506 - accuracy: 0.4860 - val_loss: 1.5899 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.2984 - accuracy: 0.5047 - val_loss: 1.4433 - val_accuracy: 0.5833\n",
            "Epoch 7/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1582 - accuracy: 0.5701 - val_loss: 1.4087 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1395 - accuracy: 0.5981 - val_loss: 1.4044 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.0770 - accuracy: 0.5794 - val_loss: 1.3646 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.0571 - accuracy: 0.6168 - val_loss: 1.2694 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8854 - accuracy: 0.7290 - val_loss: 1.1768 - val_accuracy: 0.7500\n",
            "Epoch 12/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8478 - accuracy: 0.7664 - val_loss: 1.1968 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7319 - accuracy: 0.8037 - val_loss: 1.2353 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.7850 - val_loss: 1.2253 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.7944 - val_loss: 1.1862 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.8037 - val_loss: 1.1870 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.8131 - val_loss: 1.0704 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.8131 - val_loss: 1.2718 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.8131 - val_loss: 1.0373 - val_accuracy: 0.7500\n",
            "Epoch 20/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.8131 - val_loss: 0.9943 - val_accuracy: 0.7500\n",
            "Epoch 21/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7664 - val_loss: 1.1534 - val_accuracy: 0.7500\n",
            "Epoch 22/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.8037 - val_loss: 1.3202 - val_accuracy: 0.7500\n",
            "Epoch 23/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8318 - val_loss: 1.0581 - val_accuracy: 0.7500\n",
            "Epoch 24/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8224 - val_loss: 1.0107 - val_accuracy: 0.7500\n",
            "Epoch 25/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.8131 - val_loss: 1.1871 - val_accuracy: 0.7500\n",
            "119/119 [==============================] - 0s 902us/step\n",
            "119/119 [==============================] - 0s 877us/step\n",
            "119/119 [==============================] - 0s 832us/step\n",
            "119/119 [==============================] - 0s 836us/step\n",
            "Train on 107 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 2.2952 - accuracy: 0.0748 - val_loss: 1.7061 - val_accuracy: 0.6667\n",
            "Epoch 2/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4949 - accuracy: 0.6449 - val_loss: 1.0405 - val_accuracy: 0.5000\n",
            "Epoch 3/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8333 - accuracy: 0.6449 - val_loss: 0.7815 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.5327 - val_loss: 0.6077 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.6075 - val_loss: 0.6653 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6636 - val_loss: 0.5561 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.5981 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
            "Epoch 8/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.7009 - val_loss: 0.5818 - val_accuracy: 0.7500\n",
            "Epoch 9/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7196 - val_loss: 0.3875 - val_accuracy: 0.8333\n",
            "Epoch 10/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7944 - val_loss: 0.3233 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7196 - val_loss: 0.8047 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7757 - val_loss: 0.5684 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8131 - val_loss: 0.2353 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8411 - val_loss: 0.2065 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.7944 - val_loss: 0.2615 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9346 - val_loss: 0.4087 - val_accuracy: 0.6667\n",
            "Epoch 17/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8972 - val_loss: 0.2602 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9159 - val_loss: 0.0971 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9533 - val_loss: 0.0873 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9626 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9907 - val_loss: 0.0857 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9626 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9720 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
            "119/119 [==============================] - 0s 898us/step\n",
            "119/119 [==============================] - 0s 841us/step\n",
            "119/119 [==============================] - 0s 890us/step\n",
            "119/119 [==============================] - 0s 853us/step\n",
            "16回目\n",
            "Train on 107 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 2.3302 - accuracy: 0.0654 - val_loss: 2.1655 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 2.0602 - accuracy: 0.4486 - val_loss: 1.9735 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.7515 - accuracy: 0.5234 - val_loss: 1.6906 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4163 - accuracy: 0.4860 - val_loss: 1.5847 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.3882 - accuracy: 0.4579 - val_loss: 1.6318 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4425 - accuracy: 0.4019 - val_loss: 1.5838 - val_accuracy: 0.5833\n",
            "Epoch 7/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.3391 - accuracy: 0.5140 - val_loss: 1.4816 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.2699 - accuracy: 0.4766 - val_loss: 1.4437 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1742 - accuracy: 0.5888 - val_loss: 1.4447 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1540 - accuracy: 0.5234 - val_loss: 1.4283 - val_accuracy: 0.5833\n",
            "Epoch 11/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1526 - accuracy: 0.5701 - val_loss: 1.3972 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.0494 - accuracy: 0.7196 - val_loss: 1.3625 - val_accuracy: 0.6667\n",
            "Epoch 13/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.7103 - val_loss: 1.3152 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.9699 - accuracy: 0.7103 - val_loss: 1.2809 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.9373 - accuracy: 0.7290 - val_loss: 1.3456 - val_accuracy: 0.5833\n",
            "Epoch 16/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.9570 - accuracy: 0.7383 - val_loss: 1.1642 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8658 - accuracy: 0.7570 - val_loss: 1.0432 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.8037 - val_loss: 1.1221 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.7570 - val_loss: 0.9472 - val_accuracy: 0.7500\n",
            "Epoch 20/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.8037 - val_loss: 0.8580 - val_accuracy: 0.7500\n",
            "Epoch 21/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.8037 - val_loss: 0.8612 - val_accuracy: 0.7500\n",
            "Epoch 22/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.8505 - val_loss: 0.8490 - val_accuracy: 0.7500\n",
            "Epoch 23/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.8224 - val_loss: 0.7839 - val_accuracy: 0.7500\n",
            "Epoch 24/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8505 - val_loss: 0.8046 - val_accuracy: 0.7500\n",
            "Epoch 25/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.8505 - val_loss: 0.8452 - val_accuracy: 0.7500\n",
            "119/119 [==============================] - 0s 830us/step\n",
            "119/119 [==============================] - 0s 838us/step\n",
            "119/119 [==============================] - 0s 847us/step\n",
            "119/119 [==============================] - 0s 832us/step\n",
            "Train on 107 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 2.2262 - accuracy: 0.1776 - val_loss: 1.7031 - val_accuracy: 0.4167\n",
            "Epoch 2/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.5826 - accuracy: 0.5140 - val_loss: 1.0196 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8596 - accuracy: 0.5888 - val_loss: 0.8028 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5981 - val_loss: 0.5448 - val_accuracy: 0.8333\n",
            "Epoch 5/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7069 - accuracy: 0.5327 - val_loss: 0.6028 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.6168 - val_loss: 1.3761 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8874 - accuracy: 0.6355 - val_loss: 0.4189 - val_accuracy: 0.9167\n",
            "Epoch 8/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6916 - val_loss: 0.3041 - val_accuracy: 0.8333\n",
            "Epoch 9/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7196 - val_loss: 0.4976 - val_accuracy: 0.6667\n",
            "Epoch 10/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8411 - val_loss: 0.8041 - val_accuracy: 0.3333\n",
            "Epoch 11/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7757 - val_loss: 0.3669 - val_accuracy: 0.9167\n",
            "Epoch 12/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8879 - val_loss: 0.1640 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8505 - val_loss: 0.1993 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9813 - val_loss: 0.2898 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9626 - val_loss: 0.1731 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9907 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9813 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9907 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9907 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "119/119 [==============================] - 0s 839us/step\n",
            "119/119 [==============================] - 0s 833us/step\n",
            "119/119 [==============================] - 0s 854us/step\n",
            "119/119 [==============================] - 0s 858us/step\n",
            "17回目\n",
            "Train on 107 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 2.3673 - accuracy: 0.0280 - val_loss: 2.1777 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 2.0728 - accuracy: 0.4860 - val_loss: 1.9380 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.7141 - accuracy: 0.4953 - val_loss: 1.6566 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4473 - accuracy: 0.4486 - val_loss: 1.6492 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4610 - accuracy: 0.4953 - val_loss: 1.6213 - val_accuracy: 0.6667\n",
            "Epoch 6/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4395 - accuracy: 0.5234 - val_loss: 1.4997 - val_accuracy: 0.6667\n",
            "Epoch 7/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.2873 - accuracy: 0.6355 - val_loss: 1.4112 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.2276 - accuracy: 0.5234 - val_loss: 1.4029 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1685 - accuracy: 0.5701 - val_loss: 1.4188 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1566 - accuracy: 0.5421 - val_loss: 1.4086 - val_accuracy: 0.5833\n",
            "Epoch 11/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.0904 - accuracy: 0.6075 - val_loss: 1.3666 - val_accuracy: 0.5833\n",
            "Epoch 12/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.0284 - accuracy: 0.6729 - val_loss: 1.2887 - val_accuracy: 0.6667\n",
            "Epoch 13/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.9236 - accuracy: 0.7103 - val_loss: 1.1923 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8531 - accuracy: 0.7570 - val_loss: 1.1473 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7749 - accuracy: 0.7757 - val_loss: 1.1351 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7850 - val_loss: 1.2092 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.7664 - val_loss: 1.2373 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.7850 - val_loss: 1.1741 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.7850 - val_loss: 1.2520 - val_accuracy: 0.7500\n",
            "Epoch 20/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7757 - val_loss: 1.2304 - val_accuracy: 0.7500\n",
            "Epoch 21/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.8224 - val_loss: 1.1695 - val_accuracy: 0.7500\n",
            "Epoch 22/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.8037 - val_loss: 1.2953 - val_accuracy: 0.7500\n",
            "Epoch 23/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7944 - val_loss: 1.4274 - val_accuracy: 0.7500\n",
            "Epoch 24/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8037 - val_loss: 1.2006 - val_accuracy: 0.7500\n",
            "Epoch 25/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.8318 - val_loss: 1.1466 - val_accuracy: 0.7500\n",
            "119/119 [==============================] - 0s 845us/step\n",
            "119/119 [==============================] - 0s 835us/step\n",
            "119/119 [==============================] - 0s 857us/step\n",
            "119/119 [==============================] - 0s 834us/step\n",
            "Train on 107 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 2.3495 - accuracy: 0.0748 - val_loss: 1.8940 - val_accuracy: 0.4167\n",
            "Epoch 2/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.7546 - accuracy: 0.4486 - val_loss: 1.3399 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1319 - accuracy: 0.5421 - val_loss: 0.8321 - val_accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8009 - accuracy: 0.4953 - val_loss: 0.6469 - val_accuracy: 0.8333\n",
            "Epoch 5/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6075 - val_loss: 0.5315 - val_accuracy: 0.8333\n",
            "Epoch 6/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7188 - accuracy: 0.6262 - val_loss: 0.9499 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.6542 - val_loss: 0.4328 - val_accuracy: 0.9167\n",
            "Epoch 8/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7103 - val_loss: 0.3382 - val_accuracy: 0.8333\n",
            "Epoch 9/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.6916 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7196 - val_loss: 0.6773 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.8037 - val_loss: 0.2671 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8972 - val_loss: 0.1716 - val_accuracy: 0.9167\n",
            "Epoch 13/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.7944 - val_loss: 0.1777 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.8879 - val_loss: 0.3377 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.8972 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9626 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9720 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9907 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "119/119 [==============================] - 0s 837us/step\n",
            "119/119 [==============================] - 0s 832us/step\n",
            "119/119 [==============================] - 0s 836us/step\n",
            "119/119 [==============================] - 0s 904us/step\n",
            "18回目\n",
            "Train on 107 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 2.2657 - accuracy: 0.1682 - val_loss: 1.8098 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.6313 - accuracy: 0.3925 - val_loss: 1.6397 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4202 - accuracy: 0.4673 - val_loss: 1.6090 - val_accuracy: 0.5833\n",
            "Epoch 4/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.3402 - accuracy: 0.4953 - val_loss: 1.4355 - val_accuracy: 0.4167\n",
            "Epoch 5/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.2814 - accuracy: 0.4766 - val_loss: 1.3852 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.2173 - accuracy: 0.5140 - val_loss: 1.4214 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1797 - accuracy: 0.5607 - val_loss: 1.4288 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1178 - accuracy: 0.5981 - val_loss: 1.3551 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.0279 - accuracy: 0.6636 - val_loss: 1.2665 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.9964 - accuracy: 0.7009 - val_loss: 1.2355 - val_accuracy: 0.5833\n",
            "Epoch 11/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8526 - accuracy: 0.7570 - val_loss: 1.3902 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8698 - accuracy: 0.7009 - val_loss: 1.2828 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7536 - accuracy: 0.7757 - val_loss: 1.1251 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.7196 - val_loss: 1.1869 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.7477 - val_loss: 1.3771 - val_accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.7477 - val_loss: 1.1995 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.7850 - val_loss: 1.1429 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.7570 - val_loss: 1.2282 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.8318 - val_loss: 1.4123 - val_accuracy: 0.7500\n",
            "Epoch 20/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.8131 - val_loss: 1.2888 - val_accuracy: 0.7500\n",
            "Epoch 21/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.8318 - val_loss: 1.2095 - val_accuracy: 0.7500\n",
            "Epoch 22/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.8131 - val_loss: 1.2532 - val_accuracy: 0.7500\n",
            "Epoch 23/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8318 - val_loss: 1.3294 - val_accuracy: 0.7500\n",
            "Epoch 24/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8692 - val_loss: 1.3115 - val_accuracy: 0.7500\n",
            "Epoch 25/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.9065 - val_loss: 1.2586 - val_accuracy: 0.7500\n",
            "119/119 [==============================] - 0s 840us/step\n",
            "119/119 [==============================] - 0s 1ms/step\n",
            "119/119 [==============================] - 0s 831us/step\n",
            "119/119 [==============================] - 0s 836us/step\n",
            "Train on 107 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 2.2196 - accuracy: 0.1963 - val_loss: 1.6520 - val_accuracy: 0.6667\n",
            "Epoch 2/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.5453 - accuracy: 0.5607 - val_loss: 1.0813 - val_accuracy: 0.7500\n",
            "Epoch 3/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.9807 - accuracy: 0.5234 - val_loss: 0.7621 - val_accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7739 - accuracy: 0.5607 - val_loss: 0.8015 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.5888 - val_loss: 0.5520 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.8161 - accuracy: 0.5234 - val_loss: 0.7649 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.6262 - val_loss: 0.7784 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7824 - accuracy: 0.5701 - val_loss: 0.5501 - val_accuracy: 0.7500\n",
            "Epoch 9/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7597 - accuracy: 0.6449 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7290 - val_loss: 0.7955 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.6729 - val_loss: 0.8340 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.6449 - val_loss: 0.6193 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6542 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.6542 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7196 - val_loss: 0.6772 - val_accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7944 - val_loss: 0.7352 - val_accuracy: 0.5000\n",
            "Epoch 17/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7757 - val_loss: 0.6687 - val_accuracy: 0.5000\n",
            "Epoch 18/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7850 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8131 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
            "Epoch 20/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8411 - val_loss: 0.6057 - val_accuracy: 0.6667\n",
            "Epoch 21/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8692 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
            "Epoch 22/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8692 - val_loss: 0.5581 - val_accuracy: 0.6667\n",
            "Epoch 23/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.9533 - val_loss: 0.3296 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.2918 - accuracy: 0.9252 - val_loss: 0.3602 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9533 - val_loss: 0.5091 - val_accuracy: 0.5833\n",
            "119/119 [==============================] - 0s 859us/step\n",
            "119/119 [==============================] - 0s 863us/step\n",
            "119/119 [==============================] - 0s 881us/step\n",
            "119/119 [==============================] - 0s 862us/step\n",
            "19回目\n",
            "Train on 103 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "103/103 [==============================] - 1s 5ms/step - loss: 2.4521 - accuracy: 0.0485 - val_loss: 2.1037 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.9560 - accuracy: 0.4854 - val_loss: 1.7794 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.5325 - accuracy: 0.4951 - val_loss: 1.5910 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.3995 - accuracy: 0.4854 - val_loss: 1.4607 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.3685 - accuracy: 0.5825 - val_loss: 1.3490 - val_accuracy: 0.6667\n",
            "Epoch 6/25\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 1.4195 - accuracy: 0.4272 - val_loss: 1.3235 - val_accuracy: 0.5833\n",
            "Epoch 7/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.3162 - accuracy: 0.4369 - val_loss: 1.3625 - val_accuracy: 0.6667\n",
            "Epoch 8/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.1927 - accuracy: 0.5534 - val_loss: 1.4455 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.2009 - accuracy: 0.5243 - val_loss: 1.5210 - val_accuracy: 0.3333\n",
            "Epoch 10/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.1605 - accuracy: 0.5728 - val_loss: 1.5496 - val_accuracy: 0.3333\n",
            "Epoch 11/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.1772 - accuracy: 0.5340 - val_loss: 1.4776 - val_accuracy: 0.3333\n",
            "Epoch 12/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.1112 - accuracy: 0.6019 - val_loss: 1.3580 - val_accuracy: 0.6667\n",
            "Epoch 13/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.0239 - accuracy: 0.6796 - val_loss: 1.2537 - val_accuracy: 0.6667\n",
            "Epoch 14/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.9632 - accuracy: 0.7379 - val_loss: 1.2199 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.8754 - accuracy: 0.7573 - val_loss: 1.3105 - val_accuracy: 0.6667\n",
            "Epoch 16/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.8810 - accuracy: 0.7087 - val_loss: 1.1842 - val_accuracy: 0.8333\n",
            "Epoch 17/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.8178 - accuracy: 0.7767 - val_loss: 1.0563 - val_accuracy: 0.8333\n",
            "Epoch 18/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.8914 - accuracy: 0.7573 - val_loss: 1.1209 - val_accuracy: 0.8333\n",
            "Epoch 19/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7881 - accuracy: 0.7864 - val_loss: 1.1922 - val_accuracy: 0.7500\n",
            "Epoch 20/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7181 - accuracy: 0.7864 - val_loss: 1.0157 - val_accuracy: 0.8333\n",
            "Epoch 21/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.8058 - val_loss: 0.9750 - val_accuracy: 0.8333\n",
            "Epoch 22/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7961 - val_loss: 1.0491 - val_accuracy: 0.8333\n",
            "Epoch 23/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.7864 - val_loss: 1.2194 - val_accuracy: 0.8333\n",
            "Epoch 24/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7670 - val_loss: 1.0570 - val_accuracy: 0.8333\n",
            "Epoch 25/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8155 - val_loss: 0.9178 - val_accuracy: 0.8333\n",
            "115/115 [==============================] - 0s 849us/step\n",
            "115/115 [==============================] - 0s 850us/step\n",
            "115/115 [==============================] - 0s 880us/step\n",
            "115/115 [==============================] - 0s 834us/step\n",
            "Train on 103 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 2.2718 - accuracy: 0.1456 - val_loss: 1.9375 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.8066 - accuracy: 0.5340 - val_loss: 1.4550 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.2052 - accuracy: 0.5922 - val_loss: 0.9500 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7775 - accuracy: 0.5728 - val_loss: 0.7013 - val_accuracy: 0.6667\n",
            "Epoch 5/25\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 0.7466 - accuracy: 0.5631 - val_loss: 0.8513 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.5922 - val_loss: 0.5653 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.7184 - val_loss: 0.6422 - val_accuracy: 0.7500\n",
            "Epoch 8/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7700 - accuracy: 0.5922 - val_loss: 0.8002 - val_accuracy: 0.4167\n",
            "Epoch 9/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7282 - val_loss: 0.6622 - val_accuracy: 0.6667\n",
            "Epoch 10/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.6408 - val_loss: 0.4293 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6602 - val_loss: 0.6675 - val_accuracy: 0.5833\n",
            "Epoch 12/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7379 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
            "Epoch 13/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7670 - val_loss: 0.3861 - val_accuracy: 0.8333\n",
            "Epoch 14/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8641 - val_loss: 0.2307 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8447 - val_loss: 0.3458 - val_accuracy: 0.8333\n",
            "Epoch 16/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9223 - val_loss: 0.4287 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9320 - val_loss: 0.1683 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9612 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9612 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9903 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9903 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9806 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "115/115 [==============================] - 0s 918us/step\n",
            "115/115 [==============================] - 0s 852us/step\n",
            "115/115 [==============================] - 0s 870us/step\n",
            "115/115 [==============================] - 0s 851us/step\n",
            "20回目\n",
            "Train on 103 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 2.2792 - accuracy: 0.1748 - val_loss: 1.9161 - val_accuracy: 0.8333\n",
            "Epoch 2/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.8286 - accuracy: 0.4563 - val_loss: 1.5428 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.3766 - accuracy: 0.6019 - val_loss: 1.4075 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.3011 - accuracy: 0.5825 - val_loss: 1.4027 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 1.2705 - accuracy: 0.5049 - val_loss: 1.3879 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.2360 - accuracy: 0.6214 - val_loss: 1.3870 - val_accuracy: 0.6667\n",
            "Epoch 7/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.1239 - accuracy: 0.5728 - val_loss: 1.4206 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.1297 - accuracy: 0.5922 - val_loss: 1.3432 - val_accuracy: 0.6667\n",
            "Epoch 9/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.9191 - accuracy: 0.7379 - val_loss: 1.2540 - val_accuracy: 0.6667\n",
            "Epoch 10/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.9078 - accuracy: 0.7282 - val_loss: 1.0949 - val_accuracy: 0.8333\n",
            "Epoch 11/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.8220 - accuracy: 0.7573 - val_loss: 1.1396 - val_accuracy: 0.7500\n",
            "Epoch 12/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.7767 - val_loss: 1.0033 - val_accuracy: 0.8333\n",
            "Epoch 13/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.8058 - val_loss: 1.0286 - val_accuracy: 0.8333\n",
            "Epoch 14/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.7864 - val_loss: 0.8663 - val_accuracy: 0.8333\n",
            "Epoch 15/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.8058 - val_loss: 0.9675 - val_accuracy: 0.8333\n",
            "Epoch 16/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.8058 - val_loss: 0.9720 - val_accuracy: 0.8333\n",
            "Epoch 17/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.8544 - val_loss: 0.8220 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.8350 - val_loss: 0.9399 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8447 - val_loss: 0.9341 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.8641 - val_loss: 0.8352 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8641 - val_loss: 0.9161 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8738 - val_loss: 0.9660 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8447 - val_loss: 0.7834 - val_accuracy: 0.8333\n",
            "Epoch 24/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8544 - val_loss: 0.8393 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.9029 - val_loss: 0.9595 - val_accuracy: 0.9167\n",
            "115/115 [==============================] - 0s 881us/step\n",
            "115/115 [==============================] - 0s 853us/step\n",
            "115/115 [==============================] - 0s 839us/step\n",
            "115/115 [==============================] - 0s 876us/step\n",
            "Train on 103 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 2.3223 - accuracy: 0.0291 - val_loss: 1.9540 - val_accuracy: 0.7500\n",
            "Epoch 2/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.8845 - accuracy: 0.5631 - val_loss: 1.4121 - val_accuracy: 0.8333\n",
            "Epoch 3/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1.3382 - accuracy: 0.6311 - val_loss: 0.8590 - val_accuracy: 0.8333\n",
            "Epoch 4/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.8418 - accuracy: 0.6214 - val_loss: 0.6688 - val_accuracy: 0.9167\n",
            "Epoch 5/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6408 - val_loss: 0.7914 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.6019 - val_loss: 0.5240 - val_accuracy: 0.9167\n",
            "Epoch 7/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.5922 - val_loss: 0.6412 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.7379 - val_loss: 0.6427 - val_accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6602 - val_loss: 0.3409 - val_accuracy: 0.8333\n",
            "Epoch 10/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.6990 - val_loss: 0.4200 - val_accuracy: 0.9167\n",
            "Epoch 11/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7670 - val_loss: 0.5019 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7573 - val_loss: 0.2225 - val_accuracy: 0.8333\n",
            "Epoch 13/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7573 - val_loss: 0.3769 - val_accuracy: 0.9167\n",
            "Epoch 14/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8932 - val_loss: 0.4329 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8835 - val_loss: 0.2149 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9223 - val_loss: 0.1223 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.2238 - accuracy: 0.8835 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9612 - val_loss: 0.2758 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9417 - val_loss: 0.3321 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9515 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9903 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9612 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9806 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
            "115/115 [==============================] - 0s 849us/step\n",
            "115/115 [==============================] - 0s 840us/step\n",
            "115/115 [==============================] - 0s 861us/step\n",
            "115/115 [==============================] - 0s 827us/step\n",
            "21回目\n",
            "Train on 101 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "101/101 [==============================] - 1s 6ms/step - loss: 2.3343 - accuracy: 0.0396 - val_loss: 2.1437 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 2.0242 - accuracy: 0.5545 - val_loss: 1.8674 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.6651 - accuracy: 0.5050 - val_loss: 1.5300 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.3452 - accuracy: 0.4851 - val_loss: 1.3789 - val_accuracy: 0.4167\n",
            "Epoch 5/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.4641 - accuracy: 0.4950 - val_loss: 1.2935 - val_accuracy: 0.6667\n",
            "Epoch 6/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.3219 - accuracy: 0.6139 - val_loss: 1.3250 - val_accuracy: 0.4167\n",
            "Epoch 7/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.0683 - accuracy: 0.6634 - val_loss: 1.3214 - val_accuracy: 0.4167\n",
            "Epoch 8/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.0349 - accuracy: 0.6832 - val_loss: 1.3183 - val_accuracy: 0.6667\n",
            "Epoch 9/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.0914 - accuracy: 0.6139 - val_loss: 1.3110 - val_accuracy: 0.6667\n",
            "Epoch 10/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.9464 - accuracy: 0.7426 - val_loss: 1.3083 - val_accuracy: 0.6667\n",
            "Epoch 11/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.9561 - accuracy: 0.7129 - val_loss: 1.2154 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.8611 - accuracy: 0.7624 - val_loss: 1.0226 - val_accuracy: 0.8333\n",
            "Epoch 13/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7847 - accuracy: 0.7822 - val_loss: 1.0961 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.8218 - val_loss: 0.9982 - val_accuracy: 0.8333\n",
            "Epoch 15/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.8020 - val_loss: 0.9618 - val_accuracy: 0.8333\n",
            "Epoch 16/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.8317 - val_loss: 1.0386 - val_accuracy: 0.8333\n",
            "Epoch 17/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.8317 - val_loss: 0.9166 - val_accuracy: 0.8333\n",
            "Epoch 18/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.8416 - val_loss: 0.8971 - val_accuracy: 0.8333\n",
            "Epoch 19/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.8614 - val_loss: 0.9970 - val_accuracy: 0.8333\n",
            "Epoch 20/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8218 - val_loss: 0.9172 - val_accuracy: 0.8333\n",
            "Epoch 21/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8614 - val_loss: 0.8351 - val_accuracy: 0.8333\n",
            "Epoch 22/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8119 - val_loss: 0.9093 - val_accuracy: 0.8333\n",
            "Epoch 23/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8812 - val_loss: 0.9003 - val_accuracy: 0.8333\n",
            "Epoch 24/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8911 - val_loss: 0.8392 - val_accuracy: 0.8333\n",
            "Epoch 25/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8614 - val_loss: 0.9991 - val_accuracy: 0.8333\n",
            "113/113 [==============================] - 0s 846us/step\n",
            "113/113 [==============================] - 0s 840us/step\n",
            "113/113 [==============================] - 0s 892us/step\n",
            "113/113 [==============================] - 0s 842us/step\n",
            "Train on 101 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "101/101 [==============================] - 1s 6ms/step - loss: 2.3176 - accuracy: 0.0693 - val_loss: 2.1573 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 2.0229 - accuracy: 0.5347 - val_loss: 1.8831 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.5763 - accuracy: 0.5842 - val_loss: 1.4200 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.9894 - accuracy: 0.6238 - val_loss: 1.0320 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.6139 - val_loss: 0.6594 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7155 - accuracy: 0.4752 - val_loss: 0.6130 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "101/101 [==============================] - 0s 4ms/step - loss: 0.7862 - accuracy: 0.5644 - val_loss: 1.1020 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7797 - accuracy: 0.6436 - val_loss: 0.7249 - val_accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.6535 - val_loss: 0.4737 - val_accuracy: 0.9167\n",
            "Epoch 10/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.6535 - val_loss: 0.5977 - val_accuracy: 0.6667\n",
            "Epoch 11/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.6832 - val_loss: 0.9290 - val_accuracy: 0.3333\n",
            "Epoch 12/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7228 - val_loss: 0.6028 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7624 - val_loss: 0.3242 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7723 - val_loss: 0.3580 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8812 - val_loss: 0.5277 - val_accuracy: 0.5833\n",
            "Epoch 16/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.9010 - val_loss: 0.3903 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9604 - val_loss: 0.1480 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9505 - val_loss: 0.1102 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9802 - val_loss: 0.1006 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9901 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
            "113/113 [==============================] - 0s 829us/step\n",
            "113/113 [==============================] - 0s 843us/step\n",
            "113/113 [==============================] - 0s 845us/step\n",
            "113/113 [==============================] - 0s 858us/step\n",
            "22回目\n",
            "Train on 101 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "101/101 [==============================] - 1s 6ms/step - loss: 2.2426 - accuracy: 0.1386 - val_loss: 1.8755 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.7436 - accuracy: 0.4455 - val_loss: 1.5204 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.3260 - accuracy: 0.4752 - val_loss: 1.4214 - val_accuracy: 0.4167\n",
            "Epoch 4/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.2712 - accuracy: 0.6040 - val_loss: 1.3835 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.3398 - accuracy: 0.4356 - val_loss: 1.4347 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.2539 - accuracy: 0.5545 - val_loss: 1.5510 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "101/101 [==============================] - 0s 4ms/step - loss: 1.1953 - accuracy: 0.5743 - val_loss: 1.5289 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.1326 - accuracy: 0.6238 - val_loss: 1.4721 - val_accuracy: 0.4167\n",
            "Epoch 9/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.1824 - accuracy: 0.5149 - val_loss: 1.4219 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.1321 - accuracy: 0.5743 - val_loss: 1.3883 - val_accuracy: 0.6667\n",
            "Epoch 11/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.1589 - accuracy: 0.5545 - val_loss: 1.3816 - val_accuracy: 0.5833\n",
            "Epoch 12/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.0497 - accuracy: 0.6436 - val_loss: 1.4066 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.0237 - accuracy: 0.6436 - val_loss: 1.4590 - val_accuracy: 0.5000\n",
            "Epoch 14/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.9735 - accuracy: 0.6733 - val_loss: 1.4493 - val_accuracy: 0.5000\n",
            "Epoch 15/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.9744 - accuracy: 0.6535 - val_loss: 1.3523 - val_accuracy: 0.6667\n",
            "Epoch 16/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.8695 - accuracy: 0.7228 - val_loss: 1.2812 - val_accuracy: 0.6667\n",
            "Epoch 17/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.9001 - accuracy: 0.7129 - val_loss: 1.2616 - val_accuracy: 0.6667\n",
            "Epoch 18/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.8433 - accuracy: 0.7129 - val_loss: 1.2939 - val_accuracy: 0.6667\n",
            "Epoch 19/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.7525 - val_loss: 1.3445 - val_accuracy: 0.6667\n",
            "Epoch 20/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7118 - accuracy: 0.7624 - val_loss: 1.2720 - val_accuracy: 0.6667\n",
            "Epoch 21/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.8020 - val_loss: 1.1741 - val_accuracy: 0.7500\n",
            "Epoch 22/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.8218 - val_loss: 1.1793 - val_accuracy: 0.6667\n",
            "Epoch 23/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.8317 - val_loss: 1.2828 - val_accuracy: 0.6667\n",
            "Epoch 24/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.8119 - val_loss: 0.9779 - val_accuracy: 0.8333\n",
            "Epoch 25/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.8317 - val_loss: 0.9817 - val_accuracy: 0.8333\n",
            "113/113 [==============================] - 0s 850us/step\n",
            "113/113 [==============================] - 0s 848us/step\n",
            "113/113 [==============================] - 0s 868us/step\n",
            "113/113 [==============================] - 0s 874us/step\n",
            "Train on 101 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "101/101 [==============================] - 1s 5ms/step - loss: 2.2507 - accuracy: 0.1980 - val_loss: 1.8322 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.7023 - accuracy: 0.5842 - val_loss: 1.3363 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 1.1647 - accuracy: 0.5149 - val_loss: 0.9702 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7862 - accuracy: 0.5644 - val_loss: 0.6454 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.5743 - val_loss: 0.5823 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.7310 - accuracy: 0.5644 - val_loss: 1.1187 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.8037 - accuracy: 0.5941 - val_loss: 0.7548 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.7030 - val_loss: 0.5742 - val_accuracy: 0.6667\n",
            "Epoch 9/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7228 - val_loss: 0.6930 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7426 - val_loss: 0.4730 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7129 - val_loss: 0.7749 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7921 - val_loss: 0.3358 - val_accuracy: 0.9167\n",
            "Epoch 13/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8416 - val_loss: 0.3055 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.8911 - val_loss: 0.4900 - val_accuracy: 0.5833\n",
            "Epoch 15/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9208 - val_loss: 0.2593 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9802 - val_loss: 0.1138 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9604 - val_loss: 0.1359 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9901 - val_loss: 0.1278 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9802 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "101/101 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "113/113 [==============================] - 0s 923us/step\n",
            "113/113 [==============================] - 0s 859us/step\n",
            "113/113 [==============================] - 0s 867us/step\n",
            "113/113 [==============================] - 0s 865us/step\n",
            "23回目\n",
            "Train on 100 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 2.2838 - accuracy: 0.1000 - val_loss: 2.0431 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.0071 - accuracy: 0.5200 - val_loss: 1.6650 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.6400 - accuracy: 0.5300 - val_loss: 1.2889 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3921 - accuracy: 0.4600 - val_loss: 1.1542 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4309 - accuracy: 0.4800 - val_loss: 1.0142 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3719 - accuracy: 0.4700 - val_loss: 0.9509 - val_accuracy: 0.6667\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2768 - accuracy: 0.5400 - val_loss: 0.9931 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1970 - accuracy: 0.5600 - val_loss: 1.0825 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1354 - accuracy: 0.5500 - val_loss: 1.0707 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1393 - accuracy: 0.6700 - val_loss: 1.0364 - val_accuracy: 0.5833\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1344 - accuracy: 0.5700 - val_loss: 0.9787 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0162 - accuracy: 0.7000 - val_loss: 0.9212 - val_accuracy: 0.6667\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9882 - accuracy: 0.7100 - val_loss: 0.8493 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9579 - accuracy: 0.7200 - val_loss: 0.7811 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.8849 - accuracy: 0.7700 - val_loss: 0.6292 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7976 - accuracy: 0.7800 - val_loss: 0.5759 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.7900 - val_loss: 0.4449 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.8100 - val_loss: 0.4901 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.7900 - val_loss: 0.3774 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.8100 - val_loss: 0.5109 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.7800 - val_loss: 0.3839 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.8500 - val_loss: 0.3741 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.8500 - val_loss: 0.4216 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8500 - val_loss: 0.3359 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.8500 - val_loss: 0.3042 - val_accuracy: 0.9167\n",
            "112/112 [==============================] - 0s 921us/step\n",
            "112/112 [==============================] - 0s 878us/step\n",
            "112/112 [==============================] - 0s 857us/step\n",
            "112/112 [==============================] - 0s 838us/step\n",
            "Train on 100 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 2.3272 - accuracy: 0.0400 - val_loss: 2.0941 - val_accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.0252 - accuracy: 0.5900 - val_loss: 1.7533 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.6097 - accuracy: 0.5800 - val_loss: 1.2695 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0421 - accuracy: 0.6200 - val_loss: 0.8888 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7320 - accuracy: 0.6400 - val_loss: 0.7232 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6800 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6400 - val_loss: 0.7541 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7800 - val_loss: 1.0250 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7267 - accuracy: 0.7200 - val_loss: 0.3125 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.7000 - val_loss: 0.4039 - val_accuracy: 0.8333\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8200 - val_loss: 0.4047 - val_accuracy: 0.8333\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8000 - val_loss: 0.2231 - val_accuracy: 0.9167\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8700 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8900 - val_loss: 0.1481 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9200 - val_loss: 0.1718 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9400 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9400 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9500 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9700 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9900 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9900 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9900 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "112/112 [==============================] - 0s 861us/step\n",
            "112/112 [==============================] - 0s 859us/step\n",
            "112/112 [==============================] - 0s 857us/step\n",
            "112/112 [==============================] - 0s 915us/step\n",
            "24回目\n",
            "Train on 100 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 2.3353 - accuracy: 0.0300 - val_loss: 2.0847 - val_accuracy: 0.7500\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.0483 - accuracy: 0.3200 - val_loss: 1.7734 - val_accuracy: 0.7500\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.7471 - accuracy: 0.4400 - val_loss: 1.2910 - val_accuracy: 0.9167\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3832 - accuracy: 0.4700 - val_loss: 1.0853 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3549 - accuracy: 0.4800 - val_loss: 1.2027 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3371 - accuracy: 0.6000 - val_loss: 1.0701 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2196 - accuracy: 0.5600 - val_loss: 0.9941 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1809 - accuracy: 0.5900 - val_loss: 1.0229 - val_accuracy: 0.6667\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1135 - accuracy: 0.6000 - val_loss: 1.0788 - val_accuracy: 0.6667\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1718 - accuracy: 0.4900 - val_loss: 1.1410 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1347 - accuracy: 0.5800 - val_loss: 1.1658 - val_accuracy: 0.3333\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.0871 - accuracy: 0.6700 - val_loss: 1.1721 - val_accuracy: 0.3333\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0411 - accuracy: 0.5800 - val_loss: 1.1185 - val_accuracy: 0.3333\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0119 - accuracy: 0.6300 - val_loss: 1.0183 - val_accuracy: 0.5000\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0141 - accuracy: 0.7100 - val_loss: 0.9233 - val_accuracy: 0.6667\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9724 - accuracy: 0.7000 - val_loss: 0.9006 - val_accuracy: 0.6667\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9976 - accuracy: 0.7000 - val_loss: 0.9187 - val_accuracy: 0.6667\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.8593 - accuracy: 0.7200 - val_loss: 0.9010 - val_accuracy: 0.6667\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.8168 - accuracy: 0.7600 - val_loss: 0.8464 - val_accuracy: 0.6667\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7281 - accuracy: 0.7800 - val_loss: 0.8093 - val_accuracy: 0.6667\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.7800 - val_loss: 0.7726 - val_accuracy: 0.6667\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.8000 - val_loss: 0.5906 - val_accuracy: 0.7500\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.8300 - val_loss: 0.4845 - val_accuracy: 0.8333\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.8100 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.8500 - val_loss: 0.2570 - val_accuracy: 0.9167\n",
            "112/112 [==============================] - 0s 873us/step\n",
            "112/112 [==============================] - 0s 861us/step\n",
            "112/112 [==============================] - 0s 841us/step\n",
            "112/112 [==============================] - 0s 843us/step\n",
            "Train on 100 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 2.2079 - accuracy: 0.1700 - val_loss: 1.7383 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.4520 - accuracy: 0.6000 - val_loss: 1.2539 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.8929 - accuracy: 0.5900 - val_loss: 0.8411 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7221 - accuracy: 0.5700 - val_loss: 0.5302 - val_accuracy: 0.6667\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.5300 - val_loss: 0.8050 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7000 - val_loss: 1.1721 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7980 - accuracy: 0.6100 - val_loss: 0.6787 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7500 - val_loss: 0.4760 - val_accuracy: 0.8333\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6600 - val_loss: 0.6404 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7300 - val_loss: 0.9178 - val_accuracy: 0.4167\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.8100 - val_loss: 0.8473 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8000 - val_loss: 0.4744 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8700 - val_loss: 0.3786 - val_accuracy: 0.9167\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8400 - val_loss: 0.4036 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8600 - val_loss: 0.4496 - val_accuracy: 0.6667\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9100 - val_loss: 0.3284 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.2291 - accuracy: 0.9100 - val_loss: 0.1431 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9300 - val_loss: 0.1025 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9600 - val_loss: 0.0907 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9800 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9900 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "112/112 [==============================] - 0s 863us/step\n",
            "112/112 [==============================] - 0s 852us/step\n",
            "112/112 [==============================] - 0s 861us/step\n",
            "112/112 [==============================] - 0s 857us/step\n",
            "25回目\n",
            "Train on 100 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 2.2452 - accuracy: 0.1400 - val_loss: 1.9757 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.9472 - accuracy: 0.5200 - val_loss: 1.5665 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.5384 - accuracy: 0.5300 - val_loss: 1.2076 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3250 - accuracy: 0.5700 - val_loss: 1.0726 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3627 - accuracy: 0.5400 - val_loss: 0.9870 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2779 - accuracy: 0.5600 - val_loss: 1.0130 - val_accuracy: 0.4167\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.2198 - accuracy: 0.5600 - val_loss: 1.0818 - val_accuracy: 0.4167\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1636 - accuracy: 0.5700 - val_loss: 1.1174 - val_accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1617 - accuracy: 0.5400 - val_loss: 1.0754 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1292 - accuracy: 0.5700 - val_loss: 1.0447 - val_accuracy: 0.5833\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0885 - accuracy: 0.6300 - val_loss: 1.0331 - val_accuracy: 0.5833\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0332 - accuracy: 0.6100 - val_loss: 1.0237 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0733 - accuracy: 0.6200 - val_loss: 1.0137 - val_accuracy: 0.5833\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0238 - accuracy: 0.7000 - val_loss: 0.9909 - val_accuracy: 0.5833\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0125 - accuracy: 0.7000 - val_loss: 0.9386 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9518 - accuracy: 0.6800 - val_loss: 0.8789 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.9175 - accuracy: 0.6800 - val_loss: 0.8673 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9173 - accuracy: 0.6900 - val_loss: 0.8976 - val_accuracy: 0.5833\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.8473 - accuracy: 0.7500 - val_loss: 0.7762 - val_accuracy: 0.7500\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.8195 - accuracy: 0.7900 - val_loss: 0.5961 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7883 - accuracy: 0.7900 - val_loss: 0.6587 - val_accuracy: 0.8333\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.8000 - val_loss: 0.7002 - val_accuracy: 0.6667\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.7800 - val_loss: 0.3992 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.8200 - val_loss: 0.3764 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.8300 - val_loss: 0.4055 - val_accuracy: 1.0000\n",
            "112/112 [==============================] - 0s 867us/step\n",
            "112/112 [==============================] - 0s 879us/step\n",
            "112/112 [==============================] - 0s 919us/step\n",
            "112/112 [==============================] - 0s 851us/step\n",
            "Train on 100 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 2.2428 - accuracy: 0.1300 - val_loss: 1.8452 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.6110 - accuracy: 0.5900 - val_loss: 1.2951 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9378 - accuracy: 0.6500 - val_loss: 0.9599 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.6900 - val_loss: 0.5678 - val_accuracy: 0.9167\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6400 - val_loss: 0.9714 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7000 - val_loss: 0.6028 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7700 - val_loss: 0.4765 - val_accuracy: 0.6667\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7000 - val_loss: 0.8887 - val_accuracy: 0.4167\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8400 - val_loss: 0.2483 - val_accuracy: 0.9167\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8700 - val_loss: 0.1401 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.9400 - val_loss: 0.4162 - val_accuracy: 0.7500\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9300 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9900 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9700 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9900 - val_loss: 0.0921 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9600 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0322 - accuracy: 0.9800 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0247 - accuracy: 0.9900 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 8.6368e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "112/112 [==============================] - 0s 1ms/step\n",
            "112/112 [==============================] - 0s 1ms/step\n",
            "112/112 [==============================] - 0s 2ms/step\n",
            "112/112 [==============================] - 0s 1ms/step\n",
            "26回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3646 - accuracy: 0.0707 - val_loss: 2.0784 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9373 - accuracy: 0.5354 - val_loss: 1.7166 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5281 - accuracy: 0.5051 - val_loss: 1.3887 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3746 - accuracy: 0.5354 - val_loss: 1.1050 - val_accuracy: 0.4167\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 1.2859 - accuracy: 0.6162 - val_loss: 0.9623 - val_accuracy: 0.8333\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2637 - accuracy: 0.5556 - val_loss: 1.0011 - val_accuracy: 0.5833\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1105 - accuracy: 0.6566 - val_loss: 1.1172 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0788 - accuracy: 0.5960 - val_loss: 1.1369 - val_accuracy: 0.4167\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9864 - accuracy: 0.6667 - val_loss: 1.0655 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9169 - accuracy: 0.6869 - val_loss: 0.9141 - val_accuracy: 0.6667\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.8305 - accuracy: 0.7374 - val_loss: 0.7229 - val_accuracy: 0.9167\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7694 - accuracy: 0.7576 - val_loss: 0.5693 - val_accuracy: 0.9167\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.7677 - val_loss: 0.5095 - val_accuracy: 0.9167\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.8081 - val_loss: 0.4612 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.8081 - val_loss: 0.4318 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.8081 - val_loss: 0.4464 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.8081 - val_loss: 0.4865 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8283 - val_loss: 0.4609 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.8485 - val_loss: 0.4435 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8687 - val_loss: 0.4185 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8687 - val_loss: 0.3531 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8485 - val_loss: 0.2971 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8586 - val_loss: 0.2520 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8586 - val_loss: 0.2173 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8384 - val_loss: 0.2065 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 859us/step\n",
            "111/111 [==============================] - 0s 866us/step\n",
            "111/111 [==============================] - 0s 928us/step\n",
            "111/111 [==============================] - 0s 846us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.2381 - accuracy: 0.1616 - val_loss: 1.6259 - val_accuracy: 0.7500\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4200 - accuracy: 0.5758 - val_loss: 1.0005 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8253 - accuracy: 0.5657 - val_loss: 0.7980 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5960 - val_loss: 0.4799 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.6162 - val_loss: 0.6957 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6768 - val_loss: 0.6928 - val_accuracy: 0.5833\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7879 - val_loss: 0.3666 - val_accuracy: 0.8333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7336 - accuracy: 0.6364 - val_loss: 0.6763 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8283 - val_loss: 0.7420 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8283 - val_loss: 0.3426 - val_accuracy: 0.9167\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8788 - val_loss: 0.2888 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8283 - val_loss: 0.6010 - val_accuracy: 0.6667\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.8788 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.9091 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9293 - val_loss: 0.1348 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9596 - val_loss: 0.2171 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9293 - val_loss: 0.2215 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9697 - val_loss: 0.1126 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9798 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9899 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9697 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9798 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9798 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 845us/step\n",
            "111/111 [==============================] - 0s 852us/step\n",
            "111/111 [==============================] - 0s 866us/step\n",
            "111/111 [==============================] - 0s 887us/step\n",
            "27回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3505 - accuracy: 0.0404 - val_loss: 2.0392 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9599 - accuracy: 0.5253 - val_loss: 1.6782 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5800 - accuracy: 0.4747 - val_loss: 1.3547 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3233 - accuracy: 0.5051 - val_loss: 1.1420 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4596 - accuracy: 0.5253 - val_loss: 0.9412 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3639 - accuracy: 0.5354 - val_loss: 0.9229 - val_accuracy: 0.6667\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2365 - accuracy: 0.5253 - val_loss: 1.0314 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1686 - accuracy: 0.6061 - val_loss: 1.1665 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1325 - accuracy: 0.5960 - val_loss: 1.2379 - val_accuracy: 0.3333\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1766 - accuracy: 0.5556 - val_loss: 1.2440 - val_accuracy: 0.3333\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1103 - accuracy: 0.6263 - val_loss: 1.1877 - val_accuracy: 0.3333\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0359 - accuracy: 0.6364 - val_loss: 1.0594 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9802 - accuracy: 0.6970 - val_loss: 0.8881 - val_accuracy: 0.6667\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9112 - accuracy: 0.7273 - val_loss: 0.7406 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8286 - accuracy: 0.7778 - val_loss: 0.6863 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8278 - accuracy: 0.7475 - val_loss: 0.5883 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7506 - accuracy: 0.7677 - val_loss: 0.4917 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.8081 - val_loss: 0.4910 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.7677 - val_loss: 0.5183 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7980 - val_loss: 0.4371 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.8081 - val_loss: 0.4427 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8182 - val_loss: 0.4940 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8485 - val_loss: 0.4105 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.8485 - val_loss: 0.3513 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8788 - val_loss: 0.3060 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 862us/step\n",
            "111/111 [==============================] - 0s 842us/step\n",
            "111/111 [==============================] - 0s 876us/step\n",
            "111/111 [==============================] - 0s 854us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3829 - accuracy: 0.0505 - val_loss: 2.1366 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9845 - accuracy: 0.5455 - val_loss: 1.8020 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5068 - accuracy: 0.6061 - val_loss: 1.2879 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9385 - accuracy: 0.6162 - val_loss: 0.9290 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6263 - val_loss: 0.6637 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6465 - val_loss: 0.6717 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7677 - val_loss: 0.4612 - val_accuracy: 0.8333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7071 - val_loss: 0.8122 - val_accuracy: 0.4167\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7475 - val_loss: 0.2864 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.6869 - val_loss: 0.4645 - val_accuracy: 0.8333\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8283 - val_loss: 0.6773 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8081 - val_loss: 0.3107 - val_accuracy: 0.8333\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8889 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8182 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.9495 - val_loss: 0.2330 - val_accuracy: 0.8333\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9798 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9697 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9495 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 846us/step\n",
            "111/111 [==============================] - 0s 854us/step\n",
            "111/111 [==============================] - 0s 872us/step\n",
            "111/111 [==============================] - 0s 849us/step\n",
            "28回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.3272 - accuracy: 0.1313 - val_loss: 1.9775 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.8661 - accuracy: 0.5051 - val_loss: 1.5635 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 1.5072 - accuracy: 0.5051 - val_loss: 1.2402 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 1.3233 - accuracy: 0.5960 - val_loss: 1.0288 - val_accuracy: 0.6667\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3758 - accuracy: 0.5859 - val_loss: 0.9595 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2192 - accuracy: 0.5354 - val_loss: 1.0082 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1715 - accuracy: 0.5657 - val_loss: 1.0199 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1103 - accuracy: 0.6364 - val_loss: 1.0060 - val_accuracy: 0.7500\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0847 - accuracy: 0.6364 - val_loss: 0.9897 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0428 - accuracy: 0.6364 - val_loss: 0.9705 - val_accuracy: 0.6667\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0659 - accuracy: 0.6667 - val_loss: 0.9256 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8984 - accuracy: 0.7374 - val_loss: 0.7909 - val_accuracy: 0.8333\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7670 - accuracy: 0.7879 - val_loss: 0.5988 - val_accuracy: 0.9167\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.8081 - val_loss: 0.5249 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.8081 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7072 - accuracy: 0.7980 - val_loss: 0.4133 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.8081 - val_loss: 0.3945 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.8283 - val_loss: 0.4298 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.8283 - val_loss: 0.4227 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.8283 - val_loss: 0.4156 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.8485 - val_loss: 0.4269 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8586 - val_loss: 0.4375 - val_accuracy: 0.8333\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7879 - val_loss: 0.3745 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8788 - val_loss: 0.3113 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8990 - val_loss: 0.2674 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 850us/step\n",
            "111/111 [==============================] - 0s 856us/step\n",
            "111/111 [==============================] - 0s 854us/step\n",
            "111/111 [==============================] - 0s 910us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.2415 - accuracy: 0.1616 - val_loss: 1.8339 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5172 - accuracy: 0.5758 - val_loss: 1.3390 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8945 - accuracy: 0.6061 - val_loss: 0.9788 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.6061 - val_loss: 0.5341 - val_accuracy: 0.6667\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9299 - accuracy: 0.4949 - val_loss: 0.6413 - val_accuracy: 0.6667\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6263 - val_loss: 1.1181 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.6667 - val_loss: 0.9612 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.6566 - val_loss: 0.6576 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7172 - val_loss: 0.5320 - val_accuracy: 0.8333\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6061 - val_loss: 0.5551 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7374 - val_loss: 0.7205 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7374 - val_loss: 0.8144 - val_accuracy: 0.5000\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7980 - val_loss: 0.7468 - val_accuracy: 0.5000\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7778 - val_loss: 0.5712 - val_accuracy: 0.6667\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.8081 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8081 - val_loss: 0.6210 - val_accuracy: 0.6667\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.7778 - val_loss: 0.7132 - val_accuracy: 0.5833\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7677 - val_loss: 0.6760 - val_accuracy: 0.6667\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8485 - val_loss: 0.4893 - val_accuracy: 0.6667\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8889 - val_loss: 0.3266 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.9293 - val_loss: 0.4028 - val_accuracy: 0.7500\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8990 - val_loss: 0.5611 - val_accuracy: 0.6667\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.8889 - val_loss: 0.4196 - val_accuracy: 0.7500\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9495 - val_loss: 0.1772 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9697 - val_loss: 0.1467 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 863us/step\n",
            "111/111 [==============================] - 0s 926us/step\n",
            "111/111 [==============================] - 0s 870us/step\n",
            "111/111 [==============================] - 0s 874us/step\n",
            "29回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.3683 - accuracy: 0.0303 - val_loss: 2.1673 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 2.1169 - accuracy: 0.5354 - val_loss: 1.9682 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.8738 - accuracy: 0.4949 - val_loss: 1.6635 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5016 - accuracy: 0.5051 - val_loss: 1.3691 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3605 - accuracy: 0.5253 - val_loss: 1.1414 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4093 - accuracy: 0.4949 - val_loss: 0.9370 - val_accuracy: 0.6667\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4199 - accuracy: 0.5253 - val_loss: 0.9071 - val_accuracy: 0.9167\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2658 - accuracy: 0.5758 - val_loss: 0.9637 - val_accuracy: 0.6667\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1661 - accuracy: 0.6263 - val_loss: 1.0682 - val_accuracy: 0.3333\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1110 - accuracy: 0.6162 - val_loss: 1.1295 - val_accuracy: 0.3333\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1149 - accuracy: 0.5657 - val_loss: 1.1142 - val_accuracy: 0.4167\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0475 - accuracy: 0.6465 - val_loss: 1.0035 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9540 - accuracy: 0.7172 - val_loss: 0.8293 - val_accuracy: 0.9167\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9170 - accuracy: 0.7677 - val_loss: 0.6539 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8028 - accuracy: 0.7980 - val_loss: 0.5582 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.8081 - val_loss: 0.4256 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.7980 - val_loss: 0.3878 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.8182 - val_loss: 0.3650 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.8182 - val_loss: 0.3691 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.8384 - val_loss: 0.3708 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8283 - val_loss: 0.3908 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.8182 - val_loss: 0.4503 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.8788 - val_loss: 0.3973 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.8283 - val_loss: 0.3507 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8283 - val_loss: 0.3455 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 853us/step\n",
            "111/111 [==============================] - 0s 846us/step\n",
            "111/111 [==============================] - 0s 906us/step\n",
            "111/111 [==============================] - 0s 870us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.2665 - accuracy: 0.1717 - val_loss: 1.9974 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.8320 - accuracy: 0.5758 - val_loss: 1.5064 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2270 - accuracy: 0.5960 - val_loss: 1.0564 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8080 - accuracy: 0.6162 - val_loss: 0.7655 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.6162 - val_loss: 0.6464 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7252 - accuracy: 0.5758 - val_loss: 0.9939 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6667 - val_loss: 0.6104 - val_accuracy: 0.7500\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6364 - val_loss: 0.5663 - val_accuracy: 0.7500\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7576 - val_loss: 0.6062 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7677 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.7980 - val_loss: 0.3092 - val_accuracy: 0.8333\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7677 - val_loss: 0.4420 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8485 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9192 - val_loss: 0.3774 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9293 - val_loss: 0.1402 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9495 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9899 - val_loss: 0.1312 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9798 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9899 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9899 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 904us/step\n",
            "111/111 [==============================] - 0s 920us/step\n",
            "111/111 [==============================] - 0s 1ms/step\n",
            "111/111 [==============================] - 0s 849us/step\n",
            "30回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3146 - accuracy: 0.0808 - val_loss: 2.0894 - val_accuracy: 0.9167\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 2.0887 - accuracy: 0.3939 - val_loss: 1.7456 - val_accuracy: 0.8333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.7379 - accuracy: 0.5556 - val_loss: 1.2843 - val_accuracy: 0.5833\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3871 - accuracy: 0.5960 - val_loss: 1.0374 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3039 - accuracy: 0.5960 - val_loss: 0.8707 - val_accuracy: 0.9167\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2894 - accuracy: 0.5859 - val_loss: 0.8050 - val_accuracy: 0.9167\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2307 - accuracy: 0.6465 - val_loss: 0.8148 - val_accuracy: 0.7500\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9882 - accuracy: 0.6869 - val_loss: 0.7961 - val_accuracy: 0.9167\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9783 - accuracy: 0.6465 - val_loss: 0.7455 - val_accuracy: 0.9167\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9172 - accuracy: 0.7778 - val_loss: 0.6473 - val_accuracy: 0.9167\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7983 - accuracy: 0.7879 - val_loss: 0.5586 - val_accuracy: 0.9167\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7879 - val_loss: 0.4593 - val_accuracy: 0.9167\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.7980 - val_loss: 0.4037 - val_accuracy: 0.9167\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.8182 - val_loss: 0.3771 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.8283 - val_loss: 0.3421 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8283 - val_loss: 0.3283 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.8384 - val_loss: 0.3184 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.8283 - val_loss: 0.3261 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8384 - val_loss: 0.3218 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.8485 - val_loss: 0.3302 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8687 - val_loss: 0.3512 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8586 - val_loss: 0.3178 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8788 - val_loss: 0.2956 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8889 - val_loss: 0.2782 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8990 - val_loss: 0.2481 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 956us/step\n",
            "111/111 [==============================] - 0s 926us/step\n",
            "111/111 [==============================] - 0s 894us/step\n",
            "111/111 [==============================] - 0s 846us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.3004 - accuracy: 0.0808 - val_loss: 2.0555 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9493 - accuracy: 0.5758 - val_loss: 1.6948 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4604 - accuracy: 0.5859 - val_loss: 1.2650 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9834 - accuracy: 0.5657 - val_loss: 1.0285 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7744 - accuracy: 0.5758 - val_loss: 0.7052 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.7172 - val_loss: 0.5732 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.5960 - val_loss: 0.9295 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.6566 - val_loss: 0.8472 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7172 - val_loss: 0.4719 - val_accuracy: 0.8333\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7778 - val_loss: 0.6157 - val_accuracy: 0.5833\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8788 - val_loss: 1.3198 - val_accuracy: 0.3333\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7374 - val_loss: 0.2871 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8485 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8081 - val_loss: 0.4146 - val_accuracy: 0.8333\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9394 - val_loss: 0.6203 - val_accuracy: 0.3333\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.8990 - val_loss: 0.2000 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9899 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9596 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9899 - val_loss: 0.1462 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9899 - val_loss: 0.1864 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 934us/step\n",
            "111/111 [==============================] - 0s 855us/step\n",
            "111/111 [==============================] - 0s 870us/step\n",
            "111/111 [==============================] - 0s 937us/step\n",
            "31回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3130 - accuracy: 0.0505 - val_loss: 2.0531 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9669 - accuracy: 0.4848 - val_loss: 1.6375 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5504 - accuracy: 0.5051 - val_loss: 1.2793 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4337 - accuracy: 0.4949 - val_loss: 1.0445 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4029 - accuracy: 0.4949 - val_loss: 0.9711 - val_accuracy: 0.8333\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3214 - accuracy: 0.4949 - val_loss: 1.0275 - val_accuracy: 0.5833\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1787 - accuracy: 0.5556 - val_loss: 1.1292 - val_accuracy: 0.4167\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 1.1505 - accuracy: 0.5354 - val_loss: 1.1773 - val_accuracy: 0.4167\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1874 - accuracy: 0.5354 - val_loss: 1.1593 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1603 - accuracy: 0.5657 - val_loss: 1.0910 - val_accuracy: 0.5833\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1045 - accuracy: 0.6465 - val_loss: 1.0158 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0529 - accuracy: 0.6768 - val_loss: 0.9491 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0411 - accuracy: 0.6566 - val_loss: 0.9033 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0500 - accuracy: 0.6465 - val_loss: 0.8519 - val_accuracy: 0.8333\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0663 - accuracy: 0.6465 - val_loss: 0.8193 - val_accuracy: 0.8333\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9323 - accuracy: 0.6970 - val_loss: 0.8116 - val_accuracy: 0.8333\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9369 - accuracy: 0.7273 - val_loss: 0.7891 - val_accuracy: 0.8333\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8606 - accuracy: 0.7475 - val_loss: 0.7325 - val_accuracy: 0.8333\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8090 - accuracy: 0.7576 - val_loss: 0.6398 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.8283 - val_loss: 0.5769 - val_accuracy: 0.8333\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.7879 - val_loss: 0.4291 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7980 - val_loss: 0.3869 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.8384 - val_loss: 0.3847 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7980 - val_loss: 0.3329 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.7677 - val_loss: 0.2905 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 873us/step\n",
            "111/111 [==============================] - 0s 866us/step\n",
            "111/111 [==============================] - 0s 882us/step\n",
            "111/111 [==============================] - 0s 937us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.4082 - accuracy: 0.0303 - val_loss: 2.1174 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9991 - accuracy: 0.5455 - val_loss: 1.8329 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5280 - accuracy: 0.6061 - val_loss: 1.4456 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0756 - accuracy: 0.6061 - val_loss: 1.1222 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8335 - accuracy: 0.5859 - val_loss: 0.7364 - val_accuracy: 0.4167\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.5657 - val_loss: 0.5250 - val_accuracy: 0.8333\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7993 - accuracy: 0.5657 - val_loss: 0.7479 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6162 - val_loss: 1.2095 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7768 - accuracy: 0.6162 - val_loss: 0.9169 - val_accuracy: 0.3333\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7677 - val_loss: 0.4230 - val_accuracy: 0.8333\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7172 - val_loss: 0.3581 - val_accuracy: 0.9167\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.6667 - val_loss: 0.7057 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7980 - val_loss: 0.9641 - val_accuracy: 0.4167\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8283 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8586 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8081 - val_loss: 0.2444 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9495 - val_loss: 0.4357 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9495 - val_loss: 0.3618 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9394 - val_loss: 0.1347 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9798 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9596 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9798 - val_loss: 0.0960 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 895us/step\n",
            "111/111 [==============================] - 0s 852us/step\n",
            "111/111 [==============================] - 0s 863us/step\n",
            "111/111 [==============================] - 0s 889us/step\n",
            "32回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3857 - accuracy: 0.0707 - val_loss: 2.2491 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 2.1742 - accuracy: 0.3737 - val_loss: 2.0756 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9503 - accuracy: 0.4747 - val_loss: 1.7470 - val_accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.6239 - accuracy: 0.4848 - val_loss: 1.2945 - val_accuracy: 0.5833\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2843 - accuracy: 0.5556 - val_loss: 1.0530 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3231 - accuracy: 0.6162 - val_loss: 0.9587 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3857 - accuracy: 0.5758 - val_loss: 0.8554 - val_accuracy: 0.9167\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2815 - accuracy: 0.5657 - val_loss: 0.9155 - val_accuracy: 0.8333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1201 - accuracy: 0.6263 - val_loss: 1.0289 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1414 - accuracy: 0.6364 - val_loss: 1.0096 - val_accuracy: 0.8333\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0541 - accuracy: 0.6869 - val_loss: 0.9177 - val_accuracy: 0.9167\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9464 - accuracy: 0.6970 - val_loss: 0.8411 - val_accuracy: 0.9167\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9883 - accuracy: 0.7273 - val_loss: 0.8388 - val_accuracy: 0.8333\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8739 - accuracy: 0.7475 - val_loss: 0.7579 - val_accuracy: 0.8333\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8107 - accuracy: 0.7879 - val_loss: 0.5770 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7921 - accuracy: 0.8283 - val_loss: 0.5087 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.8283 - val_loss: 0.4777 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7980 - val_loss: 0.3976 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.8182 - val_loss: 0.3630 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.8182 - val_loss: 0.3449 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.8081 - val_loss: 0.3495 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.8081 - val_loss: 0.3162 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8586 - val_loss: 0.3224 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8586 - val_loss: 0.2992 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8485 - val_loss: 0.2873 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 890us/step\n",
            "111/111 [==============================] - 0s 852us/step\n",
            "111/111 [==============================] - 0s 857us/step\n",
            "111/111 [==============================] - 0s 854us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3987 - accuracy: 0.0000e+00 - val_loss: 2.1650 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 2.1128 - accuracy: 0.5859 - val_loss: 1.8620 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.7376 - accuracy: 0.6566 - val_loss: 1.4008 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2122 - accuracy: 0.5657 - val_loss: 1.0623 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.5960 - val_loss: 0.8312 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6566 - val_loss: 0.4798 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8456 - accuracy: 0.4545 - val_loss: 0.6866 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7273 - val_loss: 1.1869 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8167 - accuracy: 0.6970 - val_loss: 0.4409 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6970 - val_loss: 0.3062 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7374 - val_loss: 0.6254 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.8283 - val_loss: 0.7238 - val_accuracy: 0.4167\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8384 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9091 - val_loss: 0.1560 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9293 - val_loss: 0.4046 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.9293 - val_loss: 0.3297 - val_accuracy: 0.8333\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9697 - val_loss: 0.1055 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9697 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9798 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9899 - val_loss: 0.0687 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9798 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 850us/step\n",
            "111/111 [==============================] - 0s 882us/step\n",
            "111/111 [==============================] - 0s 844us/step\n",
            "111/111 [==============================] - 0s 846us/step\n",
            "33回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.2354 - accuracy: 0.2727 - val_loss: 1.8990 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.8487 - accuracy: 0.5253 - val_loss: 1.5003 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4684 - accuracy: 0.5354 - val_loss: 1.3277 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4475 - accuracy: 0.4848 - val_loss: 1.1092 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4148 - accuracy: 0.5455 - val_loss: 1.0016 - val_accuracy: 0.8333\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3256 - accuracy: 0.5859 - val_loss: 1.0113 - val_accuracy: 0.5833\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1560 - accuracy: 0.4949 - val_loss: 1.1126 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1253 - accuracy: 0.6364 - val_loss: 1.2075 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1223 - accuracy: 0.6162 - val_loss: 1.2130 - val_accuracy: 0.3333\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.6364 - val_loss: 1.1046 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0049 - accuracy: 0.7374 - val_loss: 0.9083 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9106 - accuracy: 0.7677 - val_loss: 0.7148 - val_accuracy: 0.8333\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8608 - accuracy: 0.7778 - val_loss: 0.8342 - val_accuracy: 0.6667\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7997 - accuracy: 0.7475 - val_loss: 0.5825 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7931 - accuracy: 0.7677 - val_loss: 0.3981 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7896 - accuracy: 0.7879 - val_loss: 0.7317 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.7980 - val_loss: 0.7201 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.7980 - val_loss: 0.3950 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7980 - val_loss: 0.3923 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.7980 - val_loss: 0.4239 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.8586 - val_loss: 0.6147 - val_accuracy: 0.7500\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.8081 - val_loss: 0.4625 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.8485 - val_loss: 0.2937 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8687 - val_loss: 0.2637 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8182 - val_loss: 0.2310 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 841us/step\n",
            "111/111 [==============================] - 0s 854us/step\n",
            "111/111 [==============================] - 0s 846us/step\n",
            "111/111 [==============================] - 0s 858us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.2748 - accuracy: 0.2525 - val_loss: 2.0932 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9828 - accuracy: 0.6364 - val_loss: 1.7214 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5198 - accuracy: 0.6364 - val_loss: 1.2416 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0142 - accuracy: 0.5758 - val_loss: 0.9277 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7687 - accuracy: 0.5859 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.5455 - val_loss: 0.5889 - val_accuracy: 0.5833\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7374 - val_loss: 0.8633 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.7071 - val_loss: 0.2951 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7374 - val_loss: 0.3734 - val_accuracy: 0.9167\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8889 - val_loss: 0.3324 - val_accuracy: 0.9167\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8485 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9192 - val_loss: 0.1003 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9697 - val_loss: 0.2682 - val_accuracy: 0.9167\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9697 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9798 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9899 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 9.1380e-04 - accuracy: 1.0000 - val_loss: 5.4392e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 8.4149e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 4.0982e-04 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 927us/step\n",
            "111/111 [==============================] - 0s 860us/step\n",
            "111/111 [==============================] - 0s 867us/step\n",
            "111/111 [==============================] - 0s 873us/step\n",
            "34回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.2654 - accuracy: 0.2626 - val_loss: 2.0153 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9254 - accuracy: 0.5152 - val_loss: 1.6558 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 1.5409 - accuracy: 0.5051 - val_loss: 1.3804 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3612 - accuracy: 0.4949 - val_loss: 1.1409 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3764 - accuracy: 0.5556 - val_loss: 1.0054 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3640 - accuracy: 0.4747 - val_loss: 0.9883 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2440 - accuracy: 0.4949 - val_loss: 1.0759 - val_accuracy: 0.4167\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 1.1026 - accuracy: 0.6263 - val_loss: 1.1732 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0791 - accuracy: 0.6465 - val_loss: 1.2340 - val_accuracy: 0.3333\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1315 - accuracy: 0.5859 - val_loss: 1.2213 - val_accuracy: 0.3333\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0992 - accuracy: 0.6465 - val_loss: 1.1161 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0436 - accuracy: 0.7172 - val_loss: 0.9462 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0048 - accuracy: 0.6465 - val_loss: 0.9476 - val_accuracy: 0.6667\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.7172 - val_loss: 1.0686 - val_accuracy: 0.4167\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9218 - accuracy: 0.7374 - val_loss: 1.0050 - val_accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8711 - accuracy: 0.7475 - val_loss: 0.7886 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8497 - accuracy: 0.7778 - val_loss: 0.7991 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7834 - accuracy: 0.7879 - val_loss: 0.8227 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.7980 - val_loss: 0.7350 - val_accuracy: 0.8333\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.8283 - val_loss: 0.5462 - val_accuracy: 0.8333\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.7879 - val_loss: 0.7624 - val_accuracy: 0.8333\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8081 - val_loss: 0.5289 - val_accuracy: 0.8333\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.8283 - val_loss: 0.2855 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.8586 - val_loss: 0.6389 - val_accuracy: 0.8333\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.8283 - val_loss: 0.3394 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 1ms/step\n",
            "111/111 [==============================] - 0s 850us/step\n",
            "111/111 [==============================] - 0s 857us/step\n",
            "111/111 [==============================] - 0s 866us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.3815 - accuracy: 0.0404 - val_loss: 1.9578 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.8004 - accuracy: 0.6566 - val_loss: 1.4808 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1986 - accuracy: 0.6061 - val_loss: 1.0824 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.6768 - val_loss: 0.8759 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.6667 - val_loss: 0.4980 - val_accuracy: 0.8333\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6667 - val_loss: 0.5935 - val_accuracy: 0.6667\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7172 - val_loss: 0.8887 - val_accuracy: 0.4167\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.6768 - val_loss: 0.4393 - val_accuracy: 0.8333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7778 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7677 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.6970 - val_loss: 0.8246 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8182 - val_loss: 0.2995 - val_accuracy: 0.8333\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.3041 - val_accuracy: 0.8333\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8384 - val_loss: 0.4622 - val_accuracy: 0.8333\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8485 - val_loss: 0.2013 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.8990 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.8687 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9798 - val_loss: 0.1381 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9596 - val_loss: 0.0782 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9899 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9798 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 872us/step\n",
            "111/111 [==============================] - 0s 862us/step\n",
            "111/111 [==============================] - 0s 957us/step\n",
            "111/111 [==============================] - 0s 860us/step\n",
            "35回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.4033 - accuracy: 0.0101 - val_loss: 2.0748 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.9717 - accuracy: 0.4747 - val_loss: 1.7070 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5923 - accuracy: 0.4949 - val_loss: 1.3050 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3233 - accuracy: 0.5253 - val_loss: 1.0877 - val_accuracy: 0.4167\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3565 - accuracy: 0.5253 - val_loss: 0.9988 - val_accuracy: 0.6667\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3860 - accuracy: 0.5051 - val_loss: 1.0098 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1721 - accuracy: 0.6263 - val_loss: 1.0846 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1606 - accuracy: 0.5051 - val_loss: 1.1567 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1945 - accuracy: 0.5657 - val_loss: 1.1667 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1323 - accuracy: 0.5960 - val_loss: 1.1218 - val_accuracy: 0.6667\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0743 - accuracy: 0.6768 - val_loss: 1.0676 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0080 - accuracy: 0.7273 - val_loss: 0.9813 - val_accuracy: 0.6667\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9520 - accuracy: 0.7475 - val_loss: 0.8465 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8862 - accuracy: 0.7576 - val_loss: 0.6985 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8253 - accuracy: 0.7778 - val_loss: 0.6810 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7768 - accuracy: 0.8283 - val_loss: 0.6349 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7323 - accuracy: 0.8081 - val_loss: 0.4280 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.8283 - val_loss: 0.3819 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.8384 - val_loss: 0.4814 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.8384 - val_loss: 0.3393 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.8485 - val_loss: 0.3533 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.8384 - val_loss: 0.3802 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.8687 - val_loss: 0.3443 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.8889 - val_loss: 0.3133 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8889 - val_loss: 0.2734 - val_accuracy: 0.9167\n",
            "111/111 [==============================] - 0s 916us/step\n",
            "111/111 [==============================] - 0s 892us/step\n",
            "111/111 [==============================] - 0s 955us/step\n",
            "111/111 [==============================] - 0s 893us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 5ms/step - loss: 2.3536 - accuracy: 0.0202 - val_loss: 2.1359 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 2.0275 - accuracy: 0.5960 - val_loss: 1.8421 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.5813 - accuracy: 0.6364 - val_loss: 1.3559 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9988 - accuracy: 0.6566 - val_loss: 0.9319 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.6263 - val_loss: 0.6449 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.5960 - val_loss: 0.5394 - val_accuracy: 0.8333\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6768 - val_loss: 0.9358 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.7935 - accuracy: 0.6566 - val_loss: 0.4615 - val_accuracy: 0.8333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6970 - val_loss: 0.3720 - val_accuracy: 0.9167\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7879 - val_loss: 0.7922 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7374 - val_loss: 0.5796 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.8182 - val_loss: 0.2290 - val_accuracy: 0.9167\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7879 - val_loss: 0.2298 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8283 - val_loss: 0.6467 - val_accuracy: 0.5000\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8485 - val_loss: 0.6512 - val_accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8485 - val_loss: 0.1925 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9495 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8788 - val_loss: 0.0912 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1617 - accuracy: 0.9394 - val_loss: 0.1450 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9798 - val_loss: 0.2507 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9495 - val_loss: 0.1802 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9697 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9798 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 866us/step\n",
            "111/111 [==============================] - 0s 853us/step\n",
            "111/111 [==============================] - 0s 897us/step\n",
            "111/111 [==============================] - 0s 852us/step\n",
            "36回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 1.9200 - val_accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.8354 - accuracy: 0.4646 - val_loss: 1.4581 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.5051 - val_loss: 1.2053 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3749 - accuracy: 0.5455 - val_loss: 1.0013 - val_accuracy: 0.6667\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3616 - accuracy: 0.4747 - val_loss: 0.9186 - val_accuracy: 0.5833\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2442 - accuracy: 0.5253 - val_loss: 1.0039 - val_accuracy: 0.6667\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 1.2756 - accuracy: 0.5152 - val_loss: 1.1198 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2025 - accuracy: 0.5152 - val_loss: 1.1754 - val_accuracy: 0.4167\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1715 - accuracy: 0.5657 - val_loss: 1.1672 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1275 - accuracy: 0.6162 - val_loss: 1.1271 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0975 - accuracy: 0.6667 - val_loss: 1.0738 - val_accuracy: 0.5833\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1197 - accuracy: 0.5657 - val_loss: 1.0327 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9998 - accuracy: 0.6364 - val_loss: 0.9946 - val_accuracy: 0.5833\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0299 - accuracy: 0.6667 - val_loss: 0.9565 - val_accuracy: 0.5833\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0086 - accuracy: 0.6869 - val_loss: 0.9574 - val_accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.9060 - accuracy: 0.7374 - val_loss: 0.8510 - val_accuracy: 0.8333\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8383 - accuracy: 0.7778 - val_loss: 0.7102 - val_accuracy: 0.8333\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8423 - accuracy: 0.7475 - val_loss: 0.6954 - val_accuracy: 0.8333\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7283 - accuracy: 0.7879 - val_loss: 0.8560 - val_accuracy: 0.5833\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.7576 - val_loss: 0.5974 - val_accuracy: 0.8333\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.8283 - val_loss: 0.4229 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.8081 - val_loss: 0.5832 - val_accuracy: 0.8333\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.8283 - val_loss: 0.5560 - val_accuracy: 0.8333\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7879 - val_loss: 0.2988 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.8384 - val_loss: 0.2651 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 876us/step\n",
            "111/111 [==============================] - 0s 903us/step\n",
            "111/111 [==============================] - 0s 883us/step\n",
            "111/111 [==============================] - 0s 865us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3422 - accuracy: 0.0404 - val_loss: 2.1343 - val_accuracy: 0.4167\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 2.0790 - accuracy: 0.6667 - val_loss: 1.8975 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.7194 - accuracy: 0.5758 - val_loss: 1.5407 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2610 - accuracy: 0.6061 - val_loss: 1.1698 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8379 - accuracy: 0.6061 - val_loss: 0.8942 - val_accuracy: 0.3333\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6768 - val_loss: 0.5318 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.6869 - val_loss: 0.6096 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7273 - val_loss: 1.2721 - val_accuracy: 0.3333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7273 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8384 - val_loss: 0.1830 - val_accuracy: 0.9167\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6970 - val_loss: 0.5182 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8788 - val_loss: 0.8953 - val_accuracy: 0.4167\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8384 - val_loss: 0.3471 - val_accuracy: 0.8333\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9495 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9596 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9192 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9798 - val_loss: 0.2393 - val_accuracy: 0.8333\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9697 - val_loss: 0.1817 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9798 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9798 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 926us/step\n",
            "111/111 [==============================] - 0s 899us/step\n",
            "111/111 [==============================] - 0s 866us/step\n",
            "111/111 [==============================] - 0s 844us/step\n",
            "37回目\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.3408 - accuracy: 0.1010 - val_loss: 1.9095 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.8677 - accuracy: 0.4444 - val_loss: 1.4749 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.4418 - accuracy: 0.5455 - val_loss: 1.2469 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3627 - accuracy: 0.5253 - val_loss: 1.0838 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.3230 - accuracy: 0.5657 - val_loss: 0.9642 - val_accuracy: 0.6667\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2126 - accuracy: 0.5859 - val_loss: 0.9237 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1418 - accuracy: 0.6162 - val_loss: 0.9977 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0707 - accuracy: 0.6465 - val_loss: 1.0775 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.1312 - accuracy: 0.5859 - val_loss: 1.0532 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.0572 - accuracy: 0.6364 - val_loss: 0.9750 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.9787 - accuracy: 0.7172 - val_loss: 0.8730 - val_accuracy: 0.8333\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8971 - accuracy: 0.7172 - val_loss: 0.7443 - val_accuracy: 0.8333\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8447 - accuracy: 0.7475 - val_loss: 0.6639 - val_accuracy: 0.8333\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.8125 - accuracy: 0.7576 - val_loss: 0.5316 - val_accuracy: 0.9167\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7328 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.9167\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.7980 - val_loss: 0.4306 - val_accuracy: 0.9167\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7980 - val_loss: 0.3822 - val_accuracy: 0.9167\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.8384 - val_loss: 0.3636 - val_accuracy: 0.9167\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.8283 - val_loss: 0.3619 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8687 - val_loss: 0.3011 - val_accuracy: 0.9167\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8384 - val_loss: 0.2691 - val_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8788 - val_loss: 0.2494 - val_accuracy: 0.9167\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8788 - val_loss: 0.2199 - val_accuracy: 0.9167\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8182 - val_loss: 0.1742 - val_accuracy: 0.9167\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8889 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 921us/step\n",
            "111/111 [==============================] - 0s 876us/step\n",
            "111/111 [==============================] - 0s 867us/step\n",
            "111/111 [==============================] - 0s 851us/step\n",
            "Train on 99 samples, validate on 12 samples\n",
            "Epoch 1/25\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 2.2410 - accuracy: 0.1919 - val_loss: 1.9920 - val_accuracy: 0.3333\n",
            "Epoch 2/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.8089 - accuracy: 0.6465 - val_loss: 1.5263 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 1.2010 - accuracy: 0.6465 - val_loss: 1.0811 - val_accuracy: 0.3333\n",
            "Epoch 4/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.7927 - accuracy: 0.5758 - val_loss: 0.7729 - val_accuracy: 0.3333\n",
            "Epoch 5/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6768 - val_loss: 0.4950 - val_accuracy: 0.9167\n",
            "Epoch 6/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6566 - val_loss: 0.9006 - val_accuracy: 0.3333\n",
            "Epoch 7/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7071 - val_loss: 0.9484 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7576 - val_loss: 0.4198 - val_accuracy: 0.8333\n",
            "Epoch 9/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7778 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 10/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.8384 - val_loss: 1.2149 - val_accuracy: 0.3333\n",
            "Epoch 11/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7677 - val_loss: 0.1822 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8889 - val_loss: 0.1250 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.8485 - val_loss: 0.7359 - val_accuracy: 0.4167\n",
            "Epoch 14/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1858 - accuracy: 0.9091 - val_loss: 0.8472 - val_accuracy: 0.3333\n",
            "Epoch 15/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9293 - val_loss: 0.1297 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9899 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.9192 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.1496 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9899 - val_loss: 0.3342 - val_accuracy: 0.9167\n",
            "Epoch 20/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9596 - val_loss: 0.0878 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9899 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9798 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "111/111 [==============================] - 0s 862us/step\n",
            "111/111 [==============================] - 0s 856us/step\n",
            "111/111 [==============================] - 0s 946us/step\n",
            "111/111 [==============================] - 0s 852us/step\n",
            "38回目\n",
            "Train on 98 samples, validate on 11 samples\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.3526 - accuracy: 0.0204 - val_loss: 1.9715 - val_accuracy: 0.3636\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.9312 - accuracy: 0.4388 - val_loss: 1.4582 - val_accuracy: 0.3636\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.5218 - accuracy: 0.5510 - val_loss: 0.9958 - val_accuracy: 0.3636\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.2899 - accuracy: 0.6122 - val_loss: 0.7806 - val_accuracy: 0.4545\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.4236 - accuracy: 0.5612 - val_loss: 0.7046 - val_accuracy: 0.8182\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.3920 - accuracy: 0.5408 - val_loss: 0.8057 - val_accuracy: 0.7273\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.1158 - accuracy: 0.6224 - val_loss: 0.9818 - val_accuracy: 0.6364\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.1031 - accuracy: 0.6735 - val_loss: 1.1163 - val_accuracy: 0.3636\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.0704 - accuracy: 0.6122 - val_loss: 1.1474 - val_accuracy: 0.3636\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.1080 - accuracy: 0.6633 - val_loss: 1.0782 - val_accuracy: 0.5455\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.0695 - accuracy: 0.6531 - val_loss: 0.9155 - val_accuracy: 0.7273\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.9906 - accuracy: 0.7347 - val_loss: 0.7532 - val_accuracy: 0.7273\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.9325 - accuracy: 0.7449 - val_loss: 0.6967 - val_accuracy: 0.7273\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.8341 - accuracy: 0.7857 - val_loss: 0.5235 - val_accuracy: 0.8182\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.7832 - accuracy: 0.7857 - val_loss: 0.3254 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.8163 - val_loss: 0.4322 - val_accuracy: 0.8182\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.8061 - val_loss: 0.2648 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.8469 - val_loss: 0.2907 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.8469 - val_loss: 0.3323 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.8061 - val_loss: 0.2822 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.8367 - val_loss: 0.3511 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8265 - val_loss: 0.4047 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.8776 - val_loss: 0.2943 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8469 - val_loss: 0.3025 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8367 - val_loss: 0.3171 - val_accuracy: 1.0000\n",
            "109/109 [==============================] - 0s 850us/step\n",
            "109/109 [==============================] - 0s 854us/step\n",
            "109/109 [==============================] - 0s 897us/step\n",
            "109/109 [==============================] - 0s 847us/step\n",
            "Train on 98 samples, validate on 11 samples\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.4576 - accuracy: 0.0102 - val_loss: 1.9982 - val_accuracy: 0.3636\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.7419 - accuracy: 0.6020 - val_loss: 1.5743 - val_accuracy: 0.3636\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1.1334 - accuracy: 0.6020 - val_loss: 1.1879 - val_accuracy: 0.3636\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.8587 - accuracy: 0.5816 - val_loss: 0.7929 - val_accuracy: 0.3636\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.7174 - accuracy: 0.5714 - val_loss: 0.5647 - val_accuracy: 0.6364\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.4796 - val_loss: 0.6068 - val_accuracy: 0.9091\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.6122 - val_loss: 0.9762 - val_accuracy: 0.3636\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.6327 - val_loss: 1.0409 - val_accuracy: 0.3636\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6429 - val_loss: 0.7679 - val_accuracy: 0.3636\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.6224 - val_loss: 0.5124 - val_accuracy: 0.9091\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6429 - val_loss: 0.4893 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6735 - val_loss: 0.6267 - val_accuracy: 0.6364\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8367 - val_loss: 0.7752 - val_accuracy: 0.3636\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8367 - val_loss: 0.6556 - val_accuracy: 0.5455\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8061 - val_loss: 0.3692 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.9082 - val_loss: 0.2672 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8673 - val_loss: 0.3099 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9286 - val_loss: 0.4470 - val_accuracy: 0.7273\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9388 - val_loss: 0.3429 - val_accuracy: 0.9091\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9490 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9898 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9592 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9898 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
            "109/109 [==============================] - 0s 854us/step\n",
            "109/109 [==============================] - 0s 855us/step\n",
            "109/109 [==============================] - 0s 920us/step\n",
            "109/109 [==============================] - 0s 883us/step\n",
            "39回目\n",
            "Train on 97 samples, validate on 11 samples\n",
            "Epoch 1/25\n",
            "97/97 [==============================] - 1s 6ms/step - loss: 2.3096 - accuracy: 0.0619 - val_loss: 2.0661 - val_accuracy: 0.3636\n",
            "Epoch 2/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 2.0045 - accuracy: 0.4536 - val_loss: 1.6865 - val_accuracy: 0.3636\n",
            "Epoch 3/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.5916 - accuracy: 0.4948 - val_loss: 1.2129 - val_accuracy: 0.3636\n",
            "Epoch 4/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.2671 - accuracy: 0.4948 - val_loss: 0.9108 - val_accuracy: 0.3636\n",
            "Epoch 5/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.2962 - accuracy: 0.6186 - val_loss: 0.6710 - val_accuracy: 0.8182\n",
            "Epoch 6/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.2557 - accuracy: 0.5155 - val_loss: 0.6986 - val_accuracy: 0.7273\n",
            "Epoch 7/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.1217 - accuracy: 0.6289 - val_loss: 0.8281 - val_accuracy: 0.3636\n",
            "Epoch 8/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.0823 - accuracy: 0.6392 - val_loss: 0.9602 - val_accuracy: 0.3636\n",
            "Epoch 9/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6186 - val_loss: 1.0129 - val_accuracy: 0.3636\n",
            "Epoch 10/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.9160 - accuracy: 0.7010 - val_loss: 0.9508 - val_accuracy: 0.7273\n",
            "Epoch 11/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.8829 - accuracy: 0.7526 - val_loss: 0.8582 - val_accuracy: 0.7273\n",
            "Epoch 12/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.8351 - val_loss: 0.7571 - val_accuracy: 0.7273\n",
            "Epoch 13/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.7835 - val_loss: 0.4787 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.8247 - val_loss: 0.3620 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.8041 - val_loss: 0.3003 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.8454 - val_loss: 0.1959 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.8351 - val_loss: 0.2320 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8351 - val_loss: 0.1663 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8557 - val_loss: 0.2074 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8557 - val_loss: 0.2229 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8866 - val_loss: 0.2222 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8969 - val_loss: 0.1597 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8660 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "97/97 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8557 - val_loss: 0.0834 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8969 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
            "108/108 [==============================] - 0s 855us/step\n",
            "108/108 [==============================] - 0s 847us/step\n",
            "108/108 [==============================] - 0s 924us/step\n",
            "108/108 [==============================] - 0s 877us/step\n",
            "Train on 97 samples, validate on 11 samples\n",
            "Epoch 1/25\n",
            "97/97 [==============================] - 1s 6ms/step - loss: 2.3058 - accuracy: 0.0619 - val_loss: 2.0878 - val_accuracy: 0.3636\n",
            "Epoch 2/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.9458 - accuracy: 0.6598 - val_loss: 1.7132 - val_accuracy: 0.3636\n",
            "Epoch 3/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 1.4290 - accuracy: 0.7113 - val_loss: 1.1779 - val_accuracy: 0.3636\n",
            "Epoch 4/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.9472 - accuracy: 0.5876 - val_loss: 0.8479 - val_accuracy: 0.3636\n",
            "Epoch 5/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6495 - val_loss: 0.6587 - val_accuracy: 0.6364\n",
            "Epoch 6/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.7953 - accuracy: 0.5670 - val_loss: 1.0140 - val_accuracy: 0.3636\n",
            "Epoch 7/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.7747 - accuracy: 0.6392 - val_loss: 0.6102 - val_accuracy: 0.6364\n",
            "Epoch 8/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7010 - val_loss: 0.5986 - val_accuracy: 0.6364\n",
            "Epoch 9/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.7010 - val_loss: 0.9363 - val_accuracy: 0.4545\n",
            "Epoch 10/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.6289 - val_loss: 0.6283 - val_accuracy: 0.5455\n",
            "Epoch 11/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.7526 - val_loss: 0.3129 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7732 - val_loss: 0.4120 - val_accuracy: 0.8182\n",
            "Epoch 13/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8454 - val_loss: 0.9046 - val_accuracy: 0.4545\n",
            "Epoch 14/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8247 - val_loss: 0.3800 - val_accuracy: 0.8182\n",
            "Epoch 15/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9175 - val_loss: 0.1485 - val_accuracy: 0.9091\n",
            "Epoch 16/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8866 - val_loss: 0.1256 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9485 - val_loss: 0.3076 - val_accuracy: 0.9091\n",
            "Epoch 18/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9485 - val_loss: 0.4469 - val_accuracy: 0.7273\n",
            "Epoch 19/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.1877 - accuracy: 0.8969 - val_loss: 0.1481 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9897 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9897 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.9381 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "97/97 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9691 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
            "108/108 [==============================] - 0s 878us/step\n",
            "108/108 [==============================] - 0s 981us/step\n",
            "108/108 [==============================] - 0s 939us/step\n",
            "108/108 [==============================] - 0s 924us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd1hUx9fHv7N0RUGNoIKKFQt2Y0GJiUYTW+w9akzUmKhoYl5LzE+xm9hijRp7icaa2Guwghqxl4CKImJBlN7Z/b5/DCAgZZeikMznefaBvXdm7rl3751z55wzZwRJKBQKhUKR39C8bQEUCoVCoUgPpaAUCoVCkS9RCkqhUCgU+RKloBQKhUKRL1EKSqFQKBT5EqWgFAqFQpEvUQpKoVAoFPkSpaAUCoVCkS9RCkqhKCAIiXpmFf8Z1M2uUBiIEGK8EOKeECJcCHFLCNElxb4hQojbKfbVT9xeVgixSwjxXAjxQgixJHG7mxBiU4r6DkIICiGME7+fEELMEEKcBRAFoKIQYlCKY/gKIb5MI18nIcQVIURYopwfCyF6CCG80pT7VgjxZ95dKYUiZxi/bQEUigLIPQAuAJ4C6AFgkxCiMoDmANwAdAZwEUAlAPFCCCMA+wD8BaA/AC2AhgYcrz+AtgC8AQgAjgA6APAF8B6Ag0KIv0leEkI0ArABQHcAxwGUBlAEwH0AK4QQ1UneTtHu9OxcAIXiTaBGUAqFgZDcTvIxSR3J3wHcAdAIwGAAP5H8m5K7JP0S95UB8H8kI0nGkDxjwCHXkbxJMoFkPMn9JO8lHuMkgCOQChMAvgCwhuTRRPkCSP5DMhbA7wA+BQAhRE0ADpCKU6HIlygFpVAYiBBiQKIJLUQIEQLACcA7AMpCjq7SUhaAH8mEbB7SP83x2wohzgkhXiYev13i8ZOOlZ4MALAeQF8hhIAcPW1LVFwKRb5EKSiFwgCEEOUB/ApgBIASJK0B3IA0vflDmvXS4g+gXJJfKQ2RAAql+F4qnTLJSw4IIcwA7AQwF4Bt4vEPJB4/6VjpyQCS5wDEQY62+gLYmP5ZKhT5A6WgFArDKAypMJ4DgBBiEOQICgBWAfhOCNEgMeKucqJCuwDgCYDZQojCQghzIUSzxDpXALwnhCgnhLACMCGL45sCMEs8foIQoi2ANin2rwYwSAjRSgihEULYCSGqpdi/AcASAPEGmhkVijeOUlAKhQGQvAVgHgBPAM8A1AJwNnHfdgAzAPwGIBzAHwCKk9QC6AigMoCHAB4B6JVY5yikb+gaAC9k4RMiGQ7AFcA2AMGQI6E9KfZfADAIwAIAoQBOAiifoomNkAp1ExSKfI5QCxYqFP8dhBAWAAIB1Cd5523Lo1BkhhpBKRT/Lb4C8LdSToqCQJ4pKCHEGiFEoBDiRgb7hRBikRDirhDiWtKERoVCkTcIIR4AGAVgzFsWRaHQi7wcQa0D8HEm+9sCqJL4GQrglzyURaH4z0PSgWR5kpfftiwKhT7kmYIieQrAy0yKdAKwIXGy4TkA1kKI0nklj0KhUCgKFm8z1ZEdUk9AfJS47UnagkKIoZCjLFhYWDQoW7Zsjg6s0+mg0RQc99ublJcE4uI0iIkxQkyMEWJjNYiNNUJSLI2ZmQ42NjGwsNAaJGt0tBaPHwdBqw3NS/Ffw8LCAtbW1rC0tIQQAgkJGoSEmCA01ARarcigViRkFPdLpJiClAlmKFWqMooWjTdYPp1OwN8/DrGx9wFYoEgRO5QsaQxjY106ZV+/tiQQHm6C4GBTxMa+2mdmFg8Tk0gIEQGtNhKxsdHQatP/zfISIQTMzc1hbFwYQGFotUUQE2MKnS7ttY+HvO4RiZ8ovLr2FpDTw4rh1XSvrEiA/A0DE/9XZBchBMzMzGBqWhhCJP2GZkhIkL+FjU0MrK0zvvf16b98fHyCSJZMu71A5OIjuRLASgBo2LAhL168mKP2Tpw4gffffz8XJHsz5KW8JHHq1EWMHbsDjx8Xx7NnDREf3wCANYoWBZo0ARo0kB+tFpgwAfD3Bz7/HJg9GyiZ5pZKK2tERBy6d5+Pw4enASDatJmJTp264sYNgevXgevXgdBEnWViAlSrBlSuDDx4ANy6BcQm5jkoUgRwcgJq1QJq15aybN0KeHrKeh9/DPTtC9SrBwgBaLVaHDx4EEuXLoWvry9KlCiDkiWH4f79IRCiFDp0AIYNA4KCzqNx48aIi4vFwYPbsXnzEly9+g8KFbJEly5fo3PngShSxCrD67d790asWDEdT58ewWeflcGMGYC+7xL37gHt2wPx8WNgZLQEJiZWCA+/j4iI8eja9X8YM8YMTZumf20DA4Hly4Fly4Bnz4AaNbRo2fIg/PyO4uJFTzx9ehuxsUmdRiVYWDRF1apN0aRJIzx7VhSXLwN+fnKvkRFQvTpQt668fo6OgHEmPQMJPH4MXL4MXLoEXL0KREbKfcWKAfXrAzVrJuDs2RPw8/sHQUEekNO9ggAA1tY1ULu2Mxo2rIa7d6/g8mUP+Pv7AgBMTc3g5NQQ9eo5o359ZwQHB2HNmnnw9f0HpUsnYODA0ejRYwgsLYukK9uDB3ewbt0C7N69DjEx0fjgg44YMMAVpUuXy/S3uHr1KurUqZNpmfxEVvIGBgIbNwJHj8rno1Mn+cxWSncK9+tERABXrhBHj3rD0/MM/P3PIibmbwAvAABFi1aHk1NztGnTDIMGtUa5cmUybEuf/ksI4ZfuDpJ59oHM9XUjg30rAPRJ8d0bQOms2mzQoAFziru7e47byCt0Oh1v3rzJpUuXskePHqxSpQoXLlyY68d58uQJ58yZw8qVaxIAAePEv/JTvnxl9urVm3PnzuWJEycYFhZGkgwPJ8eOJY2NyWLFyOXLyYSEV+2mvLZz5x6nqWk1AmDp0p15+vSDdM6XvHeP3LqV/O47skUL0saGbNaMHD2a3LyZ9PGR5dLj9m3S1ZUsWpQEyLp1yV9/JSMiyOBgcv78BJYps4/ARwRAjcaEnTv3o6enJ3U6Hbdt28YffviBNjY2BMCqVaty0aJFDA0N1es6XrhwgQD44Ye/EyC7dSMjI7Oud+oUWaIEWbw4Wb16I7q4uPDly5fs3n1gopw1CJxj48bkli1kXJy8tleukIMGkaam8nzbtAnhsGHzWbFiRQKghYUF33vvPY4bN467dv3Jo0efcckSsl8/smJFWcfGhuzUiZw9mzx5Uj95MyMhgbx2Td4LAweSVarI4xQqFM/WrcnJk8k//ojgnj1/cfr06WzXrh2tra0JgLa2tuzatSvnzp1LDw8PxsTEvNa+Vqvlvn372KJFCwKglZUVx44dy0ePHiWX8fDwYNeuXSmEoKmpKQcPHsxbt27pfQ75uU9ID33lvXOH/Ppr0sJC/iYdOpAnTqR+nnQ68p9/yLVryaFDSScnUghZXgiydm3yq6/ItWujuG3bKc6YMTPVb7h27docywrgItPTE+ltzK1PFgqqPYCDkGP2JgAu6NPmv01B6XQ63rp1K1khlSxZMllJ2Nvbs2TJknRwcGBcXFyOjxUbG8udO3eyQ4cONDIySuwIm7JIkZXcsyeEL1684JEjRzhz5kx27dqV5cqVS5ZFCMFq1arx008/5YIFC7hhw2k2bx5OgHz3XfLvxPSo7u7uvHjxEcuV600ANDauyMmT9+dY9qwID5cdZK1a8q62siILFZL/N21KbtxIXr/uzVGjRrFo0aIEQEdHR2o0Ggoh2LFjRx45coRardag48bFxbFQoUIcPnwE58+XD3TDhuTjxxnXWb+eNDEhHR3Jq1cjaGxszAkTJiTvP3DgAO3s7CmEhsWKjSEQRTs7snbt4MSOn+zb14effjqSlpaWBMBmzZpx27ZtWd4nYWEZK/vcJCSEPHbMPcP9Wq2Wz549o85AYS5cuMBevXpRo9HQ2NiY/fr1o7OzMwGwWLFinDhxIp88eWKwvPmpT9AHQ+V9/pycMoUsWVI+Ew0bkj/8QLZrJ1+S5LhYPjcffUS6uZGHD8vfMSO0Wi2vX7/OFy9e5FjWN66gAGyB9CfFQ/qXvgAwDMCwxP0CwFLIxJbXATTUp91/k4KaNGlS8pt7kkLq378/V69ezXv37lGn0/GPP/4ggByNou7evUtXV1eWKFEicTRThnXqjCdwm++9l3ln+uzZMx44cIBTp05lx44dWaZMmVRKy86uBs3N+xNYyE6dzrBp0wkELAmYsUWLyXzxIirbcmcHnY48fZocMEC+DXp5vV4mLCyMy5YtY4sWLdirVy/6+vrm6JitWrVi3bp1SZJ79pCFC5P29uTly6nLabXkxInyqWvZknz5kjx+/DgB8MCBA6nKhoaG8ssvvyQAlilThQ0anKK9fQSHDDnKNm3aUwhBExMTfvrpp/w76e0gn5GXz5mvry9HjRrFwoULs0KFCly8eDEjIiKy3V5+6RP0JbvyRkWRK1aQVavK+7BGDfKLL8hVq8ibN+U9mtvkSwWVV59/i4LS6XS0tLRkw4YNUymk9Mo1bNiQVlZWDAwMNPg4z58/Z6lSpWhqasqePXty9eqDrFMngQA5fjwZH2+47I8fP+bevXs5efJkdujQgTY2tqnMgyVLtuXx43cNb/gtkBv3wuTJk6nRaBiS+Lp5+bJUUIULS4VFSjNa9+7yiRsyRJrsSHLKlCkUQjA4ODjdto8dO0YHB4fEF4vSBEAbGxtOmjSJjzN7s8gHvInnLC4uzuBRb3rkhz7BEHIqr1YrzeBvAqWgDCQ/3IwBAQEEwKVLl2ZZdt26dTQ2NubgwYMNOoZOp2OnTp1oamrKy5cvc+dO6aspVozcty+7kqd/nEePHnHhwj84dOgKarVvwIaUS+TGvXDs2DEC4MGDB5O3PX4szShCkFOnSjOoEOTcualNbB9++CFr166dafvh4eH85ptvWLduXa5bty5dP01+JD88Z/pSkGQlC5a8OVFQBSfW+l+Gt7c3AKBq1apZli1fvjxcXV2xevVqGBLBuGrVKvz555+YPn0WNmyoi27dZJTc5csyeiy3EELAzs4Orq6d0KdPVWg0+oYC/zto3LgxjIyMcObMq+TgpUsDJ08CXboAkyYBN28Cu3cDY8bIKEMASEhIgKenJ1xcXDJoWWJpaYn58+djwYIFGDhwIMzMzPLydBSKfINSUG8JHx8fAICjo6Ne5SdNmgQbGxu4urpCp3t9jkxavL29MXr0aHz44Ye4eXM0FiwARo4ETp8GypfPsrrCACwtLVG/fn2cPn061fZChYDt24FVq4Bz52Sob0quXLmCyMhING/e/A1Kq1AUHJSCekt4e3ujUKFCsLOz06u8lZUVZs+eDU9PT2zevDnTsnFxcejXrx/Mzc2xZs06/PGHBgMHAosWAaamuSG9Ii3NmzfHhQsXEBubeoFajQb44gs5fystSSMupaAUivRRCuot4ePjgypVqhiUIWLAgAFo1KgRxo4di/Dw8AzLubm5wcvLC6tWrUJwsB1CQ4FWrXJDakVGuLi4ICYmBl5eXnrXOX36NBwcHGBvb5+HkikUBReloN4S3t7eSEhwxLRpQIKemVg0Gg0WL16Mp0+fYvr06emWOXnyJGbPno3BgwejS5cuSHKLZOHmUOSQZs3kArkp/VCZQRJnzpzJ0v+kUPyXUQrqLRAXF4f79+/Dx6cqJk0CPvpIpibRh0aNGmHQoEFYsGBBsh8rieDgYPTv3x+VK1fGggULAEifk52d8jvlNTY2NqhateprfqiMuHPnDgIDA5V5T6HIBKWg3gK+vr7QarWIj3fERx8BHh4yf5mHh371Z82aBQsLC3zzzTfJ20hi2LBhePLkCTZv3gxLS0uQUkG5uLyKHFPkHS4uLjh79qxeQSxJIy01glIoMkYpqLdAUog5UBWjRsmEp+bmQIsWMpCBWSTQtrW1xeTJk3HgwAHs27cPALBx40Zs27YNU6ZMwbvvvgtAJgMNCFDmvTdF8+bNERwcjNu3b2dZ9syZMyhRogSqVav2BiRTKAomSkG9BV6Z5qqicmWZRfriRaBdO2DUKKBPH5lNODNGjBiBatWqYfTo0bh9+zZGjBgBFxcXjBs3LrlMkjtEWZHeDEmjIX3MfKdPn0bz5s0h1NBWocgQpaDeAt7e3ihc2AYajXWyb8jaWk7knD1bzp1p1AjI7EXc1NQUCxcuxL1799CkSRNoNBps3LgRRkZGyWVOnwasrOQyFYq8p2LFiihVqlSWgRJPnz7F3bt3lf9JocgCpaDeAj4+PihUyBHlyqWel6TRAOPGAceOAS9eAO++C2zblnE7bdq0QadOnRAWFoZffvkF5dNEQpw5AzRrpv/6RIqcIYSAi4tLliMoNf9JodAP1XW9BaQPSpr30uODD+RCcHXqAL16ARcuFMuwrXXr1uHQoUPo06dPqu0vXsgF/5T/6c3SvHlzPHz4EA8fPsywzJkzZ2BhYYH69evr3W50fDSexjzNDREVigKDUlBvmJCQEAQGBiIy0jHT1S3t7AB3d6B4ceDo0VIZlrO2tsZHH3302vazZ+XfgvaSHhEXgYXnFiI05s0uDZ9bJPmhMjPznT59Go0bN4apAWk9XA+64tMLn+L3G79nW7bTfqdR+5faOPHgRLbbUCjeJEpBvWGSAiSioqpmufyyqanM3+bpWQJxcYYd5/RpwMxMmgkLEt8e/hajD4/GuGPjsi6cD6lVqxaKFCmSoYIKDw/HlStXDAovD48Nx283foMGGvTZ2QcrLq4wWK4dt3ag9cbWuB54HSMPjoRWpzW4DYXiTaMU1BvmVQSfY4YmvpR06wZERhrj+HHDjnPmjFROBSnx9T6fffj10q8oW7QsVnqthNdj/dMG5ReMjY3RtGnTDP1Qnp6e0Ol0Bvmftt3chqj4KMyuNRvtqrTDsP3DMPvMbL3rLz6/GD2390T90vWxosMK3Ai8gXVX1uldX1+ehD/Bzls78d2R7/D+uvcx8/ZMrL60Gvde3ktaxFSRD4jXxmPTtU2YcWoGnkU8y1FbwdHBSNDpmQonGygF9Ybx9vaGRmMEoGKWIygA+PBDoHDhBOzcqf8xoqJk2HpB8j89j3yOwXsGo7ZtbXgN9YJNYRuMODgCOmY96TW/4eLighs3biA4OPi1fWfOnIFGo0HTpk31bm/tlbVwLOGIetb1sLvXbvRx6oMJxydg3NFxmXb8Ouow/th4uB5yxSeOn+DYgGMYUn8Imtg3waQTkxAZF5mt8wNkJ+f12AtLLixB35194fCzA8rML4Pu27tjyYUliIqPwt/Bf2Pw3sGovLgyyv1cDv1391cK6y0SGhOKuR5zUXFRRfTf3R8/uP+AiosqYtzRcQiKCjKoLe8gb3y9/2vYL7DH7tu780hiwDjPWlaki4+PD4oVq4AXL0xRsWLW5c3MgCZNXuCPP2yxfDlgrMcvduGCzO9XUPxPJDFs/zAExwTjSP8jKFm4JH5q/RMG/jEQG65uwGd1P3vbIhpE0ujIw8MD7dMsvHXmzBnUrVsXRYoU0astnxc+OOt/Fj9++CNEvICJkQk2dd0Ea3Nr/OTxE15Gv8TyDsthpDFKVS9OG4cv9nyBTdc2YViDYVjSbklymbmt56L52uZYcG4BfnjvB4PPb/yx8Vh8YTGi4qMAAGWKlIFzWWeMajwKzmWdUbdUXZgZm8Hd3R22TrY4+eAkTvidwJF7R7Dp2iYAgH1Re7Qo3wLNyjZDs3LNULNkzdfOISNI4mHoQ3j4e+Di44toU6kNPqr8uh9WIfEP9cei84uwwmsFwuPC0bJCS6zssBIVi1XE9NPTMcdjDpZdXAbXRq4Y4zwGxS2Kp9sOSRy/fxwLzi3AgTsHYGpkin61+sHJJg/nsaS3imF+/hT0FXXr1KnDsmXb09ZW/zpubtcJkMeP61d+6lS5emsGq4jnKdm5tuuvrCfcwB/P/Ji8TavT0nm1M23m2DA4Ou9OJC/uhcjISJqYmHDcuHGptsfGxtLCwoKjRo3Su63xR8fTaIoRH4c9TiWrTqfjxOMTCTewx7YejIl/tcpuWEwYW29oTbiB009Op073+grHXbZ2oeVMSz4Nf2rQuW28upFwA7v93o1brm+hX4hfuu2Tr19bnU7HW4G3+Mvfv7DX9l4sNbcU4QbCDSwyswhbb2jNye6TefjuYYZEhyTXi02I5flH57nAcwF7bOvBMvPKJNcTboKaKRquuLjCoPPIStb8jj7yXn5ymZ/u+pTGU41pNMWIfXf2pddjr9fK3Qq8xV7be1G4CRadVZST/pqU6pmLiovir16/subSmoQbaDPHhm7ubnrfOzlZUVeNoN4gOp0OPj4+KF68pV7+pyQaNXoJCwtg1y6gZcusy585I9cfsrbOvqxvioehDzHy4Ei4lHPBmKZjkrdrhAZL2i5Bg5UN4HbCDT9//PNblNIwChUqhAYNGiQHSmy9sRWN7Roj0CcQ0dHRevuftDotNlzbgI8rf4zSRUrDG97J+4QQmN5yOoqZF8N3R79DaGwodvXchfC4cLTb3A7Xnl3D2k5rMxx9zmo1C3u892DKySlY1n6ZXvL4vPDBsH3D4FLOBVu7b4WxxrDuQwiB6iWro3rJ6hjWcBhI4kHIA3j4e8jPIw9MOzUNOuogIOBk4wQrcytcfHwRMQkxAIDyVuXxvsP7cLZ3hnNZZ1QqXgm9d/TGl/u+xLOIZ/jhvR8Mzs6x32c/Vt5ZiTtF7sC5rDOql6wOjch974eHvwc2XduEGiVrwLmsM2rb1jb4GurDree3MPrQaBz1PQpLU0uMbDQSo5uMRjmrcumWr16yOrZ234qJLhMx5eQUTD01FYsuLMK3Tb5FnDYOy72WIygqCHVs62Bdp3Xo7dQbZsZvxrmtFNQbJCAgANHR0VmGmKfFwkKHtm2lglq0KPOJtwkJMunswIE5lzev0VGHz/74DDrqsL7z+tdMPPVK18OXDb7EkgtL8EW9L1DLNp1V//IpLi4uWLhwIQ7cPoA+O/ugsV1jdAvuBkD/CbpH7h3B4/DHWNx2cYZlxjiPQTGLYhiydwhabWiFZ5HP8DzyOfb22Yu2VdpmWM/xHUd82eBLrPBagVGNR8HxncxXdo5JiEHP7T1hbmyO37r9lisdqxACFYpVQIViFdCvdj8AQFhsGC4EXICHvwfO+p9FeGw4vmr4FZzLOqOpfVPYFX19gc8/e/+JL/Z8gUknJuFZ5DMs/HihXubC0JhQfHP4G6y9shYmwgR79u0BAFiZWaFp2aZwtndGs3LN0MiuESxNLbN9njEJMZjsPhlzPefCWGOMOK0MyS1kUgiN7RrDuawzmpVthib2TVDMIuM5j1mh1Wml2favH1DErAh+/PBHDG0wFNbm+r2p1rKthR09d+DK0ytwO+GGSScmQUDgE8dPMLrJaLQo3+KNp+ZSCuoNkpQkNiQk6xDztHTrJhXUuXOAs3PG5a5dk3n8CoL/aeG5hXB/4I5VHVehQrEK6ZaZ3nI6tt3ahpEHR8J9oHuByV3XvHlzzJkzB1+v/Brm75jjfMB56E7pULlyZZQqlfG8tpSsubIG7xR6Bx2qdsi03Of1PoeVmRX67uoLKzMruA90x7t2Wc8vmPz+ZGy4tgHjj4/H7l6ZO7q/O/Idrj67in199sG+aN4tsFjUrCg+rPghPqz4od51TIxMsK7zOtgWtsVcz7l4HvUcGzpvyPQt/7jvcXy+53M8CnuEiS4T8R7eQ4U6FVKN5iafmAyC0AgN6tjWQceqHfH1u1/D1tJWb9kuPbmEAbsH4ObzmxhafyjmtpmL4JjgV8fx98DsM7OhpQz7r1GyBj6q9BFcG7vCwdpB7+Pce3kPn/35Gc48PIPO1TpjRYcVsClso3f9lNQtVRd/9P4Dt5/fhrmxeYbP5hshPbtffv4UZB/U0qVLCYBAADdv1r+eu7s7Q0NJU1Py228zL/vzzyRA+vvnTNbsou+1vfHsBs2mmbHjbx0z9GEksfzv5YQbuOX6Fr3luBl4k34hflmWy6t7ISgoSP7WLcE/bv/B6ourU1NYwwEDB+hXPzKIptNMOergK39VVrLeDLzJx2GPDZJz2slphBt46sGpDMvsuLmDcAO/PZTFzZeGt/GczTk7h3ADW65vydCY0Nf2R8ZFcsT+EYQbWHVxVZ7zP0cyfVmDo4N56M4hTvprEj9Y9wGFm6DZNDMO2TOEt5/fzlSOuIQ4TjkxhcZTjVl6bmke8DmQYdmI2Ai633fnjFMz2HZTW5pMNaFmioa9tvfi3wF/p1snSV6dTsdlF5ax0IxCtJplxQ1XNmT5PL1pcuKDeusKx9BPQVZQrq6utLCwJKDjuXP610uSt107snx5MrP7r3t30sEhR2LmCH2ubWxCLOstr8eSP5XUy9GaoE1g/RX1WWZeGYbHhmdaNjQmlCMPjKRwE7SdY8t7L+/lWN7s8CT8CTU2GpasU5IkuWT/EgLggP/pp6AWnVtEuIFXnlxJ3pYnAR1xkSwzrwwb/9o43Y7N96UvrWZZ8d2V7zI2Idagtt/Wc7b+ynoaTTFi/RX1U91fHg89WGVRFcINHH1wNCPjIpP36SOrd5A3h+0dRvPp5oQb2PG3jjz54ORr1+1m4E02XNmQcAP77ezHF1EvDJL/Uegjjj0ylkVnFSXcwBZrW3Cf9z5qddpU8j4MeZgcDNNmYxv6h+byW2lICBkWluNmcqKg1DyoN4iPjw9KlKgKQGRq4iMJr8de+O7Id2iwsgHuRtwFIM18fn7A5csZ1Xu1QGF+ZsqJKbj89DJWdlypl7nESGOEJW2X4HH4Y0w/lf5S9ySx6/YuVF9aHUsuLMHn9T5HvC4eH236CM8jn+f2KWTJuGPjgHJAzP0YaLVamDwyAQAcjDuo1/yjNVfWoH7p+qhTqk6eylnIpBCmfTAN5wPOY8etHan2xWnj0HtnbwDA791/h6mR/qmZ3iYD6gzAnj57cPv5bTRb0wy3n9/GhGMT0Hxtc8Rp4+A+0B0LPl6AQiaFDGq3aomq+KXDL3g4+iEmt5gMz0eeaLGuBRqvaoztN7cjThuHeR7zUH9FfTwIeYDtPbZjU9dNGYZtZ4RdUTv82PpH+H/jj3lt5sE32BcdtnSA0zInrL60GjEJMTj89DBq/VILHv4e+KX9LzjU71DumJ2mfAMAACAASURBVF51OuDoUZkEtGRJmWuteXPAzU1GX8XH5/wYhpCe1srPn4I8gqpQoQKrVOlNK6v0R0E3A2/yf3/9L/ktz2SqCY2nGrPzys4kyaAg0siI/P779Nu/c0eOiVfkLOI2R2R1bc8+PEvNFA0H/THI4LY/++Mzmkw14T/P/0m13S/Ejx1/60i4gXV+qcPzj84nH8t8ujnfXfluhiOvvLgXzj48K9+wx3ckAF65coX9+/dnsXeKEZPBGadmZFr/8pPLhBu4+PziPJeVlCNUp2VOrLSwUqpR0neHvyPcwO03t2er3bcduu3p78niPxZPDkkf/OdghsWkPyLIjqyRcZH85e9fWHlRZcINtJxpSbiBnbZ0Mjh8PzPiEuK4+dpm1l1eN9Vxmq9pzrsv7ubOQfz95fwUBwfZiRQvTo4aJTubRo1IjUZut7Qk27cnFywgr1/P3JyTiDLxGcjbeHBiYmIohGClSpNZv/6r7b4vfTnr9CzW/qU24QZqpmjYan0rrvJaxRdRL9jt924sMbNE8vC+VSvS0TH9+2LNGvmL3rr1hk4qHTK7tnEJcay6uCodfnZI1z+QFU/Dn7LorKJss7ENdTod47XxnOcxj4VnFGahGYU49+xcxmvjU9X5858/qZmiYdtNbRmXEGeQvNkhyRxpN8+ON7xvEACXLFnCChUqsGvXrvxkyycsOqson0c+z7AN1wOuNJ1m+pppKC/v2wM+Bwg3cOG5hSTJ/T77CTfwq31fZbvNt62gSDnHp9OWTtzvsz/TcjmRNUGbwN23d7Pn9p5cf2V9nvmAdDodj/seZ9+dfTl843AmaBNy1mBcHLl7t1Q4SQroww/JrVvJmJjUZV++JHftIr/+mqxaVZYFSFtbcnvmLzBKQRnI23hwbtyQnZWt7Wb26CG3Ddg9IPntznm1MxedW8Qn4U9S1fvt2m+EG3jG7wxJctky+avduPH6MT7/nCxRQq+Xmjwjs2u74uIKwg3c67032+3/7Plz8gTUpDfK9pvb80HwgwzrrLy4knADB+4e+Frnkdv3QtI5brm+hTqdjvb29mzevDkBcMGCBbzx7AY1UzT85tA36daPiY9h8R+Ls+f2nq/ty8v7VqfTseX6lizxYwneeHaDJX4swdq/1GZ0fHS228wPCipDdDrSx4dct44cOpQv69YlW7TI/NOnD7l4MenlRcbHZ9z2GyBH1/bZM3LyZLJUKdmZlClDTpxI3svcX5sKPz/5Rty3L7NyqKuJugWApCSxQUEySSxJ7Ly1E+2qtMPSdkszDCltX7U9TIQJdtzagWblmqFzZ2D4cGDnTqBmzdRlT5+W5uL8GIkdkxCDaaemoal9U7Sv0j7rChkwvNFwrLq8Cj+4/4DSlqWxo8cOdK3eNdPw8yENhuBx+GO4nXRDmSJlMLPVzGwfPzNeRr/E98e/R4vyLdCrZi8IIdC8eXNs3boVgAw9r2lTE5/V+QxL/16abijxXp+9eBn9Ep/X/TxPZMwIIQTmtJ6DBisbwGV5I8QZC2zrvg3mxuZvVI48Izoa8PKS69B4eMhPUGL+OWtraOyz8N+QwKlTwJYt8nvhwnLZ62bN5LyPJk2AYtmfw/RG8PEB5s8H1q8HYmKADh2AL78EPv5YvxxqKSlXDhg0SH7ykvS0Vn7+FNQR1KxZsxJDzEO5apUMI4Yb+LPnz1nWdV7szLLzyya//TdrRtapk7rMkyfyZWjOnLyQXn8yurZJI5/jvnrma8qE68+uc/rJ6anS4WSFTqfj0D1DX/Pt5Oa9MHz/cGqmaHj16dXkbUlTCwoXLsz4xLfuhyEPaT7dnP139X+tjXab29F+vn265ps8v299fXmlXhkSYIhDaXLQIHLlSjlc12qzrp+GfDGCOntWPjAmJq/MUlWqkJ99lurc9JJVp5Mjhy1byJEjyfr1pVM4qd0aNcgNG7JvwoiJkSObQYPIv9MPL09C72ur05FnzpCdOsn8Z2Zm5NCh5D//ZF03l1AmPgP566+/ctyGoQwaNIjFi5cmQLq7kxcDLhJu4O7bu7OsO37LeMINyc7/+fPlL3c3hX90xw65zZDwdX3R6XS88OgCl/+9PF0/TkrSuxkjYiNoM8eGLde3zH3hDCBeG89PtnxC4SaSHf8ZPTwBYQHcfXs3l11YppfD+8qTK9RM0XDE/hGptl+9epUA+OGHH6baPvbIWAo3kSqM/FHoI2qmaPj9sfSjYDJ90HU6cv9+8q+/DO8g4+PJuXPJQoWos7Sk36BuZMeO0l6c1PlaWZEffUS6uZFHjpAREVk2+1YVVHQ0OXas9K2UK0eOG0f++ScZGJhu8WzLGh4ur/n06WTDhvJade4szWiGcOkS6eQk6xcuLP+2aEHu3Zvuy0GW8iYkyE6hSRPZVokS5KRJhsuVCygFZQDff/8927Ztm6M2soOzszOrVGlBgHz4kNx5ayfhBl56fCnLunuO7KHxVGOOPTKWJPnggfzlfnyVW5WjRpEWFmSsYVNVMsUvxI8zTs1gtSXVkn1lk/6alGmd9G7GmadmEm6gp79n7gmXTSLjIum82pmm00x54v4JOQk6JpR/+f7FWadnscvWLrSbZ5d8vknRlP129kue1JkWnU5HlzUufOend/gy6mWqfVqtlrVq1eLy5ctTbX8Z9ZLWs63ZdtOre3HW6VmEG3jnxZ10j5Phg+7lJUcJScqkdm3pW0nr6E6PixfJevVkvY4d5c356sRS+WlYq5Z8CwfI0qWlQsyEDOXV6eQoxNmZbNAg80+XLvKNzhCl6+VF1qwp5RwyRK+5PLmiTBMSpKI3MyPfeYfcuTPrOnFxMnrO2PjVNQ0NJefNI8uWledQrRr5669S6WYkr04nfUgbN5JffUVWqCDrVqpELl1KRkbybaEUlAF8//33BMB9+/blqB1DKVGiBGvXHkozM/lCNM9jHuGG1zq09HB3d+fHmz5mxYUVk818DRrI6M8kGjQgP/gg53KGxYRx7eW1yTPn4Qa6rHHhr16/st/OftRM0SQHbGQka0qCo4NpPduaHX7rkHPhcokXUS9YfUl1Fp1VlOV/Kp98nnADKy+qzL47+/Jnz5/p6e/J68+u0/WAK4vMLEK4ge+ufJfrr6xPFTyw+dpmwg1ceXGlQXL8dOYnwg38y/cv6nQ6Vl1clS5rXDIs/9qDHhgoO2AhZIe4cqV0XCe9iZcqJd/sg4Jebyw8XKYl0Whkue3b9VMCISGyE01SAJ9/LrfpIy8p367atpV1a9aUEWQZfdq1I21sZNkGDaRSyyw4IS6OnDIldWevJ7k62rtxQ8oLkP36yQi49Lh589Woq29f8kWaCb1xceTmzWTdukyOmEv8PU8ePizNl3PmSCVua/vqBaVIETna3bFDKs23jFJQBhATE8MKFSqwdOnSfJnRjZPLJKW9cXKay+rV5bakTk+fkFR3d3f+6vUr4QZefnKZJDlzJpNHY2Fhsp/53/+yL+PJByfZb2c/Wky3SO6op56YSt+XvsllQmNCWeHnCpmGiae9GX84/kMqufMLfiF+bLm+JZssasIpJ6bw4J2DDIpMpyNPJCwmjEvOL0keTZb8qSS/P/Y9bz+/zTLzyrDBigYGh/1GxUXRfr493135Lk/7nSbcwDWX1mRYPvnaxsXJnFZWVrIzHj069doqOh15+LDspAA5tP7qK9LbW+4/cECmJAHIL7/M3rosMTHkhAnyxitbljx6NGN5SdlRLlggzVeFC0v59ek8o6Ol4nV0lPKWLy/bSTsqyqqzz4JcN0emVJZlypAHD77al5AgR0hmZtL0lkWYNnU6udZOkmK3sKA2pU+tUiWyf39y+XLy2rV8oZRSohSUAUTHR3Pawmk0MjLigAH6pZ3JKR4eHgTA8uX3skPiQOKTLZ+w1rJaetV3d3fn88jnNJpixInHJ5KUfQ1ALlwoXQKA/Jsdjtw9QuEmWGx2MQ7bO4weDz0yVJweDz1oNMUoXQd/kqxJBEYE0nKmZboh0/kFQzsmnU7Ho/eOstOWTtRM0SSPvLJrvlxzaQ3hBlZZVIWFZxTONJWTu7u7VAQ1asgfvHVr2TFnxvXr5BdfyESOwKu38erVydOnsyVzKs6de6U8vvpKjsxSykuSV66Q774ry7RrJ0dRhqLVknv2kC4ush1ra3L8eDnBNMmspk9nnwF55i+7ePHVaHPoUHktks7hk0/IpwZO6L1+nRwxgn69esk5TIbWfwvkWwUF4GMA3gDuAhifzv5yANwBXAZwDUC7rNrMqYL6YN0HrDK3CidOnEgA3LNnT47a04d169YRAC0sfDh6tNxW55c6epu9kn7glutb0nGxY7LycHIi33tPjpw0muylzXoa/pS2c2xZY2kNRsRm7fgmycnukwk3cOv1rRnKSpLfHvqWmimaLBNrvk1y0jHdD77P8UfHc+7ZudluI0GbkLwQXIbZNSIiSHd3BiZ1bBUrkn/8YZhf5ulTGSHm5CQDHfTxT+lLVJQ0FwohZTt5kiR58tAhqUSMjcmSJcnffsudSXrnzpE9eryaXJrdzj4FeRrQkRSwkeS/K1qUXL8+R9ciX0RI6km+VFAAjADcA1ARgCmAqwBqpCmzEsBXif/XAPAgq3ZzqqDme8wn3MAbATfo5OT0Rkx9EyZMoLGxMYE4Lk6McLaebf1axFdGJP3Ayy4sk7I/k7N0J0+W97yTkzR5G4pWp2WbjW1oPt2c159d17tevDaeTVY1ofVs69cyhifJ+ij0Ec2mmXHg7oGGC/YGyQ8P+gGfAzSeaiyDMLRaGQK8bh05bJgc8SR2xAnm5uSMGamc5fmKU6ekuUkIcvBgRtrZyS5m0CCDTW56ce+enGCaC4rvjdwHZ87I8PSUgSjZJD/ct/qSEwWVl8liGwG4S9KXZByArQA6pSlDAEUT/7cC8DgP5QEA9KzZEwICu+/uxrp16xAYGIhRo0bl6TF9fHxQpkwlACaoVEkulBYSE4Ly1uUNaqdL9S4QENh5eycAoGtX+fp440b21n+a6zEXR+4dwcKPF8LJxknvesYaY2zqsgkJugQM2D0AWp32tTIzTs+AjjpMbjHZcMH+Y7Qt3wqRRpPReIgb8M47QLVqwGefAb/9JhN2TpwI7N8Pz23bgO+/B8zz6eRZFxfg6lU5k3zVKggSOH4cWLNGJh3NbSpWBKZPB/r0yZ+z09PSrJlccbRs2bctSYEhLzNJ2AHwT/H9EYDGacq4ATgihBgJoDCAdFcpE0IMBTAUAGxtbXHixIkcCVbDsgZWn1+N5u82R9++fbFx40ZUq1YNzpmtBJgDLl26BFNTBwDAixfnsePYDQBARECEXucSEfGqnFNRJ6z/ez3e43sgATu7RggIKIRixW7gxIkgvWW6FXYL31/5Hi1KtkCVsCrZuqbDKwzHj94/4utNX6NPuT7Jsm45uAUrvVaifen28LvqBz/4Gdx2jiH16rRSXtu3hd2uXaiyeDEiHRwQ6uyMsOrVEVajBqLKl0+1fHJ+kFUvunWDRePGeGFhgUIaDVAAZC4w1zaRgiRvjmRNb1iVGx8A3QGsSvG9P4Alacp8C2BM4v9NAdwCoMms3dyYqDtq0yjCDbz+7DpjY2NZu3ZtlipVii/ywAyh1WppZmbGpk2/o0Yj5yn9+c+fhBt44dEFvdpIOUROysjgHSQjspICqZ48yaByOgRHB9PhZwc6/OzA4OhsRHAlotPp2GNbD5pMNeHFgIvJsg7cPZDm080ZEBaQ7bYNFCRxctlOOSGzZUvpRO/aVUZTZUKm5of4+KyDEHKKViuTbzZunGXRgmTWIQuWvAVJVrJgyZtfTXwBAFKOZe0Tt6XkCwDbAICkJwBzAO/koUwAgBYlW0AjNNh6YytMTU2xbt06BAUF5Ymp7+HDh4iNjUVCQlWUKweYmgJ+IXJEYaiJDwC6Vu8KANh5S5r5Jk6UacX0XEUcJDF071D4h/pjS7ctsDa3NliGJIQQWN5hOWwK26Dfrn6Iio+CX6QfNl7biOHvDkeZImWy3XamxMUBhw8D06YBn3wClC4tc4N16wbMmweEhgKtWwO7dslcY/IFyDASEoDevWXCw27dgMd5ZH0+flzmSBsxIm/aVygKMHmpoP4GUEUIUUEIYQqgN4A9aco8BNAKAIQQ1SEVVJ6vLlfMtBhaVWiFrTe2giTq1auH77//Hps2bcKePWlFzBlJSWLDw2WSWAB4EPIAFsYWKFmopMHtlbUqi8Z2jZP9UIULA43TGk4z4ddLv2L7re2Y0XIGmtg3Mfj4aSluURwbumyAzwsfjDk8Bmv91qKQSSGMazYux22ny4MHQNOmMsHl5MnAnTvARx8BixcD584B4eHAxYvAtm3A//4HrF0r/RSGoNMBQ4bIjLzduwMHDgDVqwPLl8t9ucmSJdLP1KNH7rarUPwLyDMFRTIBwAgAhwHcBrCN5E0hxFQhxCeJxcYAGCKEuApgC4DPEod7eU5vp964F3wPXk+8AAATJ05EnTp18OWXX+Lly5e5dhxvb28AwLNnVZNX0fUL9UN56/KZZuDOjG7Vu8HriRfuB983qN7NwJsYdWgUWldsjf9r9n/ZOnZ6tKzQEt85f4flXstx8vlJjG48GiULG658s+TwYaBBA+DePRlAEBIC3L4tszOPGCE1dcoAgilTgP79gUmTgA0b9DsGCYweDaxbJ1cR3b4duH4daNgQ+OoroEULeczc4MEDYN8+YOhQwMwsd9pUKP5F5OmS7yQPkKxKshLJGYnbJpHck/j/LZLNSNYhWZfkkbyUJyVdqnWBicYEW2/IpRBSmvpcXV1z7Tje3t4oUqQogoNtkxXUg5AHGS6vkYqYGODAAYg0yyx3q9ENALDr9i695YiKj0KvHb1gZWaFjV02QiNy96ef9sE01C1VF0WNi2KM85hcbRs6nRwFtW0L2NvLEVKfPkDRopnXEwJYtQpo2RL44gvgr7+yPtakSXI09s038n8AqFwZOHZMjsZu3QLq1JHKKzY2Z+e1fLmU8csvc9aOQvEvJU8VVH6mmEUxfFz5Y/x+83foKM02devWxcSJE7F58+ZcM/X5+PigbNmqAETqEZRVJv6n6Ghg4UIZRtu+PRzWrUu1u2KxiqhXql6ymU8fvjn0DW4+v4mNXTbC1tLW8BPJAjNjM5z67BRWNVyVsV8rIgKoV0+unbNhg1TAWRESAnTqJM11/foBnp5ItpXqg6mpNNU5Osq4/Bs3Mi77009SEQ4eLH1ZKUe4QsjQ79u3pdlvyhSgbl3gzBn9ZUlJdLRUnp07q7BjhSID/rMKCgB61eyFR2GP4Onvmbzt+++/h5OTE1xdXREVFZXjY3h7e6N4cUcAsl+NjItEUFRQ+iOoyEi5oFiFCtLM5OgIfPQRym7fDtxPbc7rXqM7PB954lHYoyxl2L91Gl5uXInp1YajdaXWOT6njChiVgQlzTIx7f3f/8l5Mi9fAgMHytHQ//2fNNmlx7Vr0rR26JD01WzYABQqZLhg1tbSj1SoENCuXfoBD8uXA+PGAb16vRrZpIeNjTQvHjgglYyLi5ybZCi//w68eKGCIxSKTPhPK6hPHD+BubF5spkPkKa+pUuXws/PD7Nnz85R+9HR0Xj48CHMzKoCkAMiv9DECL6UI6iICPn2XqECMGYM4OQEnDwJuLsDq1eDRkayI09Bt+rSzLf79u4Mjx8QFoAvf+2EpoMmYft2YGLvpUClSnIksGoV4O2dvQi37HDkiOz4v/1WHvevv4APPgAWLJCau21bYO9eQJs46XfTJjnSio6W12L48JxNxixXDti/XyrHDh3kNU9i0ybg66+B9u2BjRsBI6Os22vbVo7GPvsMmDVL+pL0hZRmxJo1pU9LoVCkT3qx5/n5k9sr6nbf1p02c2wYr02dxr9v3740MzPj3ZSrAhpI0mJ177+/lba2ctsBnwOEG3j24VmZPG/mzFcLw7VpI9OhpMF30CC5/8SJVNudljnxvbXvvVY+LiGOc8/OpeWMwtxdXcN4EyPG7PhdrnTYpYvMi5aUw6xkSblt/ny5jk4OMyGnO+chOJi0t5fr2kRFpd4XECCzPpeRK7myXDkpT9KCbbmdDHP/frkKatu2ZHw8r02bJr+///7rsulDTIxcJ6lUKf3T+Xh6yvNbtsygQxWkuS9kwZK3IMlKFix582Uuvrz65LaC2nFzB+EGHrt3LFWZgIAAWlpasmPHjtk+zvbt2wmA9etfYrNmcltSPr2AsIBXi8y1ayc7rQw4eeiQ7Ljr1EmlQCa7T6ZwE6lWfD1x/0Ry8tGZrokL0aVc2ZCUE1v/+UcugjZggEzwmXLl1I4dpcK6dMlghZXuzThwoFQC589nXDEuTk60bdVKlh0zJvO1f3LCihXyXNu2lcsWNGqUvUy7SVy+LBOi9u2rX/l+/WTC0PCMM5enR0HqlMiCJW9BkpUsWPLm14m6BYJ2VdrB0tQylZkPAMqUKYNJkyZh79692L9/f7baTgoxf/o0dYi5qZEpShlZyRm248dL01OTjOck6czMpAnw6lUZSZZI9xrdQRC7/9mNpxFP0X93f7y//n1ExEXgQOv1GL/lkfThfPtt6gaFkP6twYNliPa9e8CjR8DmzUDPnsA//8g69evLOTqdOwM//wzcvGn4RdizRx5jwgSgUaOMy5mYyCCGY8dkdNzcuYBxHmXiGjpUXveDBxFVtixw8CBQpEj226tbVwZx/PabnBycGc+eyTlan30GWFpm/5gKxX+A/7yCsjCxQOdqnbHz9k7EaeNS7Rs1ahSqVauGUaNGIUafiLM0+Pj4wM7OHo8fF04VYl7Oqhw0/yT6fxo00K+xnj1lRtiJE4GwMABAzZI1UbVEVfx09ic4LnHEtpvbMNFlIm4Nv4W2Sw5BhIRIhaZPR29nB/TtC6xcKTMb+PtL30y3blIxffON9I1NnPjKT5QVQUFSGdSpIztwfdHHB5RTZswAfv8dV+fNy51EphMmSIU+bBjwPJO55r/+CsTHS5+XQqHIlP+8ggKA3jV7IzgmGEfvHU213dTUFIsWLcK9e/cwb948g9v19vaGvb0MkEiKjE4OMU8Kd3bSM4u4EHIU8/x5cmYEIQR61uiJ+yH30diuMa5/dR3TW05HoQNHgS1bpFLQt/202NvLsO5ff5XZGh4+lNkVZs6U6YVCQrJuY/hwGZSwfr0M985PaDRAz56It85+qqdUmJjI8wwNlconveCT+HgZKNKmjRzBKhSKTFEKCkDrSq1RzLwYtt7c+vq+1q3RrVs3zJgxAw8fPtS7TZKpQsxfm6R744bstA2Z09OggQzP/vln4O5dAMDE9ybi/ODzOPzpYVQtURUIDpYZD+rUkWas3KJsWTm6Wr5cRuQ1bpx5RoXff5emLDc3Kct/AScnOT9qxw55/mn5808gIECFlisUeqIUFABTI1N0rd4Vf/7zJ6Ljo1/bP3/+fADAmDH6Z0gICgpCSEgITE3lCKpSJSAmIQZPI56+GkFVr264n2XmTJkW57vvAADmxuZoZNfoVdqkb78FAgPlGjwmJoa1rQ9ffinD30NCpJJKb0Lz06dyFNGoETB2bO7LkJ/57jt5XYYPl9chJUuWAA4Oci6WQqHIEqWgEunt1BvhceE4ePfga/vKlSuHiRMnYseOHTh27Jhe7SUFSGi1jrCyAkqUAPxD5fJYDtYO0q+THfNb6dJyYuiff8pM2Ck5dEjmkBs/XvpD8ormzWW6IUdHmeVh2rRXSVRJ6XeKipImr7wKdMivGBvL846KktchydR3/bqcz/X112/Gx6ZQ/AtQCiqR9x3eh01hm9ei+ZIYM2YMKlWqhJEjRyIuLi7dMilJymIeFiYj+ISQ5j0AqGj0jvTpZNc/9M03r7JNJCQg8UDSR1S9umEBCdmlbFng1KlXyVi7dwfCw2F7+LCccDtzplwZ9r+Io6MMwti7V078BYBly2Qi288/f7uyKRQFCKWgEjHWGKNHjR7Y57MP4bHhr+03NzfHokWL8M8//2DRokUZthMUFIQ1a9Zg8eLFMDExQUCAQ6oQcwCo+DjRjFizZvaENTcH5syRZsJVq+S2sWNlCp+1a99cZmwLCzla+Plnaepr0gRVliyR6X/yYG2tAsWoUXKk6eoqR8sbNsgoyRIl3rZkCkWBQSmoFPR26o3ohGjs9dmb7v527dqhY8eOmDJlCh6nyOcWEBCAJUuWoGXLlrC1tcUXX3yBkJAQzJgxC35+RqkCJIyEEWzuB8oN2R1BAXLO0HvvydHSrl3AihXS/2TI4lC5gRCyMz58GHj6FEKrlUpS8x+/tYyMpLk1Pl4q7Kgo6ZdSKBR68x/vRVLjXNYZdkXsMjTzAcCCBQsQHx+PESNGYM6cOWjatCns7e0xcuRIPH36FBMmTMClS5fg6+uL7t3HICEhdYi5fVF7GN26LVcaLG/4irrJJIWdv3ghzWtVqgBTp2a/vZzSqhVw4wa8Vqx4FbL4X6dSJTnBOjhYLrKYl35BheJfyH/Mg505GqFBr5q9sPjCYgRHB6OYRbHXylSqVAljx47FtGnTsHv3btSvXx/Tp09H165dUb169VRlEyPB0w8xr1kz56OMevVkNohVq4DVq6XJ7W1SujSiypV7uzLkN776Siqotm3ftiQKRYFDjaDS0NupN+J18ZkuBvjDDz/gt99+w/379+Hl5YWJEye+ppyAV6tIJPugQuRKutmO4EuPpUvlfCQXl9xpT5G7aDTADz/onzFEoVAkoxRUGhqWaYhq71TDLxd/kdl008HU1BR9+vSBg4NDpm3duyfjFezsgHhtPALCA1CDJWU+tuwGSKTFxERlJVAoFP9KlIJKgxACIxuNhNcTL5x7dC5Hbd27J9eA0miAR2GPoKMOtYISL3lujaAUCoXiX4pSUOkwoM4AFDUrikUXMg4n14e7d1P7nwCgUkBiiLlSUAqFQpEpSkGlg6WpJb6o9wV23NqBgLCAbLVBAr6+R0Q/TAAAIABJREFUqSP4AKCU3wugWDGZEUKhUCgUGaIUVAYMf3c4tDotll9cnq36z54BkZGpAyQEBIr4+MnRU06WL1coFIr/AEpBZUCl4pXQoWoHrPBagZgEw9eCei3EPPQByliWhubWLWXeUygUCj1QCioTXBu74nnUc/x+I52lE7IgKcQ82cQX4ocGKC2zgOdWBJ9CoVD8i1ETdTOhVYVWqP5OdSw8vxAD6gxIXtIiIgL48UcgPFxmsklIeP3v7dsyei8pWcSDkAcYGpL4RY2gFAqFIkuUgsoEIQRcG7viq/1fwcPfA83KNQMgV7qYPh0oUkSuOWhiIldZMDZO/f/gwXK/VqeFf5g/aj+vIBtWIyiFQqHIEqWgsqB/7f6YcHwCFl1YlKygLl2SCcVfvtRvuaPH4Y+RoEtApcfRQKlSwDvv5LHUCoVCUfBRPqgsKGxaGIPrDcbOWzvxKOwRAKmgatfWfy2+VCHmyrynUCgUeqEUlB4MbzQcBPHL37+ABC5fNiwx9YOQBxA6oMhdf2XeUygUCj1RCkoPHKwd8InjJ1jhtQK370QjNNQwBeUX4geHEEATFa1GUAqFQqEnSkHpiWsjV7yIfoGlp+RaUfXq6V/XL9QPzcOs5BeloBQKhUIvlILSk/cd3oeTjRN2+i+CkTEN0jMPQh6gSUgR+aVGjbwRUKFQKP5lKAWlJ0IIuDZyxTPNFTi4nIG5uf51/UL9UPu5kJOiihbNOyEVCoXiX4RSUAbQt1Y/iJhiSGiof5ZzHXXwC/FDxScxyrynUCgUBqAUlAGEBhUCLw6Bf+HdeBj6UK86gZGB0MbFwtY/WEXwKRQKhQHkqYISQnwshPAWQtwVQozPoExPIcQtIcRNIcRveSlPTrl8GcDfXwOJIef68CDkASq/BIziE9QISqFQKAwgzxSUEMIIwFIAbQHUANBHCFEjTZkqACYAaEayJoDReSVPbnDpEiDCyqND5c5YeWklouKjsqzjF+IHp8DEL0pBKRQKhd7k5QiqEYC7JH1JxgHYCqBTmjJDACwlGQwAJAORj7l0CahSBRjTfBReRr/E6kurs6zzIOQBnAIBajRAtWpvQEqFQqH4d5CXufjsAPin+P4IQOM0ZaoCgBDiLAAjAG4kD6VtSAgxFMBQALC1tcWJEydyJFhERES22vD0bIKaNUOh9dWitlVtTP1rKhwjHWGqMc2wjscdD3weZIxou9K4cP78G5X3bVCQZAUKlrwFSVagYMlbkGQFCpa8OZKVZJ58AHQHsCrF9/4AlqQpsw/AbgAmACpAKjTrzNpt0KABc4q7u7vBdYKCSID88Uf5/bjvccINXHx+cab12m1uR19bM7JLl2xIKsmOvG+LgiQrWbDkLUiykgVL3oIkK1mw5NVHVgAXmU5/r5eJTwixSwjRXghhiEkwAEDZFN/tE7el5BGAPSTjSd4H4AOgigHHeGNcuSL/JqU4+sDhAzQv1xyzz8xGbEJshvUeP/dFucBY5X9SKBQKA9FX4SwD0BfAHSHEbCGEox51/gZQRQhRQQhhCqA3gD1pyvwB4H0AEEK8A2ny89VTpjfKpUvyb1KKIyEEJreYjIDwAKy+nL4viiTM7zyAEf+/vXuPjqo+9z/+fgyBcAmgUTktwRIV5Md1IiCFgAVUBIGAVQSspUDV4wUVe1RAlh5K0XJEBW+r1KLEKo0oCFKlScUQJFK5CCgiEW8BotzkmggBkjy/P/ZOnIRcJpBh9jDPay1WZu/Zl8/sBXn47v2d7xcrUMYYU0MBFShVXaaqvwEuB3KAZSKySkTGiEh0JfsUAuOAdGAL8IaqbhaRqSKS7G6WDuwTkc+B5cCDqrrv9D5ScKxfDxddBHFxP627KuEqklok8eesP1fYitp3dB+XfF/gLFiBMsaYGgn4lp2IxAGjgVuBDcAzOAXrvcr2UdWlqtpaVS9R1cfcdY+q6hL3tarqH1S1rap2UNXXT+OzBFVFU2yUtKJyD+fy8oaXT9qnpIt5cXQdp/ufMcaYgAX6DGoRsBJoAAxW1WRVna+q9wCNghnQC/LzYevWikcwv/riq+ke373CVlTOwRza7YVjlyY4c8EbY4wJWKAtqGfdVs6fVXWn/xuq2iUIuTzlk09AteI5oESEKb2nsOPwDlI2ppR5b9shpwUV1b7DmQlqjDFnkUALVFsRaVqyICLnishdQcrkOSUdJCqbpPCai6/hl/G/5PGsxzledLx0/c7vt5JwEKI71mDyKGOMMUDgBeo2VT1YsqDOyA+3BSeS96xfDxdeCD/7WcXvlzyL2n5oe9lW1JbPnfc7WAvKGGNqKtACFSUiUrLgjrNX+fAJZ5mSDhI/XYGTXXvJtXRr3o3HV/7Uimr4xbfOm9aDzxhjaizQApUGzBeRq0TkKiDVXXfWO3YMNm+ufor3klbUtkPb+Psnfwfgwm/3cLxeHUhIOANJjTHm7BJogZqA8z2lO90/7wMPBSuUl3z2GRQWVv78yV//S/vT9eddeWzlY/xw5Acu3Xmc/S3/C86xabeMMaamAv2ibrGq/kVVb3T//FVVi4Idzguq6yDhr6RHX87BHP604k+03wMFbS4JbkBjjDlLBfo9qFYissCdWPCbkj/BDucF69dDkyaB36UbcOkAuvy8C/9Y8Rw/z4eoDp2CG9AYY85Sgd57mgv8BSgE+gB/B14LVigv2bDBef5UVQcJfyXPov7fbgUgtnP3IKYzxpizV6AFqr6qvg+Iqm5T1SnAwODF8obCQudLutV1kChvYKuBXHfMGci9SeekICQzxpizX6ATFh5zp9r4UkTG4UybcdYPcfTFF1BQENjzJ3/y44/ct6UJx5oepF58fHDCGWPMWS7QFtR9OOPw3Qt0Bm4BfhesUF5Rkw4SpY4dg6FDqb9pC/VSXg383qAxxpgyqm1BuV/KHa6qDwD5wJigp/KI9euhfn24LJDZr8C5JzhyJLz/PrzyCgwZEtR8xhhzNqu2BeV2J+95BrJ4zoYN0KkTREUFsHFxMdx2GyxaBM88A6NGBT2fMcaczQJ9BrVBRJYAbwI/lqxU1beCksoDioudAvWb3wSwsSo88ACkpMCUKXDvvUFOZ4wxZ79AC1QMsA/o67dOgbO2QH37LRw+HODzp2nTYOZMuO8+ePTRoGczxphIEFCBUtWIee5UoqSDRLVdzJ9/3ilKv/sdPP20dYowxphaElCBEpG5OC2mMlR1bK0n8oj166FOnWoGIn/tNbjnHhg6FObMsTH3jDGmFgV6i+8dv9cxwPXA97Ufxzs2bHCKU716lWywZAmMHg19+0JqqlPNjDHG1JpAb/Et9F8WkVQgKyiJPEDVaUENGlTJBhs2wE03QefOsHgxxMSc0XzGGBMJTvWeVCvgwtoM4iXffw9791bSQUIV7r7bGUF26VKIjT3j+YwxJhIE+gwqj7LPoHbhzBF1Vqqyg8Rrr8F//gNz50Jc3BnNZYwxkSTQW3wR1UxYv97pjNep/EwZeXnw0ENwxRX2RVxjjAmyQOeDul5EmvgtNxWRocGLFVobNjjDGzUqPxzutGmwaxc895z12DPGmCAL9Lfs/6rqoZIFVT0I/G9wIoXe+vUV3N7butX5Mu6YMU4LyhhjTFAFWqAq2u6s7FedkwM7dlRQg+6/3xk59s9/DkUsY4yJOIEWmXUi8jTwgrt8N/BxcCKFVnq687N/f7+V777r9Nh76ilo1iwkuYwxJtIE2oK6BzgOzAdeBwpwitRZJz0dLrrIb4qNY8dg/Hho0wbGjQtpNmOMiSSB9uL7EZgY5Cwhd+IELFvmTOlUOqTerFnw1VdO5apbN6T5jDEmkgTai+89EWnqt3yuiKQHL1ZofPSR05P82mvdFd99B3/6kzPxYL9+Ic1mjDGRJtBbfOe7PfcAUNUDnIUjSaSlOZMTXnWVu2LCBGeW3KefDmkuY4yJRIEWqGIRuahkQURaUsHo5uEuLQ26d3dGMeLDD2HePHjwQbj44lBHM8aYiBNoL77JQJaIrAAE6AXcHrRUIbBnj/P9p2nTgKIiZxqN+HiYeNY/ejPGGE8KtJNEmoh0wSlKG4DFwNFgBjvT/v1v5+e11wIvveQMJ/H669CwYUhzGWNMpAq0k8StwPvA/wAPAK8CUwLYr7+IfCEiX4lIpU0REblBRNQtgiGRng7nnw+XtzsGkyfDlVc6U2oYY4wJiUCfQd0HdAW2qWofIBE4WNUOIhKF88XeAUBbYKSItK1gu1j3+KtrkLtWFRc7BapfPzgnYxn88IMzKKxN326MMSETaIEqUNUCABGpp6rZwGXV7HMF8JWqfqOqx3G+4Dukgu3+BPwfzpd/Q2LjRmf+p/79gQULnF4SV18dqjjGGGMIvJNErvs9qMXAeyJyANhWzT7NgR3+xwC6+W8gIpcDLVT1XRF5sLIDicjtuJ0ymjVrRmZmZoCxK5afn1/mGK+9dhFwMY3qZnJiwQL2de9O9n/+c1rnqE3l83pZOGWF8MobTlkhvPKGU1YIr7ynlVVVa/QH+BWQDNStZrsbgTl+y78FnvdbPgfIBFq6y5lAl+rO37lzZz1dy5cvL7N85ZWqiYmq+q9/qYLqkiWnfY7aVD6vl4VTVtXwyhtOWVXDK284ZVUNr7yBZAXWaQW/72s8qZGqrlDVJerctqvKd0ALv+V4d12JWKA9kCkiOcAvgSVnuqPE4cOwapXf7b3YWLjmmjMZwRhjTAWCOeveWqCViCSISF1gBLCk5E1VPaSq56tqS1VtCXwEJKvquiBmOklGhjNYRP+rTsCiRTB4MMTEnMkIxhhjKhC0AqWqhcA4IB3YAryhqptFZKqIJAfrvDWVluY0mrofy4T9+2HYsFBHMsYYQ5AnHVTVpcDScuserWTb3sHMUvE5nQLVty9Ev73A+VJu6UixxhhjQimYt/g8b+tW2LYNBlxT6NzeGzTImTXXGGNMyEV0gUpLc34mN/3A+SKU3d4zxhjPiOgClZ4OrVvDzz5cAA0awIABoY5kjDHGFbEFqqAAMjOh/zVF8NZbcN11TpEyxhjjCRFboFauhKNHYWSLLNi9227vGWOMx0RsgUpLg7p1ofO3C5zvPV13XagjGWOM8ROxBSo9HX7Vq5joJQud4tSoUagjGWOM8RORBWrPnnps3gxj26yCnTvhxhtDHckYY0w5EVmg1q49F4CrDy2AevWc7z8ZY4zxlAgtUOcR//Ni4pYvcEaJjY0NdSRjjDHlBHWoIy8qLISPPz6XSb1XI+98B9OnhzqSMcZDTpw4QW5uLgUFIZtDtVpNmjRhy5YtoY4REP+sMTExxMfHEx0dHdC+EVeg1qyB/PxobmCB041v8OBQRzLGeEhubi6xsbG0bNkSEQl1nArl5eURGyZ3fkqyqir79u0jNzeXhISEgPaNuFt8aWlwjhRz6cYF0K+fM727Mca4CgoKiIuL82xxClciQlxcXI1aphFXoNasgWEtM4nK3W6994wxFbLiFBw1va4Rd4tv6VL46tcvQW40JHtmWipjjDHlRFwL6hxRWqzOgKuvhnPPDXUcY4wxlYi4AsX69dTftctu7xljPG3x4sWICNnZ2QBs3LiRpUuXVrMXpKSkcMEFF+Dz+WjXrh033ngjR44cqfI8n3/++SllDDTTqYq8ArVgAcVRUTB0aKiTGGNMpVJTU+nZsyepqalAzYrB8OHD2bhxI5s3b6Zu3brMnz+/0m29XKAi7hkUu3ZxoEsX4s47L9RJjDEeN348bNxYu8f0+WDWrKq3yc/PJysri+XLlzN48GAmT57Mo48+ytGjR8nKymL8+PEkJyczduxYvvnmGxo0aMCLL75Ix44dyxynsLCQH3/8kXMreZyxatUqlixZwooVK5g2bRoLFy4E4O6772bv3r00aNCAv/3tb7Rp04Y333yTP/7xj0RFRdGkSROWLVtWJtOkSZMYPnx4rVyjEpFXoObO5bP33+dXoc5hjDGVePvtt+nfvz+tW7cmLi6OTZs2MXXqVNatW8fzzz9PXl4eDz/8MImJiSxevJiMjAxGjRrFRreazp8/n6ysLHbu3Enr1q0ZXMn3PXv06EFycjKDBg3iRvexx1VXXcXs2bNp1aoVq1ev5q677iIjI4OpU6eSnp5O8+bNOXjwIHXr1i2TKRgir0ABGhUV6gjGmDBQXUsnWFJTU7nvvvsAGDFiBKmpqbRv377MNllZWaUtnr59+7Jv3z4OHz4MOLf4nn/+eVSVu+++mxkzZjBx4sRqz5ufn8+qVasY5jc/3rFjxwBISkpi9OjR3HTTTfz617+ulc9ZnYgsUMYY41X79+8nIyODTZs2ISIUFRUhIrRr167GxxIRBg8ezHPPPRdQgSouLqZp06alLTF/s2fPZvXq1bz77rt07tyZjz/+uMZ5airyOkkYY4yHLViwgN/+9rds27aNnJwcduzYQUJCAtu3bycvL690u169ejFv3jwAMjMzOf/882ncuPFJx8vKyuKSSy6p9HyxsbGlx23cuDEJCQm8+eabAKgqn3zyCQBff/013bp1Y+rUqVxwwQXs2LGjzL7BYAXKGGM8JDU1leuvv77MuhtuuIFdu3bx+eef4/P5WLhwIVOmTOHjjz+mY8eOTJw4kVdeeaV0+/nz5+Pz+ejYsSMbNmzgkUceqfR8I0aMYMaMGSQmJvL1118zb948XnrpJTp16kS7du14++23AXjwwQfp0KED7du3p0ePHnTq1Ik+ffqUZqqqp+Cpslt8xhjjIcuXLz9p3b333ltmuWQA1sWLF5+07ejRoxk9enTA50tKSjqpm3laWtpJ27311lsnrTvvvPNYu3ZtwOeqKWtBGWOM8SRrQRljTAR47LHHSp8tlRg2bBiTJ08OUaLqWYEyxpgIMHnyZE8Xo4rYLT5jjDGeZAXKGGOMJ1mBMsYY40lWoIwxxniSFShjjPEgr88HtWTJEqZPn17j/WrCCpQxxniQF+aDKiwsrHS/5OTkgMb3Ox3WzdwYYyoxPm08G3fV7oRQvv/yMat/1cOkh3I+qN///vf4fD6ysrIYOXIkrVu3Ztq0aRw/fpy4uDjmzZtHs2bNSElJKZ1qY/To0TRu3Jh169axa9cunnjiidLpO05HUAuUiPQHngGigDmqOr3c+38AbgUKgb3AWFXdFsxMxhjjdaGcDwrg+PHjrFu3DoADBw7w0UcfISLMmTOHJ554gqeeeuqkY+3cuZOsrCyys7NJTk72doESkSjgBeAaIBdYKyJLVNW/LbkB6KKqR0TkTuAJoHanZDTGmFNUXUsnWEI1H1QJ/5lxc3NzGT58ODt37uT48eMkJCRUuM/QoUM555xzaNu2Lbt3767R561MMJ9BXQF8parfqOpx4HVgiP8GqrpcVUue3n0ExAcxjzHGeF7JfFC33norLVu2ZMaMGbzxxhuoao2PVTIf1AcffFCj/Ro2bFj6+p577mHcuHFs2rSJv/71rxQUFFS4T7169Upfn0rWigTzFl9zYIffci7QrYrtfw/8q6I3ROR24HaAZs2akZmZeVrB8vPzT/sYZ1I45Q2nrBBeecMpK4RXXv+sTZo0CeocR9V57bXXGDFiBM8880zpugEDBvDll1+yf/9+8vLyKCoqolu3brz88stMmDCBlStXct555yEiFBQUcPz48dLPkJGRQYsWLSr9TPXq1WPv3r2l7xcVFfHjjz+WLh84cICmTZuSl5fHnDlzKCoqIi8vr8x5Tpw4wdGjR8ucw/94/usLCgoC/nvhiU4SInIL0AX4VUXvq+qLwIsAXbp00d69e5/W+TIzMzndY5xJ4ZQ3nLJCeOUNp6wQXnn9s27ZsoXY2NiQZVm0aBETJkwok+Gmm25iy5YtfPnll/Tq1Yvx48fz+OOPM3bsWJKSkmjQoAGvvvoqsbGxxMTEsGjRItasWUNxcTHx8fGkpKRU+plGjRrFbbfdxosvvsiCBQuIioqiYcOGpdtPnTqV0aNHc+6559K3b19yc3NLz1O3bl1iY2OJjo6mfv36Zc5R8rpkapASMTExJCYmBnQtglmgvgNa+C3Hu+vKEJGrgcnAr1T1WBDzGGOM54V6PqjyrZshQ4YwZMgQyvM/T0pKSpn38vPzAz5/VYL5DGot0EpEEkSkLjACWOK/gYgkAn8FklV1TxCzGGOMCTNBa0GpaqGIjAPScbqZv6yqm0VkKrBOVZcAM4BGwJsiArBdVZODlckYYyKVzQdVjqouBZaWW/eo3+urg3l+Y4wxDpsPyhhjjKklVqCMMcZ4khUoY4wxnmQFyhhjjCdZgTLGGI+JiorC5/PRqVMnLr/8clatWgVATk4O//jHPwI+zvjx42nevDnFxcVVbpeZmVl6jpqqaaaa8MRIEsYY40njx8PG2p1uA58PZlU9CG39+vVLRyZPT09n0qRJrFixorQYVDY6ub/i4mIWLVpEixYtWLFiBX369Kl028zMTBo1akSPHj1q9ln4qUDdfPPNNd63OtaCMsYYDzt8+HDpfE4TJ05k5cqVJCUlMXPmTAoKChgzZgwdOnQgMTGxzCgUmZmZtGvXjjvvvLN00sOK5OTkMHv2bGbOnInP52PlypXs3buXG264ga5du9K1a1c+/PBDAFasWIHP58Pn85GYmEheXl5pJp/Px8yZM2v1s1sLyhhjKlNNSydYjh49is/no6CggJ07d5KRkQHA9OnTefLJJ0lNTSU2NpannnoKEWHTpk1kZ2fTr18/tm7dSkxMDKmpqYwcOZIhQ4bw8MMPc+LECaKjo086V8uWLbnjjjto1KgRDzzwAAA333wz999/Pz179mT79u1ce+21bNmyhSeffJIXXniBpKQk8vPziYmJKc30zjvv1Pp1sBaUMcZ4TMktvuzsbNLS0hg1alSFU1hkZWVxyy23ANCmTRt+8YtfsHXrVo4fP87SpUsZOnQojRs3plu3bqSnpwd8/mXLljFu3Dh8Ph/JyckcPnyY/Px8kpKS+MMf/sCzzz7LwYMHqVMnuG0ca0EZY4yHde/enR9++IG9e/cGvE96ejoHDx6kQ4cOABw5coT69eszaNCggPYvLi7mo48+IiYmpsz6iRMnMnDgQJYuXUpSUlKNit6psBaUMcZ4WHZ2NkVFRcTFxREbG1tmbqVevXoxb948ALZu3cr27du57LLLSE1NZc6cOeTk5JCTk8O3337Le++9x5EjRyo8R/nj9uvXj+eee650uaTDxtdff02HDh2YMGECXbt2JTs7+6R9a5MVKGOM8ZiSZ1A+n4/hw4fzyiuvEBUVRceOHYmKiqJHjx7MnDmTu+66i+LiYjp06MDw4cNJSUmhqKiItLQ0Bg4cWHq8hg0b0rNnT/75z39WeL7BgwezaNGi0k4Szz77LOvWraNjx460bduW2bNnAzBr1izat29Px44diY6OZsCAAaWZOnXqZJ0kjDHmbFdUVFTh+ujoaDIyMspMAjh37tyTttu/f/9J6956661Kz9e6dWs+/fTTMuvmz59/0nb+rSp/JZ04apu1oIwxxniStaCMMSZCzJ07l2eeeabMuqSkJF544YUQJaqaFShjjIkQY8aMYcyYMaGOETC7xWeMMcaTrEAZY4zxJCtQxhhjPMkKlDHGGE+yAmWMMR4TLvNBrVu3jnvvvbfG+wXKevEZY0wlxo8fXzrMT23x+XzMCqP5oAoLCysdFLZLly506dKl2iynylpQxhjjYaGYD2r06NHccccddOvWjYceeog1a9bQvXt3EhMT6dGjB1988UXpOUoGoJ0yZQpjx46ld+/eXHzxxTz77LOn/dmtBWWMMZWorqUTLKGeD+qll14iNzeXVatWERUVxeHDh1m5ciV16tRh2bJlPPzwwyxcuPCkY2VnZ7N8+XLy8vK47LLLuPPOO0/rOlgLyhhjPCbU80EBDBs2jKioKAAOHTrEsGHDaN++Pffffz+bN2+ucJ+BAwdSr149zj//fC688EJ2795dw09elrWgjDHGw0IxHxQ4I6CXeOSRR+jTpw+LFi0iJyeH3r17V7hPvXr1Sl9HRUVRWFgY8PkqYi0oY4zxsFDMB1XeoUOHaN68OQApKSm19+GqYQXKGGM8JtTzQZX30EMPMWnSJBITE0+7VVQTdovPGGM8JtTzQfXq1avM+927d2fr1q2ly9OmTQOgd+/epbf7pkyZUmafzz77DOC0Ztu1FpQxxhhPshaUMcZECJsPyhhjwpyqIiKhjlHrQj0fVEVd5atit/iMMcZPTEwM+/btq/EvU1M1VWXfvn3ExMQEvI+1oIwxxk98fDy5ubk1+t7RmVZQUFCjX/Sh5J81JiaG+Pj4gPe1AmWMMX6io6NJSEgIdYwqZWZmkpiYGOoYATmdrEG9xSci/UXkCxH5SkQmVvB+PRGZ776/WkRaBjOPMcaY8BG0AiUiUcALwACgLTBSRNqW2+z3wAFVvRSYCfxfsPIYY4wJL8FsQV0BfKWq36jqceB1YEi5bYYAr7ivFwBXydnYdcYYY0yNBfMZVHNgh99yLtCtsm1UtVBEDgFxwA/+G4nI7cDt7mK+iHxxmtnOL38OjwunvOGUFcIrbzhlhfDKG05ZIbzyBpL1FxWtDItOEqr6IvBibR1PRNapavCmgaxl4ZQ3nLJCeOUNp6wQXnnDKSuEV97TyRrMW3zfAS38luPddRVuIyJ1gCbAviBmMsYYEyaCWaDWAq1EJEFE6gIjgCXltlkC/M59fSOQofbtOGOMMQTxFp/7TGkckA5EAS+r6mYRmQqsU9UlwEvAqyLyFbAfp4idCbV2u/AMCae84ZQVwitvOGWF8MobTlkhvPKeclaxBosxxhgvsrH4jDHGeJIVKGOMMZ4UcQWquuGXvEREckRkk4hsFJF1oc5Tnoi8LCJ7ROQzv3Xnich7IvKl+/PcUGYsUUnWKSLynXt9N4rIdaHM6E9EWojIchH5XEQ2i8h97nrPXd8qsnry+opIjIisEZFP3Lx/dNcnuEOufeUOwVaJ9h2GAAAFUUlEQVTXw1lTRORbv2vrC3VWfyISJSIbROQdd/mUrm1EFagAh1/ymj6q6vPodx5SgP7l1k0E3lfVVsD77rIXpHByVoCZ7vX1qerSM5ypKoXA/6hqW+CXwN3u31UvXt/KsoI3r+8xoK+qdgJ8QH8R+SXOUGsz3aHXDuAMxRZqlWUFeNDv2m4MXcQK3Qds8Vs+pWsbUQWKwIZfMgFS1Q9wel/68x++6hVg6BkNVYlKsnqWqu5U1fXu6zycf+zN8eD1rSKrJ6kj312Mdv8o0BdnyDXwzrWtLKtniUg8MBCY4y4Lp3htI61AVTT8kmf/IeH8Rfy3iHzsDvcUDpqp6k739S6gWSjDBGCciHzq3gIM+e2yirij/CcCq/H49S2XFTx6fd1bUBuBPcB7wNfAQVUtdDfxzO+G8llVteTaPuZe25kiUi+EEcubBTwEFLvLcZzitY20AhVueqrq5Ti3JO8WkStDHagm3C9de/l/e38BLsG5dbITeCq0cU4mIo2AhcB4VT3s/57Xrm8FWT17fVW1SFV9OCPcXAG0CXGkSpXPKiLtgUk4mbsC5wETQhixlIgMAvao6se1cbxIK1CBDL/kGar6nftzD7AI5x+S1+0WkZ8BuD/3hDhPpVR1t/uPvxj4Gx67viISjfMLf56qvuWu9uT1rSir168vgKoeBJYD3YGm7pBr4MHfDX5Z+7u3VVVVjwFz8c61TQKSRSQH5xFKX+AZTvHaRlqBCmT4JU8QkYYiElvyGugHfFb1Xp7gP3zV74C3Q5ilSiW/6F3X46Hr6963fwnYoqpP+73luetbWVavXl8RuUBEmrqv6wPX4Dw3W44z5Bp459pWlDXb7z8pgvM8xxPXVlUnqWq8qrbE+f2aoaq/4RSvbcSNJOF2dZ3FT8MvPRbiSBUSkYtxWk3gDEn1D69lFZFUoDfOcPq7gf8FFgNvABcB24CbVDXknRMqydob5/aTAjnAf/s93wkpEekJrAQ28dO9/Idxnu146vpWkXUkHry+ItIR50F9FM5/0t9Q1anuv7nXcW6ZbQBucVsoIVNF1gzgAkCAjcAdfp0pPEFEegMPqOqgU722EVegjDHGhIdIu8VnjDEmTFiBMsYY40lWoIwxxniSFShjjDGeZAXKGGOMJ1mBMqaWiMgq92dLEbm5lo/9cEXnMuZsZt3Mjall/t//qME+dfzGKqvo/XxVbVQb+YwJF9aCMqaWiEjJFyWnA73ceXrudwf7nCEia93BPf/b3b63iKwUkSXA5+66xe7gwJtLBggWkelAffd48/zPJY4ZIvKZOHOHDfc7dqaILBCRbBGZ5446YEzYqFP9JsaYGpqIXwvKLTSHVLWrO+r0hyLyb3fby4H2qvqtuzxWVfe7w9qsFZGFqjpRRMa5A4aW92uc0Ro64YySsVZEPnDfSwTaAd8DH+KMk5ZV+x/XmOCwFpQxwdcPGOVOmbAaZ/qBVu57a/yKE8C9IvIJ8BHOwMatqFpPINUdlHU3sAJnhOuSY+e6g7VuBFrWyqcx5gyxFpQxwSfAPaqaXmal86zqx3LLVwPdVfWIiGQCMadxXv+xzoqwf+8mzFgLypjalwfE+i2nA3e6U1IgIq3dEerLawIccItTG5zp00ucKNm/nJXAcPc51wXAlcCaWvkUxoSY/Y/KmNr3KVDk3qpLwZkPpyWw3u2osJeKp7xOA+4QkS3AFzi3+Uq8CHwqIuvd6QtKLMKZy+gTnFHDH1LVXW6BMyasWTdzY4wxnmS3+IwxxniSFShjjDGeZAXKGGOMJ1mBMsYY40lWoIwxxniSFShjjDGeZAXKGGOMJ/1/GGS8kmiTejkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "    airplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n",
            "0        311         246   413  450   395  314   263    295   174    220\n",
            "1        149         129   164  150    78   51    35     68    49     89\n",
            "2         63          88    71   62    35   25     4     30    12     47\n",
            "3         47          82    62   32    10   10     2     19     4     20\n",
            "4         44          55    54   17     5    3     1      2     1      8\n",
            "5         42          54    54   16     3    1     1      2     1      6\n",
            "6         38          54    54   12     2    1     0      1     1      2\n",
            "7         21          45    54    8     1    1     0      0     0      1\n",
            "8         18          44    54    7     1    1     0      0     0      1\n",
            "9         17          44    54    7     1    1     0      0     0      1\n",
            "10        17          44    54    7     1    1     0      0     0      1\n",
            "11        15          44    54    6     1    1     0      0     0      1\n",
            "12        15          44    54    6     1    1     0      0     0      1\n",
            "13        15          44    54    5     1    1     0      0     0      1\n",
            "14        15          44    54    5     1    1     0      0     0      1\n",
            "15        14          44    54    5     0    1     0      0     0      1\n",
            "16        14          44    54    5     0    1     0      0     0      1\n",
            "17        14          44    54    5     0    1     0      0     0      1\n",
            "18        14          44    54    5     0    1     0      0     0      1\n",
            "19        13          42    54    4     0    1     0      0     0      1\n",
            "20        13          42    54    4     0    1     0      0     0      1\n",
            "21        11          42    54    4     0    1     0      0     0      1\n",
            "22        11          42    54    4     0    1     0      0     0      1\n",
            "23        11          42    54    4     0    0     0      0     0      1\n",
            "24        11          42    54    4     0    0     0      0     0      1\n",
            "25        11          42    54    4     0    0     0      0     0      1\n",
            "26        11          42    53    4     0    0     0      0     0      1\n",
            "27        11          42    53    4     0    0     0      0     0      1\n",
            "28        11          42    53    4     0    0     0      0     0      1\n",
            "29        11          42    53    4     0    0     0      0     0      1\n",
            "30        11          42    53    4     0    0     0      0     0      1\n",
            "31        11          42    53    4     0    0     0      0     0      1\n",
            "32        11          42    53    4     0    0     0      0     0      1\n",
            "33        11          42    53    4     0    0     0      0     0      1\n",
            "34        11          42    53    4     0    0     0      0     0      1\n",
            "35        11          42    53    4     0    0     0      0     0      1\n",
            "36        11          42    53    4     0    0     0      0     0      1\n",
            "37        11          42    53    4     0    0     0      0     0      1\n",
            "38         9          42    53    4     0    0     0      0     0      1\n",
            "39         9          42    53    4     0    0     0      0     0      0\n",
            "40         9          42    53    4     0    0     0      0     0      0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "    airplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n",
            "0        334         327   423  371   281  267   197    251   315    315\n",
            "1        129         150   116   89    74  102    25     65    87    125\n",
            "2         89         129    85   41    10    9     2     21    17     34\n",
            "3         67         105    65   22     1    1     0      5     0     22\n",
            "4         32          81    63   14     0    0     0      0     0      0\n",
            "5         31          75    63   11     0    0     0      0     0      0\n",
            "6         31          62    63    9     0    0     0      0     0      0\n",
            "7          6          62    63    0     0    0     0      0     0      0\n",
            "8          1          62    63    0     0    0     0      0     0      0\n",
            "9          1          61    63    0     0    0     0      0     0      0\n",
            "10         1          61    63    0     0    0     0      0     0      0\n",
            "11         0          60    62    0     0    0     0      0     0      0\n",
            "12         0          60    62    0     0    0     0      0     0      0\n",
            "13         0          59    62    0     0    0     0      0     0      0\n",
            "14         0          59    62    0     0    0     0      0     0      0\n",
            "15         0          57    62    0     0    0     0      0     0      0\n",
            "16         0          57    62    0     0    0     0      0     0      0\n",
            "17         0          57    62    0     0    0     0      0     0      0\n",
            "18         0          57    62    0     0    0     0      0     0      0\n",
            "19         0          53    62    0     0    0     0      0     0      0\n",
            "20         0          53    62    0     0    0     0      0     0      0\n",
            "21         0          51    62    0     0    0     0      0     0      0\n",
            "22         0          51    62    0     0    0     0      0     0      0\n",
            "23         0          50    62    0     0    0     0      0     0      0\n",
            "24         0          50    62    0     0    0     0      0     0      0\n",
            "25         0          50    62    0     0    0     0      0     0      0\n",
            "26         0          49    62    0     0    0     0      0     0      0\n",
            "27         0          49    62    0     0    0     0      0     0      0\n",
            "28         0          49    62    0     0    0     0      0     0      0\n",
            "29         0          49    62    0     0    0     0      0     0      0\n",
            "30         0          49    62    0     0    0     0      0     0      0\n",
            "31         0          49    62    0     0    0     0      0     0      0\n",
            "32         0          49    62    0     0    0     0      0     0      0\n",
            "33         0          49    62    0     0    0     0      0     0      0\n",
            "34         0          49    62    0     0    0     0      0     0      0\n",
            "35         0          49    62    0     0    0     0      0     0      0\n",
            "36         0          49    62    0     0    0     0      0     0      0\n",
            "37         0          49    62    0     0    0     0      0     0      0\n",
            "38         0          47    62    0     0    0     0      0     0      0\n",
            "39         0          46    62    0     0    0     0      0     0      0\n",
            "40         0          46    62    0     0    0     0      0     0      0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxyj0jIa8Ofi",
        "colab_type": "code",
        "outputId": "834f854a-43bb-4a28-c18d-df94d0aeef0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(x_a.shape)\n",
        "print(A_miss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1802, 32, 32, 3)\n",
            "[4288, 266, 1006, 3376, 3914, 1512, 3167, 2373, 2798, 246, 1267, 4016, 3353, 2801, 2505, 1819, 4246, 1094, 3086, 1872, 3548, 3733, 1133, 2601, 3967, 4167, 818, 1795, 324, 4997, 544, 3570, 2928, 4591, 466, 4976, 2863, 2989, 3440, 1293, 1363, 3155, 878, 4174, 1403, 1190, 446, 4711, 880, 1066, 675, 4676, 4887, 3445, 3956, 1114, 2527, 824, 512, 1250, 1460, 4533, 2096, 3765, 3532, 1843, 2011, 4509, 3766, 3472, 2729, 527, 4220, 2315, 1003, 4673, 3560, 3813, 4472, 268, 1518, 3233, 2570, 2969, 3128, 4640, 3921, 2369, 3827, 1602, 1532, 1493, 804, 2883, 4163, 2653, 949, 3539, 1718, 987, 2281, 35, 4437, 3181, 3229, 323, 870, 2159, 328, 3690, 4106, 2473, 364, 3928, 4204, 1598, 3031, 766, 1449, 2681, 4910, 2139, 2619, 2756, 980, 637, 4108, 174, 2226, 143, 621, 4186, 417, 1159, 2577, 2056, 1728, 2692, 3048, 1773, 69, 21, 1097, 2205, 4637, 192, 890, 1141, 2345, 1596, 1222, 237, 1929, 505, 2772, 1526, 1390, 975, 3214, 4415, 2111, 3693, 366, 4179, 11, 183, 832, 3840, 4806, 603, 55, 4880, 2289, 2715, 2471, 3510, 2238, 1912, 2364, 4197, 2277, 2794, 684, 1946, 1368, 4940, 1794, 1775, 3727, 2242, 374, 1362, 4349, 2685, 213, 1882, 260, 3589, 895, 2095, 456, 3699, 2683, 1575, 1964, 945, 2745, 1592, 4586, 3190, 3753, 3681, 1745, 2497, 176, 2058, 4194, 3942, 62, 3632, 1777, 439, 1077, 3325, 0, 297, 3317, 3715, 1312, 4510, 2687, 1857, 2356, 3988, 2348, 4924, 3114, 4348, 1396, 3577, 4786, 231, 3315, 4836, 4553, 3145, 2708, 2865, 2611, 4185, 2153, 2273, 45, 4408, 1412, 2044, 54, 3133, 736, 550, 2233, 2828, 2013, 3604, 209, 201, 3814, 3847, 523, 3300, 1788, 4953, 4996, 1357, 1648, 2245, 2118, 131, 3334, 2549, 808, 1573, 1356, 4289, 4318, 3100, 1453, 1651, 2290, 2106, 2854, 952, 3782, 4825, 2252, 1416, 4890, 200, 4212, 3061, 2040, 1785, 4849, 3864, 1327, 4715, 3216, 4302, 1482, 554, 17, 4062, 3721, 2389, 2516, 1111, 2866, 499, 3598, 10, 2063, 2303, 2036, 1694, 3200, 4852, 3305, 1080, 1632, 607, 2841, 3593, 1880, 1958, 1091, 3999, 1032, 4010, 3073, 3046, 1934, 111, 4425, 3051, 3199, 2695, 661, 1313, 3006, 1807, 760, 3035, 2644, 242, 4205, 2332, 4161, 2412, 535, 3430, 1185, 2905, 1135, 3711, 4442, 2442, 2997, 2402, 2861, 4751, 2597, 2551, 4946, 1438, 3859, 1306, 51, 3141, 1620, 471, 2604, 2132, 4355, 4982, 724, 2740, 2565, 3848, 1256, 670, 2136, 1300, 329, 4080, 1542, 4548, 3638, 699, 2915, 4550, 1321, 639, 2956, 4930, 3419, 1621, 640, 2244, 359, 2721, 3411, 511, 547, 1709, 4856, 137, 630, 401, 4601, 3228, 4819, 1230, 792, 1940, 4850, 3955, 734, 1132, 289, 3159, 1660, 3408, 4662, 4315, 4566, 3551, 4695, 2349, 911, 3385, 334, 3576, 702, 4432, 2243, 632, 1935, 338, 583, 1229, 1861, 4266, 2788, 110, 820, 773, 4818, 3230, 781, 1227, 4149, 3301, 305, 2230, 967, 2850, 1881, 2047, 2914, 1611, 1274, 56, 4347, 4951, 1200, 3561, 2518, 3862, 4079, 1740, 610, 3243, 163, 695, 4190, 3930, 2846, 3830, 1746, 1151, 3028, 1071, 3088, 2450, 2666, 4488, 3337, 4434, 107, 1120, 4942, 2881, 580, 2088, 2545, 2648, 4397, 749, 3644, 3062, 2519, 2479, 2493, 3709, 2263, 3695, 4077, 1291, 3203, 3919, 3245, 4337, 4644, 4911, 216, 2615, 4892, 4941, 4331, 1574, 4044, 4087, 1476, 3170, 3186, 3597, 4788, 4807, 3041, 3416, 3364, 3778, 1455, 172, 1110, 4764, 3594, 3871, 3889, 3093, 2624, 2384, 1591, 3806, 557, 2557, 1735, 3219, 3881, 2786, 3599, 4361, 40, 3836, 4706, 4120, 4124, 153, 1350, 148, 1215, 141, 4904, 963, 1901, 3863, 2104, 4189, 3113, 2837, 998, 4936, 2278, 2407, 3646, 2272, 1714, 1158, 4469, 1385, 1747, 1253, 3676, 1364, 2307, 1128, 3975, 3436, 3460, 1407, 3896, 4593, 4821, 3368, 2701, 965, 4840, 4237, 2609, 2968, 1841, 1284, 717, 4084, 4386, 3794, 2154, 4985, 1456, 4213, 3366, 4308, 2510, 4233, 3485, 4812, 1258, 1314, 4830, 284, 299, 398, 3475, 984, 528, 1115, 552, 1646, 2782, 4341, 1406, 4117, 3107, 1150, 1191, 2026, 3251, 4523, 513, 214, 2182, 3049, 4782, 1976, 1105, 685, 241, 4142, 4178, 3550, 4968, 2512, 1234, 927, 33, 657, 196, 368, 207, 1262, 3263, 1464, 1480, 4693, 1153, 4293, 2064, 2326, 3664, 738, 4652, 4243, 2007, 414, 538, 3841, 1649, 3649, 115, 3906, 584, 78, 2030, 4681, 1860, 4979, 4138, 2025, 128, 3839, 4275, 4385, 3293, 3745, 4392, 1668, 3379, 3002, 271, 4325, 1292, 2741, 1561, 4187, 4714, 4073, 1278, 714, 1770, 1523, 4753, 204, 4920, 1098, 3387, 3278, 3421, 3541, 4522, 2390, 4440, 463, 2924, 3520, 570, 3707, 2947, 950, 102, 1136, 2652, 2170, 3153, 2067, 2049, 2347, 2897, 3285, 2691, 3098, 1175, 3239, 388, 1176, 3613, 575, 740, 3751, 758, 2048, 185, 495, 2789, 2120, 2181, 3112, 1540, 722, 3546, 1371, 1989, 3523, 1604, 866, 3372, 2180, 3238, 177, 4364, 3723, 996, 182, 1680, 1395, 212, 574, 42, 2534, 99, 1221, 3332, 3647, 4304, 3811, 1086, 3947, 4584, 278, 3731, 2061, 3452, 3634, 1968, 939, 3645, 1389, 4598, 2941, 4580, 3781, 4882, 741, 4195, 4826, 1762, 4319, 3378, 896, 4708, 377, 2522, 3206, 3505, 228, 4330, 372, 461, 2352, 3976, 4638, 4504, 793, 2023, 2004, 3479, 2623, 2259, 4535, 2344, 4085, 3922, 1873, 4251, 1778, 1599, 4701, 3580, 2536, 2065, 3652, 4259, 2119, 3703, 703, 1497, 3718, 2984, 489, 31, 517, 4099, 4018, 2872, 795, 4883, 2957, 2845, 3660, 1914, 4005, 3382, 1244, 3490, 1981, 4096, 2633, 1297, 4272, 633, 1631, 2301, 1687, 327, 1248, 2669, 4778, 2982, 2564, 220, 2815, 2253, 1641, 2847, 2460, 300, 90, 4150, 1682, 1800, 960, 2222, 2304, 3456, 2590, 3607, 2727, 2397, 4848, 2958, 1467, 4002, 175, 2388, 1494, 4738, 3402, 3341, 84, 2640, 2101, 1160, 732, 3304, 3878, 2543, 1945, 1104, 1576, 833, 3183, 2052, 4983, 476, 3706, 3724, 2189, 59, 13, 4100, 180, 2319, 4661, 3968, 3844, 955, 4594, 1054, 983, 4803, 4487, 392, 1134, 4418, 561, 2784, 2157, 647, 1417, 4267, 873, 1333, 3433, 432, 1919, 4137, 1024, 1560, 4585, 2797, 994, 3333, 2548, 2328, 1808, 1999, 2452, 3142, 4130, 2410, 3339, 2528, 3884, 169, 2276, 2588, 582, 2494, 4647, 2018, 1906, 399, 876, 3284, 16, 4970, 2100, 4699, 1055, 4203, 4242, 3148, 3910, 3323, 2214, 1712, 3024, 1161, 4086, 700, 3082, 1531, 3952, 4216, 1985, 2448, 4463, 1703, 3780, 3962, 4517, 1701, 2719, 2375, 3810, 191, 1478, 3173, 3401, 26, 3668, 4964, 3658, 4783, 4885, 1423, 2620, 920, 4969, 4798, 3853, 3478, 2458, 4611, 3291, 1662, 104, 4610, 1102, 356, 1629, 2851, 4544, 4218, 577, 2974, 43, 3631, 4896, 2424, 4674, 1294, 4747, 2693, 1180, 991, 4793, 2085, 4362, 2383, 1544, 854, 1106, 4166, 4763, 3116, 2893, 1787, 1823, 3789, 3615, 4479, 573, 3319, 756, 1484, 4554, 4569, 4529, 1063, 3010, 3603, 1922, 3954, 3587, 1910, 2220, 3601, 2583, 3573, 2880, 1692, 3459, 1548, 1951, 173, 1207, 712, 4889, 2300, 4453, 2196, 4441, 3207, 830, 1399, 2641, 1415, 1432, 4582, 545, 968, 81, 3279, 2117, 4374, 2411, 872, 2336, 1060, 3184, 4524, 4081, 351, 4630, 1123, 2898, 2377, 1863, 357, 2614, 943, 3480, 3427, 2707, 2586, 4468, 3265, 1261, 1425, 2663, 145, 4563, 53, 966, 2434, 2540, 441, 815, 1044, 4592, 4222, 1896, 1168, 1298, 2562, 1419, 483, 1226, 1645, 322, 2037, 1638, 2953, 1766, 2198, 3944, 4952, 3710, 2799, 3352, 4097, 4508, 3651, 2054, 1916, 4656, 2976, 18, 1447, 2912, 4608, 2073, 4646, 1706, 1696, 1021, 658, 4757, 2605, 3267, 4307, 2081, 1913, 4928, 4482, 3701, 3797, 3823, 4590, 282, 1949, 2616, 2776, 2179, 2342, 4933, 871, 3950, 4417, 2712, 674, 1103, 3802, 2531, 3455, 365, 2122, 1818, 2306, 4559, 1804, 2191, 25, 3477, 2806, 2713, 3529, 1827, 1499, 1442, 1358, 1201, 3328, 3272, 2626, 3661, 2999, 1048, 2500, 1118, 1743, 1131, 1353, 1377, 4678, 1008, 1527, 4324, 2670, 254, 852, 2705, 2393, 2431, 74, 3637, 4333, 3390, 1797, 1911, 1539, 693, 3679, 2637, 4511, 1885, 3202, 1247, 4748, 701, 2818, 1272, 4158, 1672, 189, 127, 2896, 279, 4143, 2804, 754, 240, 3377, 4045, 2041, 3773, 2889, 2075, 1005, 959, 4772, 4454, 1062, 2213, 3166, 4153, 4227, 4017, 4973, 2420, 4843, 2962, 2365, 1263, 2224, 2529, 2900, 4450, 2796, 3821, 197, 2441, 395, 4075, 626, 2357, 565, 1751, 2456, 1238, 1446, 2446, 4046, 3482, 346, 373, 536, 1042, 1871, 1558, 3188, 168, 2750, 1954, 2661, 19, 3680, 3194, 2019, 2716, 4918, 4323, 4627, 1825, 3858, 307, 2034, 2423, 2589, 2014, 2546, 48, 2779, 4573, 3774, 1056, 2074, 4021, 4543, 4245, 2598, 1767, 447, 3568, 2970, 2964, 3470, 2103, 36, 4462, 2453, 2697, 4780, 4483, 3264, 294, 1491, 3978, 2171, 4168, 1049, 3359, 631, 3666, 1202, 4042, 2057, 3719, 3583, 2204, 1099, 1684, 1017, 683, 1814, 2821, 4466, 697, 2747, 1555, 316, 946, 3993, 97, 4451, 3047, 3431, 2408, 4035, 2988, 4011, 1732, 2031, 3174, 4283, 2465, 4732, 247, 3124, 2361, 4461, 1264, 4792, 4990, 3633, 1731, 2793, 1515, 4895, 1400, 853, 4532, 2550, 2415, 1302, 961, 4995, 4156, 3011, 2206, 2161, 2731, 4558, 3834, 2517, 431, 2610, 1299, 2003, 1252, 1073, 3104, 1002, 1445, 2755, 2285, 3434, 4809, 4961, 3450, 1852, 3800, 1354, 1796, 2186, 856, 1119, 4031, 1441, 851, 3933, 1930, 3172, 1251, 2208, 2380, 2257, 2029, 2885, 2394, 3412, 1628, 3849, 2812, 1854, 4055, 1562, 509, 2972, 1865, 1283, 3137, 1034, 2980, 3466, 4039, 1921, 3237, 3250, 4717, 3742, 1309, 4824, 150, 663, 3119, 428, 3688, 379, 4688, 2288, 1187, 1776, 386, 4606, 4634, 2362, 1375, 4909, 2002, 672, 2910, 2917, 1126, 1437, 2334, 1992, 3140, 788, 1967, 2736, 4561, 1343, 1488, 1409, 1519, 4730, 233, 1193, 638, 3704, 4210, 2391, 3639, 2062, 908, 4774, 4520, 2919, 3771, 1144, 2634, 2445, 208, 1634, 585, 1031, 448, 3991, 1367, 534, 1636, 1551, 2875, 1723, 1068, 3828, 3045, 1552, 1374, 370, 4512, 2824, 786, 3135, 4297, 2791, 4993, 4228, 1933, 3697, 4240, 704, 912, 1546, 3461, 2760, 1918, 611, 867, 4063, 362, 2559, 4761, 2849, 3995, 287, 120, 4128, 3244, 764, 4547, 1223, 3852, 4526, 3713, 1578, 4811, 2628, 4860, 3557, 4481, 798, 3547, 3381, 2742, 1572, 4405, 272, 4784, 821, 2977, 313, 3629, 1116, 1384, 1061, 4132, 3373, 2913, 4750, 1273, 3191, 4903, 165, 2429, 1754, 4642, 942, 1802, 726, 3842, 930, 1697, 3732, 4901, 1727, 4546, 2523, 1685, 341, 4050, 3838, 2777, 2822, 3044, 1666, 4299, 4020, 194, 118, 769, 1826, 1577, 2403, 690, 3507, 2316, 497, 649, 41, 3524, 2724, 4773, 1699, 669, 4513, 682, 1157, 295, 2284, 1240, 1172, 3134, 4668, 3935, 14, 1317, 1653, 1937, 4660, 979, 3736, 951, 4147, 532, 3798, 1866, 3498, 525, 3683, 4449, 1033, 789, 30, 3936, 3068, 2113, 586, 2718, 2490, 2310, 4868, 725, 2464, 2867, 889, 4049, 4947, 2398, 1347, 688, 2197, 1530, 403, 4433, 2668, 4833, 1549, 1422, 4700, 3851, 814, 2010, 3277, 3496, 4422, 4716, 1952, 862, 4800, 897, 3517, 1774, 1198, 3682, 4571, 1492, 4411, 236, 4649, 2643, 976, 4192, 4769, 340, 4052, 770, 592, 879, 2911, 1429, 3349, 2515, 286, 4966, 938, 1391, 4734, 1971, 934, 3675, 4725, 4282, 4082, 836, 79, 842, 1568, 50, 385, 4286, 3484, 4682, 1663, 2717, 3386, 2484, 2884, 926, 4188, 4948, 1146, 1529, 2147, 1926, 3591, 4322, 3927, 594, 3513, 4859, 1209, 1129, 4570, 3877, 2636, 3741, 1603, 3625, 2965, 405, 3269, 634, 4290, 696, 874, 4663, 4407, 2287, 847, 3097, 4629, 761, 3687, 1152, 378, 2767, 4998, 4260, 4815, 3572, 4622, 1405, 3442, 3590, 622, 972, 3292, 1892, 1581, 2672, 132, 2995, 4398, 1616, 860, 3904, 1941, 7, 3770, 210, 2682, 2858, 4382, 2553, 4831, 2145, 601, 4036, 3544, 4057, 2738, 1736, 288, 2504, 4420, 442, 485, 2939, 3022, 1204, 2274, 1607, 4321, 609, 4144, 775, 2654, 491, 2749, 4871, 3115, 3428, 4438, 2331, 2809, 3252, 1078, 1637, 665, 1, 4987, 4112, 114, 882, 3030, 1379, 202, 38, 2241, 15, 4378, 1337, 1277, 458, 1614, 653, 113, 4754, 1469, 3489, 3563, 3175, 4376, 1765, 2146, 3414, 1719, 2625, 3543, 68, 2507, 887, 2547, 434, 2279, 64, 2296, 1579, 160, 2015, 438, 2094, 1966, 1156, 2761, 3716, 4444, 400, 3865, 2286, 2595, 2409, 1876, 3916, 2175, 1894, 2709, 2511, 931, 4134, 4804, 1749, 2848, 179, 567, 1729, 4202, 4380, 293, 472, 4905, 3961, 2261, 3158, 3747, 1057, 4623, 198, 2871, 2462, 1987, 71, 3001, 1282, 276, 3361, 3522, 2341, 3297, 274, 728, 678, 4978, 4703, 252, 4231, 2951, 2979, 3469, 2006, 142, 4766, 3552, 2790, 3029, 1084, 2234, 4393, 1664, 1081, 2203, 1899, 3256, 371, 4314, 348, 1330, 1320, 1165, 4917, 2726, 3286, 2416, 3901, 2280, 1394, 3982, 1917, 3342, 2659, 1328, 765, 1125, 2283, 3344, 4273, 892, 1695, 2573, 3600, 3226, 2027, 1430, 3959, 4301, 4855, 4326, 563, 2698, 2813, 263, 3089, 3515, 1956, 986, 4089, 3209, 2771, 3126, 572, 3050, 4752, 2908, 1756, 4241, 1608, 4056, 1290, 687, 3260, 865, 1904, 4756, 4888, 2228, 1836, 2098, 3643, 1928, 4659, 2256, 2312, 3874, 1847, 325, 787, 4061, 162, 4372, 487, 4956, 4862, 4193, 4491, 2466, 4201, 2768, 4686, 1213, 277, 2210, 1781, 742, 4051, 2922, 1504, 2769, 4369, 2842, 1148, 1411, 4965, 1584, 3380, 1260, 2414, 4170, 533, 3918, 1744, 1907, 2635, 3053, 57, 4114, 1477, 3511, 3890, 1553, 229, 1117, 2371, 2722, 1216, 828, 2524, 941, 4597, 2936, 488, 2099, 2329, 2948, 1617, 429, 3791, 2596, 4165, 4667, 3078, 2428, 839, 258, 190, 262, 1708, 953, 1678, 4236, 1622, 3691, 3717, 3000, 3306, 566, 1705, 2732, 1891, 4446, 617, 1489, 3623, 4133, 673, 3347, 4914, 2487, 3254, 4354, 606, 3784, 3934, 1961, 2192, 777, 1679, 3446, 3415, 627, 3015, 1280, 4327, 4588, 422, 24, 3340, 3444, 3232, 2305, 1681, 668, 581, 2455, 1511, 2593, 4929, 4424, 2639, 2655, 2436, 864, 326, 8, 1710, 1851, 2888, 4365, 140, 1498, 2950, 1726, 3941, 465, 2606, 1832, 4384, 2156, 3965, 780, 1868, 3275, 4939, 3654, 3722, 2932, 4287, 3534, 3620, 124, 4065, 2558, 4019, 3951, 3618, 841, 1667, 2810, 3737, 345, 4047, 3182, 1381, 2360, 655, 3985, 2918, 1275, 598, 117, 4802, 3075, 280, 2662, 539, 65, 1658, 330, 2149, 2174, 4583, 2443, 1626, 4007, 413, 3449, 29, 4877, 4401, 3465, 4915, 4181, 4683, 4070, 1485, 4445, 4311, 4024, 121, 2927, 4664, 2923, 1466, 2990, 3017, 4295, 1487, 1030, 2165, 1805, 3451, 4834, 2021, 3943, 2297, 4280, 4669, 46, 4162, 542, 2218, 3777, 2060, 4176, 394, 4796, 1700, 1507, 2887, 2618, 1346, 1550, 1022, 2890, 3846, 1870, 3374, 4343, 3911, 1846, 4414, 2162, 2083, 1012, 1905, 3913, 3, 3362, 2876, 1677, 3261, 161, 4353, 2930, 1359, 2237, 3303, 962, 1122, 3653, 331, 1889, 1878, 1074, 1842, 421, 3854, 3502, 2556, 3273, 4252, 4626, 1724, 4486, 259, 3169, 2532, 2427, 3407, 3531, 3375, 2110, 989, 650, 858, 2541, 250, 1990, 3692, 1902, 4094, 3553, 2561, 4067, 2942, 794, 4471, 4698, 4908, 2675, 4870, 389, 4984, 1281, 1162, 2960, 4505, 2855, 4310, 1831, 1481, 3231, 66, 265, 1978, 3894, 393, 4196, 4419, 3432, 2735, 3888, 2765, 2757, 1254, 4119, 4988, 1096, 1503, 1473, 731, 2862, 4109, 22, 4467, 3708, 3776, 4368, 2952, 3012, 3545, 2459, 494, 4609, 4980, 4631, 188, 4922, 32, 4507, 3663, 2350, 2178, 2335, 612, 4731, 845, 4296, 4654, 3974, 2478, 3193, 2903, 4742, 2050, 3234, 1224, 1721, 320, 4262, 4388, 1323, 3422, 2961, 1065, 3034, 149, 510, 3569, 4981, 2080, 4000, 285, 2155, 4516, 3611, 767, 89, 3013, 3091, 2020, 1001, 1533, 1035, 3033, 4090, 1009, 2843, 37, 4893, 2496, 3493, 4709, 1758, 3518, 2603, 1142, 4069, 4957, 3816, 2016, 4455, 1366, 1387, 1304, 4900, 2787, 1301, 2891, 1286, 3994, 881, 3052, 283, 2955, 1305, 1269, 86, 1789, 615, 147, 1750, 4705, 407, 2498, 2235, 2447, 3085, 520, 3266, 790, 4038, 3070, 275, 1513, 4653, 608, 1372, 4066, 4198, 705, 1786, 2475, 4008, 2762, 3406, 3818, 3870, 3144, 3394, 2542, 4727, 935, 3984, 883, 4416, 4484, 3063, 1233, 1944, 1654, 2651, 2093, 1087, 4718, 3992, 1075, 3808, 460, 3764, 4844, 2166, 4225, 4545, 4697, 686, 4864, 181, 1027, 4335, 76, 502, 2372, 4572, 4972, 1197, 4477, 4230, 343, 1029, 4054, 2260, 480, 624, 838, 503, 2217, 290, 125, 2432, 508, 782, 2975, 2981, 203, 2780, 2998, 2795, 529, 3562, 3648, 4677, 195, 3299, 4214, 1657, 1570, 1089, 1556, 822, 3565, 4029, 3322, 1813, 3566, 4633, 744, 3464, 2649, 1454, 4145, 2148, 4270, 4853, 4645, 239, 985, 238, 3963, 1208, 1028, 1996, 4624, 2575, 1674, 4363, 4211, 1605, 3246, 2399, 3714, 1903, 659, 3655, 2071, 863, 4003, 4671, 4394, 2000, 504, 3519, 2671, 3249, 1295, 4799, 4092, 3549, 3099, 2608, 3069, 4206, 4801, 2585, 1195, 3258, 1397, 3309, 4873, 2678, 3473, 3659, 546, 2322, 4975, 3972, 1270, 1618, 3609, 813, 4960, 4737, 4986, 4223, 95, 4344, 1067, 662, 2632, 4954, 3506, 2509, 1707, 1124, 1139, 1170, 1318, 1995, 3684, 825, 235, 3468, 4277, 4992, 3365, 2045, 100, 1382, 2622, 336, 101, 3779, 3900, 1149, 146, 2363, 3795, 4409, 2503, 155, 1661, 2227, 1360, 4577, 4351, 4540, 3056, 2945, 1514, 1338, 1768, 1181, 1623, 1601, 457, 2901, 933, 3417, 857, 380, 3457, 1510, 4500, 3066, 3670, 4958, 1459, 3729, 1977, 1898, 3329, 3179, 1915, 2991, 1479, 1461, 1609, 39, 3728, 2121, 971, 2630, 1508, 4499, 1757, 978, 1386, 526, 1177, 4733, 666, 358, 3483, 2973, 2803, 2844, 157, 4614, 1643, 311, 2321, 1627, 4541, 426, 4292, 4475, 1439, 49, 3886, 3076, 1050, 4605, 369, 3308, 2476, 748, 3471, 159, 232, 1669, 257, 1500, 2449, 349, 98, 1167, 1830, 3165, 1388, 3494, 1402, 184, 2886, 1931, 4121, 677, 1037, 2302, 3345, 2877, 3320, 2748, 918, 2072, 4702, 3311, 3642, 2141, 2172, 2879, 4476, 2642, 4059, 4400, 3855, 3902, 2199, 3198, 1011, 616, 315, 3396, 1266, 3014, 1154, 4899, 1418, 2400, 3160, 3120, 4095, 692, 2711, 3700, 1932, 1771, 719, 4316, 4413, 1108, 3087, 1471, 2778, 3178, 1711, 2127, 4435, 1924, 3270, 1969, 4175, 2580, 2613, 2699, 4012, 1799, 4991, 785, 708, 2833, 3331, 1164, 4604, 1189, 4829, 1748, 4789, 757, 3077, 270, 988, 2087, 531, 1567, 1376, 4858, 3092, 2916, 2566, 269, 1000, 4164, 397, 1693, 4923, 467, 319, 556, 4805, 2084, 898, 3971, 1520, 4101, 2572, 3071, 4028, 4490, 716, 2022, 264, 496, 1953, 1979, 4721, 1196, 3980, 997, 3026, 1490, 4284, 1365, 3824, 360, 4808, 723, 605, 1495, 3499, 2554, 4173, 4949, 67, 1013, 763, 4217, 4749, 2878, 2552, 4430, 3338, 4743, 2535, 1451, 4762, 1475, 3949, 3162, 3521, 1506, 1474, 4534, 4157, 875, 1434, 1440, 2012, 2151, 2807, 4959, 671, 166, 595, 1673, 4692, 2078, 3861, 2690, 4612, 1072, 613, 2324, 222, 1980, 2856, 739, 948, 3605, 4771, 2236, 4264, 3672, 1339, 916, 3409, 234, 4696, 2495, 1755, 2143, 1988, 2295, 646, 3080, 1448, 2688, 3819, 3730, 4872, 1528, 891, 2249, 3829, 2909, 4926, 3908, 4238, 4729, 1468, 1414, 1109, 1590, 1759, 516, 3032, 2743, 3016, 645, 4281, 4139, 3094, 3673, 2176, 2759, 3215, 3628, 4962, 2128, 1890, 2966, 3735, 2730, 3787, 4389, 1059, 4474, 501, 1349, 2223, 251, 3357, 1246, 4574, 2907, 901, 1963, 391, 2508, 4595, 436, 3559, 4034, 1171, 3288, 4083, 840, 1670, 3057, 2339, 3662, 1053, 3095, 4248, 3307, 4722, 2734, 2055, 2882, 2646, 133, 2751, 1016, 1045, 3121, 2164, 2770, 4944, 4650, 3454, 877, 4974, 4127, 3462, 4447, 1100, 540, 4931, 1806, 2665, 2142, 2513, 3176, 4457, 1041, 4607, 1217, 344, 4971, 2444, 597, 2368, 3996, 3371, 4765, 1401, 3125, 1845, 642, 629, 1563, 779, 778, 3221, 4935, 2656, 3937, 1801, 4131, 3857, 4842, 1345, 3946, 524, 3757, 809, 1443, 4404, 1835, 4496, 2677, 4371, 4617, 1594, 3882, 2133, 4740, 2053, 2124, 4064, 922, 924, 1720, 2282, 3512, 2638, 4406, 2395, 3674, 3321, 3280, 355, 553, 861, 2144, 1010, 848, 3837, 2576, 2066, 193, 2733, 3123, 3626, 3225, 1877, 784, 3106, 1051, 3986, 3488, 4004, 928, 3540, 2775, 4338, 506, 772]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}